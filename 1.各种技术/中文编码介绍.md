# 中文编码介绍

## 1.介绍

- 为什么需要编码
  - 因为计算机存储的都是二进制的数字，本身是字节
  - 然而人去看一个个字节是看不懂的，人能看懂的是字符
  - 将**字节码**映射成人能够看懂的**字符**，这样一个映射关系就是编码
  - 字符肯定是有很多个字符，字符构成的集合就叫字符集
  - 字符集跟编码是两个概念。
    - 同一套字符集可能有多种编码方式，当然也可能只有一种编码方式。
    - 大多时候，字符集跟编码是一个概念。比如GB2312，既代表了一个中文字符集，又代表了字节码和字符（中文汉字）的映射规则。

## 2.编码方式

### 1.ascii码（一个字节）

- 将 0~127这128个数字（字节码）映射成 英文、标点、回车等字符。
- 也就是说一开始的ascii码只有128种映射规则

### 2.扩展版本的ascii码（已淘汰）

- 将128~255也加入了进来。将字符集扩展了一倍。加入了法语字符等。
- 这个版本的ascii码并没有流行开来，设计出来就被时间慢慢淘汰了。

### 3.1980年中国提出了GB2312-80（一个字节或两个字节）

- 它既是一个中文字符集，又是一种编码规则。
- 收录了6763个汉字，还有拉丁文字、日本文字 等等等等。
- 使用1~2个字节
  - 1字节==ascii码
  - 两个字节时，就是区字节+位字节
- 假如内存里的数按一个字节一个字节来读是 86 53 177 168 35
  - 那么86，小于128，按ascii识别
  - 53，小于128，按ascii识别
  - 177，因为它大于128.超出了ascii码的规范。所以177 和 168要连在一起识别，即177是区字节，168是位字节，一起去查询汉字。
  - 然后是35，小于128，按ascii识别。
- 因此GB2312是一种变长的编码规范。可能是一个字节，也可能是两个字节。一个字节时，就是ascii码。二个字节时，就是用来表示中文的。
- 如何区分内存里的数据是一个字节还是两个字节，就是依靠判断内存里的字节数字是小于128还是大于128

### 4.1995年定制了GBK（一个字节或两个字节）

- （GB2312最多是两字节，但是对于两字节映射的利用率太低了，存在大量浪费），GBK提高了利用率，同样是两字节，容纳了更多的汉字和其他字符。
- GBK兼容GB2312

- GB2312对两个字节的利用率太低了。GBK提高了利用率。
- GBK依然是1个字节，或者2个字节。
- 举个例子：
  - 瞭望的瞭，GB2312根本就没有收录。GBK就扩充收录了进来。

### 5.2000年制定了GB18030（最大4个字节）

- 对GBK扩充。
- 完全兼容GB2312，但不完全兼容GBK
- GB18030采用1~4个字节
  - 1字节==ascii
  - 2字节≈GBK
  - 4字节是为了兼容unicode
- 比如：㞎，在GB18030中收录了，但是GBK就没有，GB2312更没有

### 6.目前用的最多的编码utf-8。它是编码方式，但不是字符集

- utf-8编码，对应的字符集是unicode字符集。
  - 注意：unicode字符集既有utf-8编码方式，也有utf-16编码方式
- utf-8使用1~4个字节对unicode字符集的字符进行编码
  - 1字节==ascii
  - 2字节==希腊、拉丁
  - 3字节==中文、日文、韩文
  - 4字节==不常用

## 3.实际生活中的乱码问题

- 明确几点
  - 1.程序文件有编码
  - 2.数据文件和数据源有编码
  - 3.展示数据的平台也是有编码的
- 几种出现乱码的情形
  - 1.比如说一个文件的编码方式是A。但是文件浏览器或者IDE的编码方式是B。那么当你用这个IDE打开文件时，就会乱码。
  - 2.比如我们的程序读取编码方式是A的数据，并把它转成了字符串。但是字符串使用的编码默认是编码B，也会乱码。
  - 3.比如网页浏览器向服务端请求的数据假如说编码是A，但是我们的浏览器去展示的时候，用的编码方式是B，也会乱码。
- 举个例子
  - 这个网页采用utf-8编码。中文都是用3个字节来表示的。
    - ![image-20210225163815924](http://pichost.yangyadong.site/img/image-20210225163815924.png)
- 如果我强行让浏览器采用GBK来解析。
  - ![image-20210225164049793](http://pichost.yangyadong.site/img/image-20210225164049793.png)
- 可以看到除了数字英文还正常显示，所有的中文都成乱码了。原因是：他们都是兼容ASCII码的，一个字节时都是ASCII码。但是中文可不同。utf-8的中文都是3个字节，GBK的中文都是2个字节，所以中文必乱码。
  - ![image-20210225164138617](http://pichost.yangyadong.site/img/image-20210225164138617.png)

## 4.几个有趣的点

### 1.URLEncode

- ![image-20210225164700982](http://pichost.yangyadong.site/img/image-20210225164700982.png)
- 你把这个URL复制以后，当然不会复制上中文，而是进行了URLEncode。其实就是中文的utf-8编码，插入上%而已
- https://github.com/yangyadongv/Cpp-BackEnd-Development-Notes/tree/master/1.%E5%90%84%E7%A7%8D%E6%8A%80%E6%9C%AF
- 1.【%E5%90%84】【%E7%A7%8D】【%E6%8A%80】【%E6%9C%AF】
- 其实就是1.各种技术。在utf8里，每个汉字用3个字节。
- URLEncode就是把汉字进行utf-8编码，然后用%间隔开每个字节。

### 2.爬虫时

- 首先已知源网页是GBK中文编码的。然后你以string的方式接收爬虫结果，然后用gbk来解码这个string，在编码成utf-8格式。还是乱码。

- 原因是：

  - 接收爬虫结果时时以String类型获取，这就其实已经经过一层utf-8编码了。但是原网页又是GBK的，用string接收，就已经出错了。

  - ![image-20210225170121160](http://pichost.yangyadong.site/img/image-20210225170121160.png)

- 正确做法：

  - 以byte数据接收，然后直接gbk解码，输出即可。
  - ![image-20210225170253102](http://pichost.yangyadong.site/img/image-20210225170253102.png)

- 所以爬虫时，尽量不要以string接收爬虫结果。因为一旦源网页不是utf-8编码，那么用string接收就是错误的。

