# 1.项目笔记

## 1.C++

### 1.sighandler_t类型（typedef void (*sighandler_t)(int)）

#### 先理解一下函数指针

函数指针的定义方式为：

```c
函数返回值类型 (* 指针变量名) (函数参数列表);

举例：
int(*p)(int, int);//定义了一个指针变量 p，该指针变量可以指向 "返回值类型为 int 型，且有两个整型参数"的 函数。p 的类型为 int(*)(int，int)。
```



```c
int Func(int x);   /*声明一个函数*/
int (*p) (int x);  /*定义一个函数指针*/
p = Func;          /*将Func函数的首地址赋给指针变量p*/
```

#### sighandler_t类型声明

`typedef void (*sighandler_t)(int);`

如何理解？利用`typedef int *apple;`来解释

```c
int *apple;//声明了一个 "指向整型变量的" 指针apple  (注意：定义只是一种特殊的声明)
typedef int *apple;//声明了一种 "指向整型变量的 "指针类型apple。apple是一种类型，可以像使用int一样去使用它。
```

现在，回过来看上面的这个函数原型 `typedef void (*sighandler_t)(int)`，盖住 typedef不看 ，再简单不过，`sighandler_t`就是一个函数指针，指向的函数接受一个整型参数并返回一个无类型指针 。加上typedef之后sighandler_t就是一种新的类型，就可以像int一样地去用它，不同的是它声明是一种函数指针，这种指针指向的函数接受一个整型参数并返回一个无类型指针 。

#### 练习

做一个更酷的练习，请看：`typedef char* (* c[10])(int **p);`

盖住typedef。c是一个拥有10个元素的数组，只不过这个数组c的元素有点特别，元素都是函数指针，并且它们所指向的这些函数统统都接受一个int二级指针，然后返回一个指向char的指针。加上typedef之后，c就不是一个数组了，而是一种“数组”类型了。

### 2.#program  once

防止重复包含。

它指的是防止你手写了一个A.h文件。又写了一个B.h文件。结果B还include了A。在main里 把A、B都include了进去，这样A就被重复包含了好几遍，会出现多次声明的问题。

### 3.string转char*类型

```c
char* c; 
string s="1234"; 
c = s.c_str(); 
```

### 4."\t"对应多少个空格

![image-20210319153439508](http://pichost.yangyadong.site/img/image-20210319153439508.png)

```c
cout<<"123"<<"\t"<<endl;// \t将补充5个空格，凑够8
cout<<"1234567"<<"\t"<<endl;// \t将补充1个空格，凑够8
cout<<"12345678"<<"\t"<<endl;// \t将补充8个空格。因为已经够8的倍数了
cout<<"123456789012345"<<"\t"<<endl;// \t将补充1个空格，凑够16
cout<<"1234567890123456"<<"\t"<<endl;// \t将补充8个空格。因为已经够8的倍数了
cout<<"12345678901234567"<<"\t"<<endl;// \t将补充7个空格，凑够24
cout<<"1234567890123456789"<<"\t"<<endl;// \t将补充5个空格，凑够24
cout<<"12345678901234567890123"<<"\t"<<endl;// \t将补充1个空格，凑够24
cout<<"123456789012345678901234"<<"\t"<<endl;// \t将补充8个空格。因为已经够8的倍数了
cout<<"1234567890123456789012345"<<"\t"<<endl;// \t将补充7个空格，凑够32
```

### 5.模板类的成员函数实现应该放在头文件中

- 模板类的成员函数实现应该放在头文件中
- 因为模板类本质上不是类，只有实例化之后才会编译生成.o文件
- 即thread_pool.h，不可以有对应的thread_pool.cpp

### 6.对于模板类指针

```c++
template<class T> 
class thread_pool{

}

thread_pool<T>* threadPool
    或者
thread_pool* threadPool
 	都可以
```

### 7.主线程退出后，子线程会不会退出

- 主线程程序return，间接调用了exit()函数，因为一个线程调用exit函数，导致整个进程的退出，系统回收所有的资源，当然所有的线程都退出了。
- 在主线程退出时，要想系统并不回收进程的所有资源，可以调用`pthread_exit();`然后等其他线程终止退出。

### 8.类方法的实现，在类内实现和类外实现的区别

为了减少时间开销，如果在类体中定义的成员函数中不包括循环等控制结构，C++系统会自动将它们作为内置(inline)函数来处理。

### 9.析构函数和构造函数private

- 在单例模式中，一定要把构造函数声明为private。

  - （使用c++11的局部变量模式的单例懒汉）中的析构函数也可以private。因为（使用c++11的局部变量模式的单例懒汉）真实实例是局部静态变量，无需手动析构（即delete），设为private也可以自动析构。
  - 单例懒汉双检锁和单例饿汉，都不可以把析构函数设为private，因为要手动delete

- 把构造函数声明为private，意思是用户（使用类的人）不可以自己实例化该类对象（只能通过getinstance等方法来构造实例）。

- 把析构函数声明为private，意思是不允许delete该类指针，或者是该类实例生命周期结束自然析构。

- 注意：

  - ```c
    class TEST{
        public:
            TEST(){
                cout<<"构造"<<endl;
            }
    
        private:
            ~TEST(){
                cout<<"析构"<<endl;
            }
    };
    int main()
    {
        TEST a; 
        return 0;
     }
    //这种写法，编译根本就通过不了。因为析构函数是private，在main中没法自动调用析构函数来析构。
    ```

### 10.可变参数宏`__VA_ARGS__`

#### 第一种用法（直接传入printf）

```c
//最简单的定义
#define my_print1(...)  printf(__VA_ARGS__)  //直接传入printf时，这种写法和第三种写法没有区别。

//搭配va_list的format使用
#define my_print2(format, ...) printf(format, __VA_ARGS__)  
#define my_print3(format, ...) printf(format, ##__VA_ARGS__)
```

```c
#define my_print1(...)  printf(__VA_ARGS__)
#define my_print2(format, ...) printf(format, __VA_ARGS__)  
#define my_print3(format, ...) printf(format, ##__VA_ARGS__)
//当可变参数的个数为0时，这里的##起到把前面多余的","去掉的作用,否则会编译出错
int main()
{
    my_print1("111\n");//正确
    my_print1("i=%d,j=%d\n",1,1);//正确

    //my_print2("222\n");//错误！没有可变参数时（即...没有参数对应），宏替换后多了个逗号
    my_print2("i=%d,j=%d\n",1,1);//正确

    my_print3("333\n");//正确。没有可变参数时（即...没有参数对应），宏替换后自动删除逗号
    my_print3("i=%d,j=%d\n",1,1);//正确
 
    return 0;
}
//输出
111
i=1,j=1
    
i=1,j=1
    
333
i=1,j=1
```

#### 第二种用法（传入其他函数）

```c
void myprint_func(int i,int j,const char *format,...){
    printf("i=%d,j=%d\n",i,j);
    va_list valst;
    va_start(valst, format);
    char buf[1024];
    vsnprintf(buf, 1024, format, valst);
    printf("%s\n",buf);
    //printf(__VA_ARGS__);
}
#define myprint1(...) myprint_func(1,1,__VA_ARGS__)
#define myprint3(format,...) myprint_func(1,1,format, ##__VA_ARGS__)
//当可变参数的个数为0时，这里的##起到把前面多余的","去掉的作用,否则会编译出错
int main()
{
    myprint1("myformat--%d--%d\n",100,100,200);
    myprint3("myformat--%d--%d\n",100,100,200);
    
    //my_print3(" ");
    return 0;
}
//传到myprint_func里的可变参数怎么使用？？
//答案，用va_list、va_start、va_arg、va_end
//输出
i=1,j=1
myformat--100--100
i=1,j=1
myformat--100--100
```

- 备注：
  - 这两种写法还是没什么区别。
  - 可能就是`#define myprint3(format,...) myprint_func(1,1,format, ##__VA_ARGS__)`这种写法会明确从变量提示出，第一个参数是format吧
  - `#define myprint1(...) myprint_func(1,1,__VA_ARGS__)`写法太隐晦，不能提示出第一个可变变量写什么。
  - 所以建议还是用`#define my_print3(format, ...) printf(format, ##__VA_ARGS__)`这种格式

### 11.va_list、va_start、va_arg、va_end

VA_LIST的用法： 
（1）首先在函数里定义一具VA_LIST型的变量，这个变量是指向参数的指针； 
（2）然后用VA_START宏初始化变量刚定义的VA_LIST变量； 
（3）然后用VA_ARG返回可变的参数，VA_ARG的第二个参数是你要返回的参数的类型（如果函数有多个可变参数的，依次调用VA_ARG获取各个参数）； 
（4）最后用VA_END宏结束可变参数的获取。

#### 用法1：传入可变参数的个数，用个数来初始化va_list

```c
#include <stdarg.h> 
 
double AveInt(int num,...);//第一个是输入可变参数的数量
 
 void main()
{
   printf("%d\n",AveInt(2,2,3));
   printf("%d\n",AveInt(4,2,4,6,8));
 
   return;
}
 
double AveInt(int num,...)
{
   double ReturnValue=0;
   int i=num;
 
   va_list ap;
   va_start(ap,num);
 
   while(i>0)
   {
       ReturnValue+=va_arg(ap,int);//从可变参数列表ap中，以int方式读取各个参数
       i--;
   }
   va_end(ap); 
   return ReturnValue/=num;
}
```

可变参数的类型和个数完全在该函数中由程序代码控制,它并不能智能地识别不同参数的个数和类型. 也就是说,你想实现智能识别可变参数的话是要通过在自己的程序里作判断来实现的.

#### 用法2：传入可变参数的format，用format一次取出多个可变参数

```c
int my_snprintf(char *s, int size, const char *fmt, ...) //该自定义函数，与系统提供的snprintf()函数相同。
{
    va_list ap;
    int n=0;
    va_start(ap, fmt); //获得可变参数列表
    n=vsnprintf (s, size, fmt, ap); //写入字符串s
    va_end(ap); //释放资源
    return n; //返回写入的字符个数
}

int main()
{
    char str[1024];
    my_snprintf( str, sizeof(str), "%d,%d,%d,%d",5,6,7,8);//假如可变参数是5,6,7,8,9,0,1,2,3。在vsnprintf (s, size, fmt, ap); 中也只会按照format来取，format里只有4个，就只会取出4个，即5,6,7,8
    printf("%s\n",str);
    return 0;
}
```

附例：

```c
int my_snprintf(char *s, int size, const char *fmt, ...) //该自定义函数，与系统提供的snprintf()函数相同。
{
    va_list ap;
    int n=snprintf(s,10,"000");
    cout<<n<<endl;//3
    va_start(ap, fmt); //获得可变参数列表
    n=vsnprintf (s+n, size-n-1, fmt, ap); //写入字符串s
    //只会按照format来取出可变参数，就算可变参数再多，也不会取出多余的。
    cout<<n<<endl;//8。即- 5 , 6 , 7 , 8 
    va_end(ap); //释放资源
    return n; //返回写入的字符个数
}
int main()
{
    char str[20];
    cout<<sizeof(str)<<endl;//20
    my_snprintf( str, sizeof(str), "-%d,%d,%d,%d",5,6,7,8,9,10);
    printf("%s\n",str);
    return 0;
}
输出：
    20
	3
	8
	000-5,6,7,8
```



### 12.localtime()

这个函数内部有个静态变量，所以不可以在多线程环境下使用

```c
  time_t t=time(nullptr);//获取当今时间，秒数。gettimeofday可以获得更精细的时间。

  struct tm* sys_tm=localtime(&t);//返回将秒数转换为年月日的结构体

  //这个返回指针不需要delete,因为返回的是个指向static变量的指针,
  //所以如果你需要连续调用两个localtime的时候应该把第一个先备份一下（如果在后面需要用到的话）
  //但是这也说明了函数localtime()不能在多线程环境中使用。

  struct tm my_tm = *sys_tm;
```

### 13.字符串、stdio、文件常用函数

- **strrchr**

  - `char *strrchr(const char *str, int c)`

  - 该函数返回 str 中最后一次出现字符 c 的位置及之后的字符串。如果未找到该值，则函数返回一个空指针。

  - ```c
    #include <stdio.h>
    #include <string.h>
     
    int main ()
    {
       int len;
       const char str[] = "https://www.runoob.com";
       const char ch = '.';
       char *ret;
     
       ret = strrchr(str, ch);
     
       printf("|%c| 之后的字符串是 - |%s|\n", ch, ret);
       
       return(0);
    }
    //|.| 之后的字符串是 - |.com|
    ```

- **snprintf()**

  - `int snprintf ( char * str, size_t size, const char * format, ... );`

  - 设将可变参数(...)按照 format 格式化成字符串，并将字符串复制到 str 中，size 为要写入的字符的最大数目，超过 size 会被截断。

  - 返回值

    - (1) 如果格式化后的字符串长度小于等于 size，则会把字符串全部复制到 str 中，并给其后添加一个字符串结束符 **\0**；
    - (2) 如果格式化后的字符串长度大于 size，超过 size 的部分会被截断，只将其中的 (size-1) 个字符复制到 str 中，并给其后添加一个字符串结束符 **\0**，返回值为欲写入的字符串长度。

  - ```c
    #include <stdio.h>
     
    int main()
    {
        char buffer[50];
        char* s = "runoobcom";
     
        // 读取字符串并存储在 buffer 中
        int j = snprintf(buffer, 6, "%s\n", s);
     
        // 输出 buffer及字符数
        printf("string:\n%s\ncharacter count = %d\n", buffer, j);
     
        return 0;
    }
    //string:
    //runoo
    //character count = 10
    ```

  - 再比如

    - ```c
      snprintf(log_full_name, 255, "%d_%02d_%02d_%s", my_tm.tm_year + 1900, my_tm.tm_mon + 1, my_tm.tm_mday, file_name);
      ```

    - 构造`"%d_%02d_%02d_%s"`格式的字符串，存到log_full_name这个char数组中，最大存255byte

- **vsnprintf()**

  - 按照format格式，将可变参数列表，按一定格式添加到某个指针处
  - 

- **strncpy()**---strcpy（）加上了一个n最大长度限制

  - ` char *strncpy(char *dest, const char *src, size_t n)`

  - 把 src 所指向的字符串复制到 dest，最多复制 n 个字符。当 src 的长度小于 n 时，dest 的剩余部分将用空字节填充。

  - ```c
    #include <stdio.h>
    #include <string.h>
     
    int main()
    {
       char src[40];
       char dest[12];
      
       memset(dest, '\0', sizeof(dest));
       strcpy(src, "This is runoob.com");
       strncpy(dest, src, 10);
     
       printf("最终的目标字符串： %s\n", dest);
       
       return(0);
    }
    //最终的目标字符串： This is ru
    ```

- **fopen()**

  - ` FILE *fopen(const char *filename, const char *mode) `

  - 使用给定的模式 **mode** 打开 **filename** 所指向的文件。

  - | 模式 | 描述                                                         |
    | :--- | :----------------------------------------------------------- |
    | "r"  | 打开一个用于读取的文件。该文件必须存在。                     |
    | "w"  | 创建一个用于写入的空文件。如果文件名称与已存在的文件相同，则会删除已有文件的内容，文件被视为一个新的空文件。 |
    | "a"  | 追加到一个文件。写操作向文件末尾追加数据。如果文件不存在，则创建文件。 |
    | "r+" | 打开一个用于更新的文件，可读取也可写入。该文件必须存在。     |
    | "w+" | 创建一个用于读写的空文件。                                   |
    | "a+" | 打开一个用于读取和追加的文件。                               |

  - ```c
    #include <stdio.h>
    #include <stdlib.h>
    
    int main()
    {
       FILE * fp;
    
       fp = fopen ("file.txt", "w+");
       fprintf(fp, "%s %s %s %d", "We", "are", "in", 2014);
       
       fclose(fp);
       
       return(0);
    }
    //这将创建一个带有一下内容的文件 file.txt：
    //We are in 2014
    ```

- **fputs**

  - `int fputs(const char *str, FILE *stream) `

  -  把字符串写入到指定的流 stream 中，但不包括空字符。

  - 该函数返回一个非负值，如果发生错误则返回 EOF。

  - ```c
    #include <stdio.h>
    
    int main ()
    {
       FILE *fp;
    
       fp = fopen("file.txt", "w+");
    
       fputs("这是 C 语言。", fp);
       fputs("这是一种系统程序设计语言。", fp);
    
       fclose(fp);
       
       return(0);
    }
    //这将创建文件 file.txt，它的内容如下：
    //这是 C 语言。这是一种系统程序设计语言。
    ```

- **fflush()**

  - ` int fflush(FILE *stream) `
  - 刷新流 stream 的输出缓冲区

### 14.每个使用ET模式的文件描述符都应该是非阻塞的

- 即epoll要对某个文件描述符侦听其上的 可读、可写等事件
- 在使用ET模式时，文件描述符的文件属性必须是非阻塞的。（使用fcntl函数来修改文件描述符的文件属性）
- 对文件描述符设置非阻塞（这跟socket和epoll都没有关系，而是文件的属性，文件属性是阻塞还是非阻塞）
- 只是大多情况下，在epoll中才需要修改这个文件描述符属性为非阻塞，并且这个文件描述符大多情况下都是socket fd。

举例：

- 如果listenfd文件设置为非阻塞的，那么`int connfd = accept(listenfd, (struct sockaddr *)&client_address, &client_addrlength);`就不可能阻塞，而是永远立即返回。如果listenfd文件是阻塞的，那么listen队列上没有新的请求时，accept函数就会阻塞住。
- 如果pipefd[0]文件设置为非阻塞的，那么`ret = recv(pipefd[0], signals, sizeof(signals), 0);//读取pipefd[0]上的数据`就不可能阻塞，而是永远立即返回。如果pipefd[0]文件是阻塞的，那么管道上没有可读数据时，recv函数就会阻塞住。

### 15.strpbck

#### strpbck：在str1中查找匹配上的字符

`char *strpbrk(const char *str1, const char *str2)` 

检索字符串 **str1** 中第一个匹配字符串 **str2** 中字符的字符，不包含空结束字符。也就是说，依次检验字符串 str1 中的字符，当被检验字符在字符串 str2 中也包含时，则停止检验，并返回该字符位置。

- **str1** -- 要被检索的 C 字符串。
- **str2** -- 该字符串包含了要在 str1 中进行匹配的字符列表。

```c
int main{
	char str1[] = "GET yyd.html HTTP/1.1";
	char*ret = (char*)strpbrk(str1, " \t");//匹配的字符串列表是 空格 和 TAB
	printf("第一个匹配的字符是%c\n", *ret);//空格
    *ret++='\0';
    cout<<"str1:"<<str1<<endl;
    cout<<"ret:"<<ret<<endl;	
}
第一个匹配的字符是 (空格)
str1:GET
ret:yyd.html HTTP/1.1
```

#### strcasecmp：忽略大小差异的strcmp

`int strcasecmp (const char *s1, const char *s2);`//若参数s1 和s2 字符串相同则返回0

strcasecmp()用来比较参数s1 和s2 字符串，比较时会自动忽略大小写的差异。strcmp是不会忽略大小写差异的

```c
#include <string.h>
int main(){
    char *a = "aBcDeF";
    char *b = "AbCdEf";
    if(!strcasecmp(a, b))
    printf("%s=%s\n", a, b);
    return 0;
}
执行结果：
aBcDeF=AbCdEf
```

#### strcpn：第一个不在字符串 **str2** 中出现的字符下标

`size_t strspn(const char *str1, const char *str2)`

检索字符串 **str1** 中第一个不在字符串 **str2** 中出现的字符下标。

- **str1** -- 要被检索的 C 字符串。
- **str2** -- 该字符串包含了要在 str1 中进行匹配的字符列表。

```c
#include <stdio.h>
#include <string.h>

int main ()
{
   int len;
   const char str1[] = "DBCAABCDEFG019874";
   const char str2[] = "ABCD";

   len = strspn(str1, str2);

   printf("初始段匹配长度 %d\n", len );
   
   return 0;
}
初始段匹配长度 8
```

#### strchr()：从前先后找

`char *strchr(const char *str, int c)`

在参数 **str** 所指向的字符串中搜索第一次出现字符 **c**（一个无符号字符）的位置。

- **str** -- 要被检索的 C 字符串。
- **c** -- 在 str 中要搜索的字符。

```c
#include <stdio.h>
#include <string.h>

int main ()
{
   char str[] = "www.runoob.com/yyd.html";
   const char ch = '/';
   char *ret;

   ret = (char*)strchr(str, ch);

   printf("|%c| 之后的字符串是 - |%s|\n", ch, ret);
   
   return(0);
}

|/| 之后的字符串是 - |/yyd.html|
```

#### strrchr()：从后向前找

```c
int main(void)
{
    char str[] = "I welcome any ideas from readers， of course.";
    char *lc = strchr(str, 'o');
    printf("strchr： %s\n", lc);
    char *rc = strrchr(str, 'o');
    printf("strrchr： %s\n", rc);
    return 0;
}
示例代码运行结果为：
strchr： ome any ideas from readers， of course.
strrchr： ourse.
```

对于上面的示例代码，strchr 函数是按照从前到后的顺序进行查找，所以得到的结果为“ome any ideas from readers，of course.”; 而 strrchr 函数则相反，它按照从后到前的顺序进行查找，所以得到的结果为“ourse.”。

```c
char text[] = "/home/yangyadong/yydDir/yyd_TinyWebServer/root";
const char *p = strrchr(text, '/');

cout<<text<<endl;
cout<<p<<endl;   

text:/home/yangyadong/yydDir/yyd_TinyWebServer/root
p:/root
```

### 16.stat()函数：获取文件状态

`int stat(const char * file_name, struct stat *buf);`

函数说明：stat()用来将参数file_name 所指的文件状态, 复制到参数buf 所指的结构中。

```c
struct stat {
    dev_t st_dev; //device 文件的设备编号
    ino_t st_ino; //inode 文件的i-node
    mode_t st_mode; //protection 文件的类型和存取的权限
    nlink_t st_nlink; //number of hard links 连到该文件的硬连接数目, 刚建立的文件值为1.
    uid_t st_uid; //user ID of owner 文件所有者的用户识别码
    gid_t st_gid; //group ID of owner 文件所有者的组识别码
    dev_t st_rdev; //device type 若此文件为装置设备文件, 则为其设备编号
    off_t st_size; //total size, in bytes 文件大小, 以字节计算
    unsigned long st_blksize; //blocksize for filesystem I/O 文件系统的I/O 缓冲区大小.
    u nsigned long st_blocks; //number of blocks allocated 占用文件区块的个数, 每一区块大小为512 个字节.
    time_t st_atime; //time of lastaccess 文件最近一次被存取或被执行的时间, 一般只有在用mknod、 utime、read、write 与tructate 时改变.
    time_t st_mtime; //time of last modification 文件最后一次被修改的时间, 一般只有在用mknod、 utime 和write 时才会改变
    time_t st_ctime; //time of last change i-node 最近一次被更改的时间, 此参数会在文件所有者、组、 权限被更改时更新
};
```

stat.st_mode 则定义了下列数种情况：

```
1、S_IFMT 0170000 文件类型的位遮罩
2、S_IFSOCK 0140000 scoket
3、S_IFLNK 0120000 符号连接
4、S_IFREG 0100000 一般文件
5、S_IFBLK 0060000 区块装置
6、S_IFDIR 0040000 目录
7、S_IFCHR 0020000 字符装置
8、S_IFIFO 0010000 先进先出
9、S_ISUID 04000 文件的 (set user-id on execution)位
10、S_ISGID 02000 文件的 (set group-id on execution)位
11、S_ISVTX 01000 文件的sticky 位
12、S_IRUSR (S_IREAD) 00400 文件所有者具可读取权限
13、S_IWUSR (S_IWRITE)00200 文件所有者具可写入权限
14、S_IXUSR (S_IEXEC) 00100 文件所有者具可执行权限
15、S_IRGRP 00040 用户组具可读取权限
16、S_IWGRP 00020 用户组具可写入权限
17、S_IXGRP 00010 用户组具可执行权限
18、S_IROTH 00004 其他用户具可读取权限
19、S_IWOTH 00002 其他用户具可写入权限
20、S_IXOTH 00001 其他用户具可执行权限上述的文件类型在 POSIX 中定义了检查这些类型的宏定义
21、S_ISLNK (st_mode) 判断是否为符号连接
22、S_ISREG (st_mode) 是否为一般文件
23、S_ISDIR (st_mode) 是否为目录
24、S_ISCHR (st_mode) 是否为字符装置文件
25、S_ISBLK (s3e) 是否为先进先出
26、S_ISSOCK (st_mode) 是否为socket 若一目录具有sticky 位 (S_ISVTX), 则表示在此目录下的文件只能 被该文件所有者、此目录所有者或root 来删除或改名.
```



## 2.数据库&设计模式&操作系统

### 1.单例模式（有懒汉、饿汉、双检锁等实现方式）

#### 概述

https://zhuanlan.zhihu.com/p/37469260

- 单例模式
  - 保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享
- 实现思路：私有化它的构造函数，以防止外界创建单例类的对象；使用类的私有静态指针变量指向类的唯一实例（这是指双检锁懒汉或者饿汉模式，局部静态变量的懒汉模式中唯一实例就是局部静态变量），并用一个公有的静态方法（`static single* GetInstance（）`）获取该实例。
- 懒汉模式
  - 即非常懒，不用的时候不去初始化，所以在第一次被使用时才进行初始化；
  - 双检锁、局部静态变量
- 饿汉模式
  - 即迫不及待，在程序运行时立即初始化。
  - 不用锁

#### 单例懒汉--双检锁（线程安全。第一个检保证效率，锁保证线程安全，第二个检也是用来保证线程安全）

```c
class single{
 private:
     //私有静态指针变量指向唯一实例
     static single *p; //注意，这个p切记不可delete。因为它是static的，所有该类对象共享的，虽然它是单例模式。（不会在每个对象中存储，整个类只存储一份）
 
     //静态锁，是由于静态函数只能访问静态成员
     static pthread_mutex_t lock; //static成员的寿命持续到程序结束，自行释放
 								
    								//注意：双检锁模式，p = new single;是new出来的，在主线程中，手动delete【single::getinstance()】返回的指                                            针即可，构造函数设为空就行（如果有其他内存空间需要释放，那么就在构造函数里释放）。
     //私有化构造函数
    single(){
        pthread_mutex_init(&lock, NULL);
    }
   

public:
     ~single(){}//析构函数不能私有化，因为手动调用delete时，会触发析构函数（delete的是main函数中的single*）
    //公有静态方法获取实例
    static single* getinstance();
};

//pthread_mutex_t single::lock=PTHREAD_MUTEX_INITIALIZER;其实在类外写成这样，然后把构造函数里的pthread_mutex_init删了也行
pthread_mutex_t single::lock;//类的静态数据成员必须在类外定义和初始化。这相当于是使用默认构造函数来构造了互斥锁，真正的赋值（初始化）发生在构造函数里
single* single::p = NULL;//类的静态数据成员必须在类外定义和初始化

single* single::getinstance(){//公有静态方法获取实例，方法实现
    if (NULL == p){//说明还没有获取过单例
        pthread_mutex_lock(&lock);//加锁
        if (NULL == p){//检测是否获取过单例
            p = new single;
        }
        pthread_mutex_unlock(&lock);
    }
    return p;
    }
```

- 为什么要用双检测，只检测一次不行吗？
  - 如果把上边的`if(NULL == p)`删了。**依然可以保证线程安全，缺点是：**在每次调用获取实例的方法时，都需要加锁，这**将严重影响程序性能**。即已经获取过一次实例以后，再次调用这个函数时，依然还要加锁，再判断是否已经创建实例。获取过一次实例以后，每次进入依然要加锁，严重影响程序性能。
  - 如果把下边的`if(NULL == p)`删了。**不能保证线程安全。**原因是：判断是否获取过实例在加锁的外围，在多线程环境下，可能有多个线程判断if成功，进入if内，然后因为有锁的保护，将一个线程一个线程地加锁，然后`p =new single`，然后解锁。所有线程都可能执行了一次`p = new single;`，这将造成内存泄露，也就是非线程安全，即多线程环境下不安全。
- 所以双检锁（双重检查+互斥锁）的意思是
  - 第一重检查：保证在获取到单例之后，再次运行该函数时的效率，直接if失败返回
  - 互斥锁：加锁用来保证同一时刻只能有一个线程进入第二次if判断，保证了线程安全（保证同一时刻只能有一个线程进入锁内）。
  - 第二重检查：以防同时有多个线程突破了第一重if，然后挨个获取了互斥锁，进入互斥锁内部。互斥锁内部的这第二重检查，也是用来保证多线程环境下，依然只有一个单例，且不会内存泄露，也就是保证了线程安全。

#### 单例懒汉--C++局部静态变量（线程安全）--严禁手动delete

在C++11中，局部静态变量的访问是线程安全的，使用函数内的局部静态对象，这种方法不用加锁和解锁操作。

```c
 class single{
 private:
     single(){}//私有化构造函数
 public:
     ~single(){}
     static single* getinstance();//公有静态方法获取实例
 
 };

single* single::getinstance(){//公有静态方法获取实例，方法实现。在类内实现也没有问题。
    static single obj;
    return &obj;
}
//使用这种方法在main中获取的实例指针，严禁delete！
```

如果使用C++11之前的标准，还是需要加锁，这里同样给出加锁的版本。

```c
 class single{
 private:
     static pthread_mutex_t lock;
     single(){//私有化构造函数
         pthread_mutex_init(&lock, NULL);
     }
     
 
 public:
    ~single(){}
    static single* getinstance();//公有静态方法获取实例

};

pthread_mutex_t single::lock//类的静态数据成员必须在类外定义和初始化;这相当于是使用默认构造函数来构造了互斥锁，真正的赋值（初始化）发生在构造函数里

single* single::getinstance(){//公有静态方法获取实例，方法实现
    pthread_mutex_lock(&lock);
    static single obj;
    pthread_mutex_unlock(&lock);
    return &obj;
}
```

备注：

- 单例懒汉双检锁
  - 双检锁模式，p = new single;是new出来的。即真正的单例在堆上，在主线程中，需要手动delete `single::getinstance()`返回的指针，构造函数设为空就行（如果有其他内存空间需要释放，那么构造函数就不能为空了。比如需要一个一个的摧毁连接池）。
- 单例懒汉局部静态变量
  - 在局部静态变量实现中，真正的单例是一个局部静态变量，在主线程中，什么都不用做，等待程序结束，自行析构局部静态变量，该单例就会调用析构函数了

#### 饿汉模式（不需要用锁，就可以实现线程安全；但存在隐藏的问题）

- 饿汉模式不需要用锁，就可以实现线程安全。原因在于，在程序运行时就定义了对象，并对其初始化。之后，不管哪个线程调用成员函数getinstance()，都只不过是返回一个对象的指针而已。所以是线程安全的，不需要在获取实例的成员函数中加锁。
- 注意：一上来就初始化，这是通过`single* single::p = new single();`实现的。
  - 懒汉模式里对指针的初始化都是写成这样`single* single::p = NULL;`。 懒汉模式里执行new single()并对静态数据成员指针p 赋值是在getinstance()里。
- 隐藏的问题是：
  - 饿汉模式虽好，但其存在隐藏的问题，在于非局部（non-local）静态对象（函数外的static对象），在不同编译单元中的初始化顺序是未定义的。如果在初始化完成之前调用 getInstance() 方法会返回一个未定义的实例。
  - 即C++对于定义于不同文件内的non-local statci对象的初始化次序并无明确定义。
  - 通俗点说，`single* single::p = new single();`这句话，不知道会在什么时候执行。确实是在程序一开始时，但是跟其他cpp文件内定义的non-loal static对象谁先谁后，并无明确定义。如果你在另一个non-loal static对象的初始化中使用了这个指针p，这将导致不确定行为。

```c
 class single{
 private:
     static single* p;
     single(){}
  	 
 
 public:
     ~single(){}
     static single* getinstance();
 
};

single* single::p = new single();//类的静态数据成员必须在类外定义和初始化

single* single::getinstance(){
    return p;
}

//测试方法
int main(){

    single *p1 = single::getinstance();
    single *p2 = single::getinstance();

    if (p1 == p2)
        cout << "same" << endl;

    system("pause");
    return 0;
}
```

#### 总结

- 单例懒汉--双检锁
  - 类内的私有静态指针变量（成员）指向唯一实例。
  - 在main函数中通过getinstance获取实例后，必须手动执行delete【single::getinstance()】返回的指针
  - 因此这种方式实现的单例懒汉，构造函数是private，析构函数必须是public
- 单例懒汉--C++11局部静态变量
  - 函数中的局部静态变量指向唯一实例
  - 在main函数中通过getinstance获取实例后，**严禁手动执行delete**【single::getinstance()】返回的指针
  - 这种方式实现的单例懒汉，构造函数是private，析构函数可以public可以private。因为不用手动delete
- 单例饿汉--无需锁就可以实现线程安全
  - 类内的私有静态指针变量（成员）指向唯一实例。
  - 在main函数中通过getinstance获取实例后，必须手动执行delete【single::getinstance()】返回的指针
  - 因此这种方式实现的单例懒汉，构造函数是private，析构函数必须是public

### 2.三种线程同步机制

- POSIX信号量

  - 信号量是一种特殊的变量，它只能取自然数值并且只支持两种操作：等待(P)和信号(V)
  - 假设有信号量SV，对其的P、V操作如下：
    - P，如果SV的值大于0，则将其减一；若SV的值为0，则挂起执行（wait）
    - V，如果有其他进行因为等待SV而挂起，则唤醒；若没有，则将SV值加一（post）

- 互斥量（互斥锁、二进制信号量）

  - 互斥锁,也称互斥量,可以保护关键代码段,以确保独占式访问.
  - 当进入关键代码段,获得互斥锁将其加锁；离开关键代码段,唤醒等待该互斥锁的线程.
  - mutex是用来保证线程互斥的，防止不同的线程同时操作同一个共享数据

- 条件变量

  - 条件变量提供了一种线程间的通知机制，当某个共享数据达到某个值时，唤醒等待这个共享数据的线程

  - 如果说【互斥锁】是用于【同步】【线程对共享数据的访问】的话，那么【条件变量】则是用于【在线程之间】【同步】【共享数据的值】。

    - 条件变量就是一个变量，用来自动阻塞一个线程，直到某特殊情况发生为止。
    - 条件变量是用来等待事件
    - 通常条件下变量和互斥锁同时使用

  - //条件变量。相当于一种资源的阻塞队列。

  - //条件变量condition_variable只能和unique_lock一起使用
    //condition.wait()函数都在会阻塞时，自动释放锁权限，即调用unique_lock的成员函数unlock()，以便其他线程能有机会获得锁

  - ```c++
     std::condition_variable con1;//条件变量。相当于一种资源的阻塞队列。
     std::mutex my_mutex;//互斥量，就是最简单的进程互斥。
    std::unique_lock<std::mutex> lk(my_mutex);
    
    con1.wait(lk,[this]()->bool{return counter==2;}); // 阻塞当前线程，直到条件变量被唤醒。并且会释放lk，即解锁，好让其他线程执行。 [this]()->bool{return counter==2;}是Lambda表达式
    
     con1.notify_one();//若任何线程在con1上等待，则调用 notify_one 会解阻塞(唤醒)等待线程之一。
            //换句话说，con1.notify_one()是con1.wait()的唤醒
    
    //伪唤醒，底层设计时没有保证每次执行wait都是由notify唤醒，所以需要自己加个条件（比如lambda表达式）判断一下，是不是真的可以执行了
    ```

### 3.RAII

#### **RAII**

- RAII全称是“Resource Acquisition is Initialization”，直译过来是“资源获取即初始化”.
- 在构造函数中申请分配资源，在析构函数中释放资源。因为C++的语言机制保证了，当一个对象创建的时候，自动调用构造函数，当对象超出作用域的时候会自动调用析构函数。所以，在RAII的指导下，我们应该使用类来管理资源，将资源和对象的生命周期绑定
- **RAII的核心思想是将资源或者状态与对象的生命周期绑定**，通过C++的语言机制，实现资源和状态的安全管理,智能指针是RAII最好的例子

### 4.mysql查询，遍历输出

### 5.生产者-消费者模型

- 其中，process_msg相当于消费者，enqueue_msg相当于生产者，struct msg* workq作为缓冲队列。
- 生产者和消费者是互斥关系，两者对缓冲区访问互斥，同时生产者和消费者又是一个相互协作与同步的关系，只有生产者生产之后，消费者才能消费。

```c
 #include <pthread.h>
 struct msg {
   struct msg *m_next;
   /* value...*/
 };
 
 struct msg* workq;
 pthread_cond_t qready = PTHREAD_COND_INITIALIZER;//条件变量
 pthread_mutex_t qlock = PTHREAD_MUTEX_INITIALIZER;

void process_msg() {
  struct msg* mp;
  for (;;) {
    pthread_mutex_lock(&qlock);//上锁
    //这里需要用while，而不是if
    while (workq == NULL) {
      pthread_cond_wait(&qread, &qlock);//条件变量_wait
    }
    mq = workq;
    workq = mp->m_next;
    pthread_mutex_unlock(&qlock);
    /* now process the message mp */
  }
}

void enqueue_msg(struct msg* mp) {
    pthread_mutex_lock(&qlock);
    mp->m_next = workq;
    workq = mp;
    pthread_mutex_unlock(&qlock);
    /** 此时另外一个线程在signal之前，执行了process_msg，刚好把mp元素拿走*/
    pthread_cond_signal(&qready);//条件变量_唤醒
    /** 此时执行signal, 在pthread_cond_wait等待的线程被唤醒，
        但是mp元素已经被另外一个线程拿走，所以，workq还是NULL ,因此需要继续等待*/
}
```

### 6.条件变量

条件变量提供了一种线程间的通知机制，当某个共享数据达到某个值时,唤醒等待这个共享数据的线程。

#### 基础API

- pthread_cond_init函数，用于初始化条件变量
- pthread_cond_destory函数，销毁条件变量
- pthread_cond_broadcast函数，以广播的方式唤醒**所有**等待目标条件变量的线程
- pthread_cond_wait函数，用于等待目标条件变量。该函数调用时需要传入 **mutex参数(加锁的互斥锁)** ，函数执行时，先把调用线程放入条件变量的请求队列，然后将互斥锁mutex解锁，当函数成功返回为0时，表示重新抢到了互斥锁，互斥锁会再次被锁上， **也就是说函数内部会有一次解锁和加锁操作**.

#### 使用pthread_cond_wait方式如下：

```c
pthread _mutex_lock(&mutex)

while(线程执行的条件是否成立){ //while 资源==false，就去阻塞在信号上等待唤醒
    pthread_cond_wait(&cond, &mutex);
}

pthread_mutex_unlock(&mutex);
```

#### pthread_cond_wait执行后的内部操作分为以下几步：

- 将线程放在条件变量的请求队列后，内部解锁。即在内部解开了mutex，但是还没有退出这个pthread_cond_wait函数，解锁后依然阻塞在函数内部，等待条件变量唤醒。
- 线程等待被pthread_cond_broadcast信号唤醒或者pthread_cond_signal信号唤醒，唤醒后去竞争锁。竞争锁即去竞争锁的使用权，即上锁
- 若竞争到互斥锁，内部再次加锁。没竞争到就排队等着使用锁

#### pthread_cond_wait细节

- 1.pthread_cond_wai前要加锁，为什么要加锁？

  - 多线程访问，为了避免资源竞争，所以要加锁，使得每个线程互斥的访问公有资源。

- 2.pthread_cond_wait内部（条件变量没有被唤醒，要把锁解开，然后继续阻塞在pthread_cond_wait内部等待条件变量唤醒）为什么要解锁？

  - 如果while或者if判断的时候，满足执行条件，线程便会调用pthread_cond_wait阻塞自己，此时它还在持有锁，如果他不解锁，那么其他线程将会无法访问公有资源。
  - 具体到pthread_cond_wait的内部实现，当pthread_cond_wait被调用线程阻塞的时候，pthread_cond_wait会自动释放互斥锁。

- 3.为什么要把调用线程放入条件变量的请求队列后再解锁？

  - 线程是并发执行的，如果在把调用线程A放在等待队列之前，就释放了互斥锁，这就意味着其他线程比如线程B可以获得互斥锁去访问公有资源，这时候线程A所等待的条件改变了，但是它没有被放在等待队列上，导致A忽略了等待条件被满足的信号。
  - 倘若在线程A调用pthread_cond_wait开始，到把A放在等待队列的过程中，都持有互斥锁，其他线程无法得到互斥锁，就不能改变公有资源。
  - 所以这样的操作目的都是，让pthread_cond_wait函数不会错过目标条件变量的任何变化，也不会占着锁导致其他线程无法使用。

- 4.为什么pthread_cond_wait被唤醒后，最后还要自动加锁？

  - 将线程放在条件变量的请求队列后，将其解锁，此时等待被唤醒，若成功竞争到互斥锁，再次加锁。

- 5.为什么判断线程执行的条件用while而不是if？

  - 一般来说，在多线程资源竞争的时候，在一个使用资源的线程里面（消费者）判断资源是否可用，不可用，便调用pthread_cond_wait，在另一个线程里面（生产者）如果判断资源可用的话，则调用pthread_cond_signal发送一个资源可用信号。

  - 在wait成功之后，资源就一定可以被使用么？答案是否定的，如果同时有两个或者两个以上的线程正在等待此资源，wait返回后，资源可能已经被使用了。

  - 再具体点，有可能多个线程都在等待这个资源可用的信号，信号发出后只有一个资源可用，但是有A，B两个线程都在等待，B比较速度快，获得互斥锁，然后加锁，消耗资源，然后解锁，之后A获得互斥锁，但A回去发现资源已经被使用了，它便有两个选择，一个是去访问不存在的资源，另一个就是继续等待，那么继续等待下去的条件就是使用while，要不然使用if的话pthread_cond_wait返回后，就会顺序执行下去。

  - 所以，在这种情况下，应该使用while而不是if:

  - ```
    while(resource == FALSE)
        pthread_cond_wait(&cond, &mutex);
    ```

  - 如果只有一个消费者，那么使用if是可以的。

### 7.管道和socket

- socket
  - `int listenfd = socket(PF_INET, SOCK_STREAM, 0);`
- pipe
  - `ret = socketpair(PF_UNIX, SOCK_STREAM, 0, pipefd);`
- pipe和socket里都是字节流，即TCP连接。只是pipe的上层协议是UNIX的本地协议，而socket的上层一般是IPv4协议。

### 8.给某个进程发信号

查看所有的kill参数

```
kill -l
```

给进程"myserver"发信号

```shell
kill -9 $(ps -ef | grep "myserver" | grep -v "grep" | awk '{print $2}')
```

### 9.文件的阻塞与非阻塞

- 当文件设置为阻塞时。文件为空，read就会阻塞，直到文件有内容才会返回。文件不为空，则会立即返回。
- 当文件设置为非阻塞时。不论文件为不为空，read都会立马返回。
- 因此ET模式下，必须将文件设为非阻塞。
  - 因为：ET模式要求一次触发，采用while(1)循环，一次触发要将文件读取干干净净。此时假如文件又是阻塞的，那么必然导致，在最后一个while读取干净时，read阻塞在最后一次读空文件的操作上，导致永久阻塞，也不可能会打破while循环
  - 我认为，不管是ET还是LT，将文件设置为非阻塞总是没错。为什么要平白让read阻塞在空文件上呢。

### 10.查看Linux最大文件描述符数

- 系统最大打开文件描述符数

  - ```
     cat /proc/sys/fs/file-max
    ```

- 进程最多打开文件描述符数

  - ```
    ulimit -n
    ```


### 11.后台运行程序

```c
nohup ./myserver -u 1> 1.log 2>2.log &
```

- nohup 不挂起的意思
- ./myserver 程序
- -u 代表程序不启用缓存，也就是把输出直接放到log中，没这个参数的话，log文件的生成会有延迟
- 1>1.log  将标准输出，重定向到1.log这个文件中
- 2>2.log 将标准错误输出，重定向2.log这个文件中
- 最后一个& ，代表该命令在后台执行

**命令运行后的提示示例**

```
[1] 2880	*# 代表进程2880中运行。*
```

**查看nohup命令下运行的所有后台进程：**

```
jobs
```

**查看后台运行的所有进程：**

```
ps -aux
```

### 12.执行时需要加sudo的情况

- 占用的是热门端口时，必须得sudo。
- 如果是12345这种，就不用sudo

## 3.项目各模块要点

### 1.数据库连接池类（单例模式）

#### 数据库连接池为什么用链表不用数组

- 链表里放的都是可用连接，每次从连接池申请一个连接，都是拿走的头结点，然后头结点就会被pop出去。
- 用数组的话，那么每次想申请一个连接，都得遍历数组。因为前边的元素可能被占用了，也可能没被占用。即数组里存的是所有连接，每个元素可能被占用，也可能没被占用。而链表里存的就必定是空闲连接，每次申请一个连接，直接拿走头结点。

#### 细节：

- 操作链表时要加锁，比如获取一个连接、释放一个连接。因为链表即连接池被所有线程共享。
- 连接池中剩余的空闲连接数实际上是用信号量来维系的。
- connection_pool是数据库连接池类，它是单例懒汉模式，需要手动执行GetInstance()来获得单例。
- 该单例的实际表现形式是static connection_pool instance即c++局部静态变量。因此无需delete，程序运行结束时自然会收回。
- 在main中流程是：
  - 1.创建数据库连接池类型的单例
    - connection_pool* connPool = connection_pool::GetInstance();
  - 2.调用类内封装好的init函数，进行真正的数据库连接创建
    - connPool->init("localhost", "root", "123", "yourdb", 3306, 8);
    - 最后这个8即表明，池子里创建好8个数据库连接，等待使用。
- 获取一条数据库连接，理论上应该手动执行connection_pool里的GetConnection()函数。将一个条连接释放，还给池子，理论上应该手动执行connection_pool里的ReleaseConnection(MYSQL *conn);函数。为了避免手动申请了一个连接即执行GetConnection()，后忘记手动释放即ReleaseConnection(MYSQL *conn)，因此将获取一条连接这个过程包装成了一个类。申请一条连接，即实例化一个connectionRAII对象，构造函数connectionRAII mysqlcon(&mysql, connPool)里来自动执行GetConnection（），将得到的连接保存在对象内部数据成员一份，返回给&mysql一份。连接的释放（还给池子），即connectionRAII  mysqlcon这个对象消逝时，析构函数自动执行ReleaseConnection(MYSQL *conn);

#### 要点

- 因此：
  - 连接池的建立，由手动执行connection_pool* connPool = connection_pool::GetInstance();来做到。单例模式，保证了该类型只会有唯一的实例。懒汉模式，需要人手动执行才能建立该唯一的实例。
  - 连接池的释放（摧毁池子，即close所有的连接），由connection_pool类内的局部静态变量connection_pool instance消逝时（也就是程序结束时），自动执行析构函数释放。
  - 一条连接的申请（从空闲池里获取一个连接），实例化一个connectionRAII  mysqlcon对象来做到
  - 一条连接的释放（还给池子），由connectionRAII  mysqlcon这个对象自然消逝来做到。
- 这就是RAII的思想：“Resource Acquisition is Initialization”，“资源获取即初始化”
  - 在构造函数中申请分配资源，在析构函数中释放资源。因为C++的语言机制保证了，当一个对象创建的时候，自动调用构造函数，当对象超出作用域的时候会自动调用析构函数。所以，在RAII的指导下，我们应该使用类来管理资源，将资源和对象的生命周期绑定
  - RAII的核心思想是将资源或者状态与对象的生命周期绑定，通过C++的语言机制，实现资源和状态的安全管理，智能指针是RAII最好的例子

#### 使用到的技术

- 链表（STL的list）构建池子（连接池类里的核心数据成员连接池链表）。从池子拿走一个连接即删除头结点，归还一个连接即添加至尾结点后面

  - ```c
    connection_pool的类内成员变量： list<MYSQL *> connList; //连接池
    ```

- 互斥锁，操作链表时要加锁，比如获取一个连接、释放一个连接。因为链表即连接池是被所有线程共享的。

  - ```c
    connection_pool的类内成员变量：connection_pool::locker lock; //互斥锁
    ```

- 信号量，用来表示空闲连接。它理论上应该跟链表的实时长度是一致的，因为在链表里的肯定是可用的连接。

  - 当申请一条连接时，信号量不够了，即没有可用连接了，那就得阻塞在信号量申请即`reserve.wait();`那儿，直到有资源可用

  - ```c
    connection_pool的类内成员变量：connection_pool::sem reserve; //信号量,它的值其实就是当前空闲的连接数。
    ```

- 单例懒汉模式：单例指连接池这个类，只能有唯一一个实例。懒汉是指这个连接池类，在使用前，需要人工执行`connection_pool* connPool = connection_pool::GetInstance();`来创建这个唯一的连接池类实例。单例懒汉模式是使用C++局部静态变量来实现的，C++11规定了local static变量在多线程条件下的初始化行为，要求编译器保证局部静态变量的线程安全性。

  - ```c
    //单例模式。
    //懒汉是指实例在用到的时候才去创建，“比较懒”，用的时候才去检查有没有实例，如果有则返回，没有则新建。
    //在第一次使用这个单例类之前，要手动调用下边这个函数去创建单例。
    connection_pool的类内成员函数：
    connection_pool* connection_pool::GetInstance(){
        static connection_pool instance;//c++局部静态变量。C++11规定了local static变量在多线程条件下的初始化行为，要求编译器保证局部静态变量的线程安全性。
        return &instance;
    }
    ```
    
  - 私有化单例类的构造函数，以防止外界创建单例类的对象；C++局部静态变量指向类的唯一实例，并用一个公有的静态方法（成员函数）获取该实例

- RAII思想：将获取一条数据库连接和将该连接归还给池子这两个操作包装成了，connectionRAII类的实例化和自动析构，即构造函数和析构函数。将一个资源（一条数据库连接）和一个对象（connectionRAII类的一个实例）的生命周期绑定。

  - connectionRAII类可不是单例模式，它肯定可以有多个实例。连接池类connection_pool才是单例模式。

- CGI？暂时没看出来有CGI

### 2.线程池类

#### 半同步/半反应堆模式（半同步半异步是指并发模式，半反应堆是指事件处理模式）

最普通的半同步/半异步模式（只说半同步半异步的并发模式，不讲事件处理模式）

> - 主线程充当异步线程，没说监听什么事件。工作线程是同步线程，没说监听什么事件。
> - 主线程监听到客户请求（可能是监听socket上的连接请求，也可能是连接socket上的其他客户请求）后，将其封装为请求对象并插入请求队列中。
> - 所有工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。
> - 重点：不论半同步/半反应堆也好，他们肯定都统统属于半同步/半异步模式。因为半同步/半异步模式仅仅是并发模式，并发模式配合上事件处理模式，才有了半同步/半反应堆。

半同步/半反应堆工作流程（以Reactor模式为例。即半同步半异步的并发模式+Reactor事件处理模式）

> - 主线程充当异步线程，负责监听所有socket（监听socket和连接socket）上的事件。工作线程是同步线程，不监听任何socket上的事件。
> - 如果监听socket上有可读事件发生，即有新请求到来，主线程接受之以得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件。
> - 如果连接socket上有读写事件发生，即有新的客户请求（当然不是请求连接）或者有数据要发送至客户端。主线程就将该连接socket插入请求队列中。
> - 所有工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。
> - 重点：主线程负责监听所有socket（监听socket和连接socket）上的事件。主线程插入请求队列中的任务是就绪的连接socket（不是完成的），工作线程要自己从socket上读取客户请求和往socket写入服务器应答。

半同步/半反应堆工作流程（以Proactor模式为例。即半同步半异步的并发模式+Proactor事件处理模式）

> - 主线程充当异步线程，负责监听所有socket（监听socket和连接socket）上的事件。工作线程是同步线程，不监听任何socket上的事件。
> - 如果监听socket上有可读事件发生，若有新请求到来，主线程接收之以得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件。
> - 如果连接socket上有读写事件发生，即有新的客户请求（当然不是请求连接）或者有数据要发送至客户端。主线程从socket上接收数据，并将数据封装成请求对象（或者叫任务对象）插入到请求队列中
> - 所有工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。不同的是工作线程从请求队列中取得任务对象之后，即可直接处理之，而无需自己去socket上读数据或者往socket写入数据
> - 重点：主线程负责监听所有socket（监听socket和连接socket）上的事件。主线程插入请求队列中的任务是已经从连接socket上读写好的数据封装成的请求对象（任务对象），工作线程可直接处理之，而无需自己去socket上读数据或者往socket写入数据。

高效的半同步/半异步模式（其实是双异步）

> - 主线程还是异步线程，但是只管理监听socket。工作线程也是异步模式，连接socket由工作线程来管理。
> - 如果监听socket上有可读事件发生，即有新请求到来，主线程接受之以得到新的连接socket，并将该socket连接直接派发给某个工作线程来管理。此后该连接socket上的任何IO操作都由被选中的工作线程来处理，直至客户关闭连接。
>   - 主线程向工作线程派发socket的最简单的方式，是往它和工作线程之间的管道里写数据。工作线程检测到管道上有数据可读时，就分析是否是一个新的客户连接请求到来。如果是，就把该新连接socket上的读写事件注册到自己的epoll内核事件表中。
> - 重点：主线程只负责监听socket上的读写事件。工作线程负责连接socket上的读写事件。

#### 细节

- pthread_create的函数原型中第三个参数的类型为函数指针，指向的线程处理函数参数类型为`(void *)`,若线程函数为类成员函数，则this指针会作为默认的参数被传进函数中，从而和线程函数参数`(void*)`不能匹配，不能通过编译。静态成员函数就没有这个问题，里面没有this指针。
- 线程的释放：是靠my_stop标志，让线程执行的worker函数（其实是run函数）打破while循环，自然结束而释放的。而不是靠`delete[] my_threads;`，这只是把数组删了，其实只是把获取每个子线程的方法（即pthread_t）删了，这个数组删了，就无法获得每个子线程了。结束子线程是靠将my_stop设置为true，让子线程自然执行完毕而结束子线程的。而不是靠这个delete[]。
  - 原理是：脱离线程在退出时（我们让它自然退出）将自行释放其占用的系统资源，而无需人工结束线程。
  - 因此并不会使用`pthread_join`或者`pthread_cancel`
- 因为用的是半同步半反应堆（Reactor）模式，因此主线程就是异步线程。而线程池中的都是工作线程（同步线程）
- sem my_queuestat其实是信号量，它代表了请求队列上有多少待处理任务。
- locker my_queuelocker这个互斥锁是保护请求队列（链表）的互斥锁。线程池不需要保护。
  - 线程池里每个线程都一直在忙碌着做自己的事（也可能是在阻塞等待），没有拿取一个线程和归还线程的操作。从创建线程起，每个线程都在忙碌的工作着（通过信号量my_queuestat来竞争【请求队列中的待处理任务】）。
  - 备注：连接池有拿去一个连接和释放一个连接至连接池的操作。线程池并没有。
- 按原作者写法，子线程`while(!my_stop){}`。在请求队列为空时，关闭服务器，设置my_stop=true。这根本就不能是线程池各个子线程执行完毕，因为子线程会阻塞在 `my_queuestat.wait();`。这样的情况下，子线程退出并不是因为顺利执行完毕，自行退出，而是进程被关闭了，强制收回，这显然不好，因为线程可能还没有做完手中的活儿，就被强制退出了。
  - 因此我加了改进方案，`thread_pool<T>::~thread_pool(){}`即线程池析构函数里。（这个析构函数是会被delete调用的，线程池对象是new出来的）。在析构函数里，先再往请求队列上加入THREAD_NUMBER个空请求（我称之为冲刷队列的操作），以保证每个子线程可以从`my_queuestat.wait();`脱离阻塞态，顺利进入下一轮while时打破循环，顺利使得线程执行完毕自然退出。
    - 我除了在析构函数里加入了冲刷队列的操作，还加入了`pthread_join(my_threads[i],&res);`等待线程池中各个子线程退出，才会从析构函数返回。即delete threadPool;这个操作会阻塞一会儿，直到所有子线程退出。
  - 如果服务器要关闭时，请求队列里还有大量请求，那么加入THREAD_NUMBER个空请求也不会有问题，即使请求队列满了，没有把空请求加进去也没有关系。因为请求队列里还有大量请求时，子线程肯定不会阻塞在`my_queuestat.wait();`，每个子线程忙完当前的任务，进入下一轮while时，便会由于my_stop=true而打破循环，顺利使得线程执行完毕自然退出。
- 原作者把线程池中的各个子线程都设置为了脱离线程，即`// ret=pthread_detach(my_threads[i]);//设置该线程为脱离线程`。**我把各个子线程设置为了可回收线程，即主线程会pthread_join各个子线程，以等待各个子线程顺利退出。**
- 在本项目中，http_conn是任务类型，即请求队列里存放着的类型。很显然是Proactor事件处理模式，因为主线程插入请求队列中的任务是已经从连接socket上读写好的数据封装成的请求对象（任务对象），工作线程可直接处理之，工作线程无需自己去读socket

#### 用到的技术

- 模板类（线程池类）

  - ```c
    template<class T> 
    class thread_pool{}
    ```

  - 线程池类，定义为模板类是为了代码复用。模板参数T是任务类。T即往请求队列上放的任务类型。可以是int类型，可以是http_conn类型，任意。只要你把线程池中每个工作线程真正运行的函数run（）写对，能处理各个任务类就行（当然，我写的run肯定是针对着http_conn来写的。并没有考虑其他的任务类型）。

  - 该模板类对于T类型的使用，几乎仅仅在

    - ```
      template<class T>
      void thread_pool<T>::run(){}
      ```

    - 中。比如T是http_conn类，run函数里会直接使用

    - ```c
      T *request = m_workqueue.front();
       request->process();//这个process函数显然是http_conn类专有的
      ```

- 异常

  - ```c
        //-------------创建线程池--------------------
        thread_pool<int>* threadPool = nullptr;//在try块里声明的新变量，一出try块儿就消亡了。所以得new
        try{
            threadPool=new thread_pool<int>(connPool,THREAD_NUMBER,MAX_REQUESTS_IN_REQUESQUEUE);
        }catch(exception &e){
            cout << "创建线程池时发生异常: " << e.what() << endl;
            return 1;
        }catch(...)//捕获其余任何异常
        {
            cout << "创建线程池时发生unknown异常" << endl;
            return 1;//直接进程退出，什么资源都释放了
        }
    ```

  - 线程池类的构造函数中可能抛出std::exception()类型的异常。可能的错误类型有：【"thread_number或者max_requests参数异常"】、【("线程池数组分配内存异常")】、【pthread_create时创建第i个线程时创建发生异常】。然后就在构造函数中人工throw异常。在main中构建线程池时来try catch捕获异常

- 数组（线程池类里的核心数据成员线程池数组）

  - `template<class T> pthread_t *thread_pool<T>::my_threads//描述线程池的数组，其大小为my_thread_number`
  - 注意，线程池数组中包含THREAD_NUMBER个元素，每个元素对应一个线程的ID，即整型pthread_t 
  - 线程池是数组，跟连接池链表不一样。因为我构建的线程池没有【从线程池取一个线程和往线程池归还一个线程】这样的操作。而数据库连接池有【从连接池池取一个连接和往连接池归还一个连接】这样的操作，因此数据库连接池必须用链表，以方便的取出和加入。
  - 总结：连接池和线程池的区别
    - 连接池时链表。线程池是数组。
    - 数据库连接池有【从连接池池取一个连接和往连接池归还一个连接】这样的操作，用链表这种数据结构更合适。线程池没有【从线程池取一个线程和往线程池归还一个线程】这样的操作，用数组更合适。
    - 思考：为什么线程池没有【从线程池取一个线程和往线程池归还一个线程】这样的操作呢？因为线程池里的线程，都永远是“忙碌”状态，就没有空闲的。
    - 连接池里的的都是空闲连接，忙碌的连接已经被从链表中删除出队了。而线程池里的线程，都永远是“忙碌”状态，因为使用了信号量wait机制，让他们阻塞在代表“请求队列中任务数目”的信号量上（或者说叫每个线程都睡眠在请求队列上），线程池中的所有线程会自动地去竞争（通过信号量wait机制）请求队列上每个任务的接管权。

- 链表（请求队列或者说叫工作队列）

  - `std::list<T *> my_workqueue; //请求队列`
  - 虽然明面上叫请求队列，我还是用链表来实现（stl的链表类里有队列的所有操作啊！跟队列没啥区别）。
  - 请求队列里存放的元素其实就是需要线程池中的子线程来处理的一个一个的任务。
  -  在主线程中通过`threadPool->append(xxx);`的操作来往线程池对象里维护的请求队列添加任务。

- 互斥锁（用来保护请求队列，即链表。不是用来保护线程池即数组的，线程池里每个线程都一直在忙碌着做自己的事（也可能是在阻塞等待），没有拿取和归还线程的操作）

  - `locker my_queuelocker;//保护请求队列（链表）的互斥锁。线程池不需要保护`
  - 互斥锁是用来保护请求队列，即链表的。而不是用来保护线程池即数组的，线程池里每个线程都一直在忙碌着做自己的事（也可能是在阻塞等待），没有拿取和归还线程的操作，因此线程池数组根本就不用保护。
  - 反而是请求队列，主线程每次往请求队列里添加任务`threadPool->append(xxx);`。或者子线程从请求队列上取走任务，凡是涉及到请求队列上元素变动的，都需要加锁。理由也很简单，请求队列是被所有线程共享的。不论主线程、子线程来操作它，都应该加锁。

- 信号量（代表请求队列中任务的数量）

  - `sem my_queuestat;//信号量，是否有任务需要处理。也代表了请求队列中有多少任务需要处理 `
  - 线程池里的线程，都永远是“忙碌”状态，因为使用了信号量wait机制，让他们阻塞在代表“请求队列中任务数目”的信号量上（或者说叫每个线程都睡眠在请求队列上），线程池中的所有线程会自动地去竞争（通过信号量wait机制）请求队列上每个任务的接管权。

- 线程的pthread_create、pthread_join、pthread_detach

  - 在线程池类的构造函数中，`int ret=pthread_create(&(my_threads[i]),nullptr,worker,this);`创建每个子线程
  - 在线程池类的析构函数中，设置线程退出标志threadPool->my_stop来使得各个子线程打破while循环，自然退出。析构函数中设置my_stop为false后，pthread_join各个子线程，等待他们顺利退出。
  - pthread_detach没有使用，跟pthread_join是完全相反的两码事。pthread_detach设置的线程叫脱离线程，脱离线程不可以被pthread_join，只有可回收线程才能被pthread_join。

- 冲刷请求队列机制

  - 如果在请求队列为空时，我去停止服务器。想要在线程池类的析构函数中，设置线程退出标志threadPool->my_stop来使得各个子线程打破while循环，自然退出。这是不可能的。因为各个子线程都阻塞在信号量的获取`my_queuestat.wait();`上了
  - 因此我在线程池类的析构函数中，设置线程退出标志threadPool->my_stop为true之后，往请求队列上又放置了THREAD_NUMBER个空请求，以保证各个子线程顺利打破while，自然执行结束

- 半同步/半反应堆模式（半同步半异步是指并发模式，半反应堆是指事件处理模式）

  - 线程充当异步线程，负责监听所有socket（监听socket和连接socket）上的事件。工作线程是同步线程，不监听任何socket上的事件。
  - 所有工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。
  - 我写的这个线程池类，可以是半同步/半反应堆（Reactor），也可以是半同步/半反应堆（Proactor）。关键就在于模板类中的任务类型T
    - Reactor：主线程插入请求队列中的任务，即T类型对象是就绪的连接socket（不是完成的），工作线程要自己从socket上读取客户请求和往socket写入服务器应答。
    - Proactor：主线程插入请求队列中的任务，即T类型对象是已经从连接socket上读写好的数据封装成的请求对象（任务对象），工作线程可直接处理之，而无需自己去socket上读数据或者往socket写入数据。

### 3.日志系统--阻塞队列类（封装了生产者消费者模式）

#### 简介

- **`日志`**，由服务器自动创建，并记录运行状态，错误信息，访问数据的文件。
  - **`同步日志`**，日志写入函数与工作线程串行执行，由于涉及到I/O操作，当单条日志比较大的时候，同步模式会阻塞整个处理流程，服务器所能处理的并发能力将有所下降，尤其是在峰值的时候，写日志可能成为系统的瓶颈。
  - **`异步日志`**，将所写的日志内容先存入**阻塞队列**，写线程从**阻塞队列**中取出内容，写入日志。

- 阻塞队列类中封装了生产者-消费者模型，其中push成员是生产者，pop成员是消费者。
- 阻塞队列中，~~使用了循环数组实现了队列~~，作为两者共享缓冲区，当然了，队列也可以使用STL中的queue。
  - 我是用的是list
- **阻塞队列实际就是在队列的基础上加上了阻塞操作，当队列为空时，出队操作就会被阻塞，因为队列里没有数据，直到队列里有数据之后才能返回；当队列满的时候，入队操作就会被阻塞，直到队列中有空闲的空间时再执行入队操作。**我们可以用阻塞队列很容易的实现一个”生产者-消费者“模型，这样我们可以有效的控制生产和消费的速度。当生产者生产的过快时，队列很快就满了，这个时候生产者就阻塞等待，直到消费者消费了，生产者才会被唤醒继续生产。反之消费者消费过快时也同样被阻塞。不仅如此，我们还可以通过调整生产者和消费者的个数，来实现生产和消费的供需平衡。

#### 用到的技术

- 链表（阻塞队列主体）
  - `list<T> my_blockqueue`
- 互斥锁（访问链表要加锁）
  - 用来保护队列` list<T> my_blockqueue`的多线程安全
- 条件变量（生产者消费者）
  - 当消费者消费过快时，队列很快就空了，这个时候消费者就阻塞等待（pop函数里阻塞等待my_cond.wait或者等待超时后返回my_cond.timewait），直到生产者生产了，消费者才会被唤醒继续消费
    - 在作者的实现中，只有一个条件变量。就是消费者就阻塞等待，被生产者使用条件变量唤醒，继续消费。
  - 当生产者生产的过快时，队列很快就满了，这个时候~~生产者就阻塞等待~~（生产者就添加失败，即push函数直接返回false），~~直到消费者消费了，生产者才会被唤醒继续生产~~。
    - 在作者的实现中，只有一个条件变量。并没有生产者被阻塞，然后被消费者唤醒继续生产的功能。
    - 也就是只有单向阻塞。消费者从空队列里取东西会阻塞，生产者往满队列里放东西会直接返回false，而不会阻塞。
- 生产者消费者模式
  - 生产者线程执行：`block_queue<T>::push`。线程安全地往阻塞队列里放东西。
  - 消费者线程执行：`block_queue<T>::pop`。线程安全地从阻塞队列里取东西。
- 备注：
  - 什么叫阻塞队列？就是普通的队列加上了阻塞操作。
    - 当队列为空时，从队列中获取元素的线程将会被挂起（阻塞）；当队列是满时，往队列里添加元素的线程将会挂起（阻塞）。
  - 阻塞操作怎么实现的？用条件变量。
    - 当队列为空时，消费者还要从队列取东西（pop），那么消费者线程就会阻塞在条件变量上（`my_cond.wait(my_mutex.get());`）。当生产者又生产了新的东西放入（push）队列时（队列上有东西了，可以消费了，但是所有消费者线程都在阻塞着呢，所以必须得唤醒消费者），所以就会执行`my_cond.broadcast()`，唤醒所有阻塞在条件变量my_cond上的消费者线程来从队列取东西
    - ~~当队列满了时，生产者还要往队列里放东西（push），那么生产者线程就会阻塞在另一个条件变量`（my_cond2.wait(my_mutex.get());`上。当消费者从队列取走（pop）一个东西时（队列不满了，可以往队列上放东西了，但是所以生产者线程都在阻塞着呢，所以必须得唤醒生产），所以就会执行`my_cond2.broadcast()`，唤醒所有阻塞在条件变量my_cond2上的生产者线程往队列放东西~~
      - （没实现这个功能，讲道理应该实现的）

### 4.日志系统--日志类（单例模式）

#### 简介

- 人工缓存区干嘛用的？

  - ` char* my_buf`实际上是在init里`new char[my_log_buf_size]`，默认值有8192个byte
  - 人工缓冲区是用来，存放格式化以后的日志记录的。
  - 格式化是什么？
    - 比如给每一条记录前边加上时间戳、类型（info、warn）等等，更方便在日志文件中观察每条日志记录

- 怎么添加日志记录

  - ```c
    //这四个宏定义在其他文件中使用，主要用于不同类型的日志输出
    #define LOG_DEBUG(format, ...) Log::get_instance()->write_log(0, format, ##__VA_ARGS__)
    #define LOG_INFO(format, ...) Log::get_instance()->write_log(1, format, ##__VA_ARGS__)
    #define LOG_WARN(format, ...) Log::get_instance()->write_log(2, format, ##__VA_ARGS__)
    #define LOG_ERROR(format, ...) Log::get_instance()->write_log(3, format, ##__VA_ARGS__)
    //日志类中的方法都不会被其他程序直接调用，末尾的四个可变参数宏提供了其他程序的调用方法。
    //前述方法对日志等级进行分类，包括DEBUG，INFO，WARN和ERROR四种级别的日志。
    ```

  - 本质上就是调用write_log（）函数，添加一条记录。记录的内容就是`##__VA_ARGS__`

  - 举例：

    - `LOG_INFO("-------------------开启/重启服务器了-----------------------");`
    - `LOG_DEBUG("TestDebug,%d-%d-%d",1,2,3,4);`//可变参数比format里多，多的直接就忽略了

#### 用到的技术

- 单例模式
  - 日志类是个单例类，用的依旧是单例懒汉的c++局部变量实现。
- 阻塞队列
  - 里边是一条条的日志记录。
  - 只有异步日志模式才会用的到。异步日志模式的原理是，主线程（相对于异步线程是主线程，其实是工作线程）往阻塞队列上push一条条的记录；异步线程是从阻塞队列上pop一条条的记录，然后异步线程紧接着fputs到日志文件中
    - 在我的实现中，只有一个异步线程，理论上也可以多个
  - 主线程往阻塞队列上push，因此主线程相当于生产者；异步线程从阻塞队列上pop，异步线程相当于消费者
- 同步日志/异步日志
  - 异步模式下，异步体现在有一个额外的线程去从阻塞队列取一条日志记录string，然后写入日志文件。有且仅有一个异步线程（理论上也可以多个，不过好像多了也没什么好处，因为往文件里fputs也要加锁的，有一个线程不断去取记录，fputs到文件，就足够了，多个线程在这种不断地加锁解锁中，好像没啥速度提升），相当于一个消费者线程，不断地去阻塞队列上取出记录，然后fputs到文件上。该异步线程是在init函数中pthread_create的
  - 同步模式下。同步体现在主线程产生日志文件后，自己直接fputs到文件，没有阻塞队列，也没有额外的异步线程。
  - 同步和异步模式，主线程都要执行write_log函数。
    - 区别在于异步模式时，主线程执行write_log时，是往阻塞队列放一条条的记录，异步线程去阻塞队列取记录，然后异步线程fputs到文件。
    - 同步模式时，主线程执行write_log时，直接主线程自己fputs到文件。
- 互斥锁
  - 1.用来保护对文件中写入这个操作的线程安全。或者更精确的说法是，保护文件这个流的输出缓冲区的线程安全。
    - 例如`fputs(single_log.c_str(), my_fp);//把字符串single_log写入到指定的流 my_fp 中，但不包括空字符。`之前要加锁
    - 例如`fflush(my_fp);`刷新输出缓冲区之前，也要加锁
  - 2.用来保护类内人工缓冲区（这里其实是暂存格式化以后的结果，准备放入队列或者直接写入文件）
    - 例如：write_log函数内，修改`char* my_buf;//人工日志缓冲区`时，要加锁。
- `_VA_ARGS_`可变参数宏
  - 两种用法：
    - va_list、va_start、vsnprintf、va_end  （不需要传入参数个数，需要传入format，va_start时按format从可变参数中读取内容）
    - va_list、va_start、va_arg、va_end   （需要传入参数个数，va_start按个数从从可变参数中读取内容）
  - 本项目用的是`va_list、va_start、vsnprintf、va_end`
  - 这是用来format日志记录的。
  - 举例：
    - `LOG_INFO("-------------------开启/重启服务器了-----------------------");`
    - `LOG_DEBUG("TestDebug,%d-%d-%d",1,2,3,4);`//可变参数比format里多，多的直接就忽略了
  - 首先声明一个va_list；然后用va_start(va_list , format)来初始化；vsnprintf来将格式化后的文本复制到字符数组中；va_end释放资源
- 流程图：
  - ![image-20210329164610144](http://pichost.yangyadong.site/img/image-20210329164610144.png)

### 5.http连接处理---http_conn类

#### 简介

- 其实主状态机只是记录当前的http请求，分析到什么阶段了：是处于分析请求行阶段呢，还是处于分析首部行阶段呢，还是处于分析实体主体阶段呢
  - 主状态机这三个状态是有很显然的顺序的，一定是 请求行-->首部行-->实体主体
- 从状态机的状态，是为了服务于process_read函数中，`while(line_status = parse_line()) == LINE_OK)`保证进入while时，读出了一个完整的行。
- 每使用line_status读出一个完整的行，就要判断当前主状态机状态。
  - 主状态机处于分析请求行阶段，就要调用parse_request_line，以分析请求行的格式来处理该行数据。
  - 主状态机处于分析首部行阶段阶段，就要调用parse_headers，以分析首部行的格式来处理该行数据。
  - 主状态机处于分析实体主题阶段，就要调用parse_content，以分析实体主体的格式来处理该行数据。
- 主状态机的状态是由对象内的变量：m_check_state在维护。
- 而从状态机的状态，是入口函数process_read里的一个局部变量line_status在维护。
- 主状态机的状态转移:
  - 初始化时，主状态是分析请求行状态（CHECK_STATE_REQUESTLINE）
  - 由于请求行一定只有一行，因此执行过一次分析请求行即`parse_request_line`之后，那么必然就该分析首部行了。在`parse_request_line`函数内部直接就把主状态转移到了分析首部行状态(CHECK_STATE_HEADER)。
  - 请求行有一行空行，仅有\r\n，因此一旦见到了一个空行，那就必然标志着请求行结束了。
    - 如果在请求行中解析到了比如："Content-length: 100"类似的内容，这说明还有实体主体部分。在`parse_headers`函数中将主状态转移到了分析实体主体状态(parse_content)。
    - 如果如果在请求行中没有解析比如："Content-length: 100"类似的内容。说明http请求分析结束了，只有请求行和首部行，没有实体主体。那么就不用切状态了，结束了。
- 从状态机的状态转移：
  - 一开始时LINE_OK、LINE_OPEN都有可能（这取决于上一次m_read_buf中数据的状态）
    - 一定没可能是line_bad。出现line_bad时，本次http请求分析就彻底结束了，不再往后解析了
  - 本次parse_line开始
  - 如果上一次残存的状态是LINE_OK。说明上一次读取很正常
    - 那么本次parse_line读取到\r\n时，本次parse_line结束。返回line_ok
    - 如果次parse_line出现了一个单独的\r或者\n，那么返回line_bad
    - 如果parse_line到最后一个字符刚好是\r，说明数据不完整。或者是当前buffer中的数据都读完了，也没读到\r。那么返回line_open，等待更多数据才能判断
  - 如果上一次残存的状态是LINE_open。说明上一次数据不完整
    - 那么跟LINE_OK一样。重头开始分析就完事了。
  - （以上是基于代码的理解，基于文字描述的理解按一下说法）
    - 从状态机的初始状态是LINE_OK，其原始驱动力来自于m_read_buf中新到达的用户数据。在read_once中，我们循环调用recv函数往m_read_buf中读入客户数据。每次成功读取数据后，我们就调用process_read函数来分析新读入的数据。process_read函数首先要做的就是调用parse_line函数来获取一个行。
    - ![image-20210413154541204](http://pichost.yangyadong.site/img/image-20210413154541204.png)
- http_conn内的mysql什么时候初始化的？
  - http_conn被主线程扔到请求队列后。**当子线程从请求队列中取下来该请求时**，同时给该请求配备一条数据库连接，即初始化http_conn内的mysql连接。子线程将该请求处理完毕时，同时断开数据库连接。
  - 每个http_conn都被分配了一个mysql连接。然后才开始子线程进行process()函数的
  - 只有生成响应报文的时候，才有可能需要mysql连接。即在process_read里的do_request函数中
    - process_read中遇到解析失败的情况，就不会进入do_request
    - 只有在process_read中解析请求报文完整且无误时（就算解析结果是404，说明人家的请求报文也是完整且无误的），才会进入do_request。do_request是用于修改m_real_file和m_file_address参数的。（根据不同的post或者get参数，准备返回不同的页面）。换句话说，do_request就是用于生产请求报文的

#### 备注

- 访问网页时

  - 除了

    - ```
      GET / HTTP/1.1
      Host: 192.168.80.131:12345
      User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0
      Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
      Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2
      Accept-Encoding: gzip, deflate
      Connection: keep-alive
      Upgrade-Insecure-Requests: 1
      Cache-Control: max-age=0
      ```

  - 还会有带一个（获取网页图标）

    - ```
      GET /favicon.ico HTTP/1.1
      Host: 192.168.80.131:12345
      User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0
      Accept: image/webp,*/*
      Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2
      Accept-Encoding: gzip, deflate
      Connection: keep-alive
      Referer: http://192.168.80.131:12345/
      ```

  - 第二个请求跟第一个请求占用同一个socket fd。并且，获取到图标后，会在本地缓存，以后访问这个网站时，就不用发第二个GET请求了

#### 用到的技术

- 有限状态机（主从状态机）
  - 主状态机：标志着process_read中每次读出一个完整的行，该用什么格式来分析该行。
    - 是按照请求行格式、首部行格式、实体主体格式？
    - 因为http响应报文中，一定是请求行、首部行、实体主体的顺序排列的。因此这三个主状态可以按顺序切换
    - 主状态一上来默认就是请求行。当读完第一行时，即第一次遇到\r\n时，主状态就可以从请求行切换到首部行了。（原因是请求行一定只有一行）
    - 当遇到一个空行时，就意味着主状态就可以从首部行切换到实体主体了。（原因是首部行的结束一定有一个空行）
    - 实体主体的结束，是按照（首部行中解析出的报文长度来的，读够相应的byte数，就自行结束了）
  - 从状态机：标志着是否读出了完整的一个行。
    - 读取到一个\r\n时，就从LINE_OPEN切换到LINE_OK。标志着读出了一个完整的行
    - 有新数据到达时，就从LINE_OK切换到LINE_OPEN，去读完整的一行去。
    - 当发现语法问题（比如只出现了一个独立的\r或者一个独立的\n），那就从LINE_OPEN切换到LINE_BAD，标志着HTTP请求报文中有语法问题。
  - 总结：
    - 从状态机的目的是保证parse_line函数读到一个完整的行，供给process_read函数来分析该行数据。
    - 主状态机的目的是，每次不是parse_line每次得到一行完整的数据吗，以什么样的解析格式来解析该行数据。
- io向量机制iovec：` struct iovec m_iv[2]`
  - 当对客户的请求报文解析后，如果解析结果是：INTERNAL_ERROR服务器内部错误、BAD_REQUEST HTTP请求报文有语法错误或请求资源为目录、FORBIDDEN_REQUEST请求资源禁止访问，没有读取权限等等。那么就只用发送一个简单的响应报文回去就行，实体主体就简单的写上一句短语就行（不写都行）。
    - 此时的iovec就只有1个。
    - m_iv[0]里记录了 要发送的响应报文的内存地址(其实就是m_write_buf的地址) 和 要发送的数据长度
  - 但是当客户的请求报文解析后，如果解析结果是：FILE_REQUEST时。即正确解析出了请求的文件，那么就需要发送HTTP请求报文（200），以及对应的html文件给客户。
    - 此时的iovec就有2个。
    - m_iv[0]里记录了 要发送的响应报文的内存地址(其实就是m_write_buf的地址) 和 要发送的数据长度
    - m_iv[1]里记录了 要发送的响应报文的实体主体（其实就是映射到内中的html文件的）内存地址和 要发送的数据长度
- `int m_iv_count`来标志着m_iv数组里的有效元素有几个
  - 因为`struct iovec m_iv[2]`数组已经写死了。m_iv_count来标志着m_iv数组里的有效元素有几个。即标志要往connfd上写几个文件
  - 1个说明，直接把缓存m_write_buf里的发走就行。
  - 2个说明，除了发m_write_buf里的内容，还得发mmap到内存的文件内容（m_file_address），即_iv[1].iov_base指向的内容
- 

### 6.主线程（IO处理单元）中的IO复用

#### 1.setnonblocking

- 每个使用ET模式的文件描述符都应该是非阻塞的
- 即epoll要对某个文件描述符侦听其上的 可读、可写等事件
- 在使用ET模式时，文件描述符的文件属性必须是非阻塞的。（使用fcntl函数来修改文件描述符的文件属性为nonblock）
- 对文件描述符设置非阻塞（这跟socket和epoll都没有关系，而是文件的属性，文件属性是阻塞还是非阻塞）
- 只是大多情况下，在epoll中才需要修改这个文件描述符属性为非阻塞，并且这个文件描述符大多情况下都是socket fd。

#### 2.内核事件表

- 向内核事件表中注册"listenfd"这个socket文件的 可读事件、以及socket连接被对方关闭事件，非oneshot。（ET还是LT是由全局变量ENABLE_ET控制的）
  - "listendf"这个socket文件绑定的地址是0.0.0.0:port
- 向内核事件表中注册"pipefd[0]"这个管道读端文件 的 可读事件、以及socket连接被对方关闭事件，非oneshot。（ET还是LT是由全局变量ENABLE_ET控制的）---------**"pipefd[0]"这个管道读端文件 的 可读事件 完全等价于有 信号触发**
  - pipefd是个二元素的数组，pipefd[0]被当做读端，pipefd[1]被当做写端
  - 而pipefd[1]什么情况下才会写入数据，导致pipefd[0]可读呢？
    - 答：有信号时！比如alarm(TIMESLOT)周期性触发SIGALRM信号，比如ctrl+c的SIGINT信号。
    - 前提是调用了addsig，为这些信号设置了信号处理函数。信号处理函数里人工设定的，一旦遇到这些信号，就往pipep[1]写入数据（就是信号值，char型）。
  - 这就是统一事件源，将信号也当做事件来处理了。用管道实现，信号事件表现的跟IO事件无异
- 每一个内核事件表中监听的事件，都可以独立地设置是ET还是LT。ET还是LT，除了与EPOLLET有关，人工处理事件时，也得对应的上。

#### 3.统一事件源

统一事件源的好处：以前信号事件的处理要在信号处理函数中执行。现在统一后，所有的事件都在主函数（IO处理单元）中执行。（信号处理函数其实还必须有，只是充当一个摆设了，真正对信号的处理在主函数中）

- 信号（pipefd[0]可读）：
  - 有信号触发时，就在信号处理函数中`send(pipefd[1], (char *)&msg, 1, 0);`。即将信号值发送给管道。
  - 内核事件表监控管道pipe[0]的可读事件，一旦它可读，就触发epoll_wait，然后在epoll_wait之后处理各个就绪的事件时，再区分到底是IO事件，还是信号（即等价于pipe[0]可读）触发，还是TCP连接被对方关闭事件，还是客户连接上接收到了新的数据
  - 区分出信号（即等价于pipe[0]可读）触发事件后，还可以继续区分，到底是哪个信号触发。是SIGALRM还是SIGINT、SIGTERM等，以使得程序做出不同的反应。
  - 一次从管道读出来1024个byte，我认为这肯定是一次读干净了。所以pipefd[0]可读事件，我设置成了ET。
- IO（listenfd可读）：
  - 新的客户连接的connfd，设置为了oneshot
  - 原因是：即使使用ET模式，一个socket上的某个事件还是可能被触发多次，这在并发程序中就会引起一个问题。比如一个线程，在读取完某个socket上的数据后开始处理这些数据，而在数据的处理过程中该socket上又有新数据可读（EPOLLIN再次被触发），此时另外一个线程被唤醒来读取这些新的数据。于是就出现了两个线程同时操作一个socket的局面。使用EPOLLONESHOT就可以保证一个socket连接在任一时刻都只被一个线程处理。
  - （当子线程在处理这个http连接时，该connfd又可读了，那么epoll就不会触发！所以主线程上不会得到这个可读事件，直到子线程处理完了）
    - 凭什么呢？因为oneshot只会触发一次，需要重置才能再次触发。子线程没处理完时，它就不重置。所以你主线程永远也不会在子线程处理时，又在该connfd上读出来新数据。
- IO（客户连接上接收到新数据）
- IO（要给客户连接发送新数据）
- IO（TCP连接被对方关闭了）

#### 4.LT ET

- ET一定会有个while(1)。因为一次触发就要处理干净。
  - ET要求文件属性必须是非阻塞的
- LT一般没有while循环。就处理一个，或者是处理某些，不会保证一次处理干净，没处理干净的下次事件触发继续处理
  - LT文件属性可以阻塞可以非阻塞。建议也按非阻塞。

### 7.定时器类

#### 简介

- 定时器容器：每个定时事件封装成一个定时器，所有定时器串联起来构成容器。容器可以是链表、时间轮、最小堆。
  - 本项目用的容器是升序链表。
- 驱动定时的动力可以有：socket选项（SO_RCVTIMEO、SO_SNDTIMEO）、SIGALRM信号（有alarm或者setitimer函数周期性触发信号）、epoll里的超时参数（epoll_wait里的最后一个参数）。
  - 本项目的驱动定时的动力肯定是SIGALRM信号。由alarm函数周期性触发。
- 低效的定时器：基于升序链表的定时器
- 高效的定时器：时间轮、时间最小堆

#### 用到的技术

- 定时器容器：每个定时事件封装成一个定时器，所有定时器串联起来构成容器。容器可以是链表、时间轮、最小堆。
- 本项目用的容器是升序双向链表。
  - 升序定时器链表中将其中的定时器按照超时时间（超时时间在项目里使用的是绝对时间，就是那年那月几点几分那个绝对时间）做升序排序
  - 切记：expire就是绝对时间。它代表了从1970到现在的秒数。谁的expire越小，说明越早要触发定时。它就越处于链表的头部方向。谁的expire值越大，谁就越处于链表的尾部方向。（升序就是按expire的值来升序的）
- SIGALRM信号每次被触发，就执行一次`void sort_timer_lst::tick()`即脉搏函数。该函数首先获取当前系统时间，然后从头结点开始依次检查每个定时器，是否到时间了（即比较当前时间和每个节点的expire）。如果已经到时间了，那么就调用 `当前节点->cb_func(当前节点->user_data)`。将用户数据传入回调函数中，以执行定时任务。
  - 定时任务就是 删除非活动连接在socket上的注册事件，并关闭该connfd。
- 类中还封装了：
  - 添加某个定时器timer至升序定时器链表中：`void add_timer(util_timer *timer)`
    - 重载的辅助函数，用于在add_timer中将定时器添加到合适位置。`void add_timer(util_timer *timer, util_timer *lst_head);`
    - 换句话说，`void add_timer(util_timer *timer)`只能处理简单的添加任务（比如添加至头尾节点），当定时器要添加到链表中间某个位置时，就得调用辅助函数`void add_timer(util_timer *timer, util_timer *lst_head);`
  - 某个定时器的expire值手动增大了，要手动调整该定时器在链表中的位置：`void adjust_timer(util_timer *timer)`
    - 一般没用过
  - 从升序定时器链表中删除某个定时器timer：`void del_timer(util_timer *timer)`
    - 一般没用过
- 相当于是每多少（TIMESLOT=5）秒，SIGALRM信号就触发一次，就执行一次tick脉搏函数，就开始检查一次链表上所有到期的定时器。因此这5s内，不管你是第1秒还是第2秒第三秒就到时了，都得等到第5秒才能去处理定时任务。因此周期TIMESLOT就反应了精度，它越小，则精度越高。
- 升序链表的复杂度？
  - 添加一个定时器的复杂度：O(n)
    - 因为要保证升序，最坏就是添加到末尾呗
  - 删除一个定时器的复杂度：O(1)
    - 直接删除，就修改一下该节点相邻节点的指向
  - 执行定时任务的时间复杂度：O(1)
    - 备注：因为已经排好序了，比时间更大的定时器之后的定时器就不用检查了，因此执行定时任务的时间复杂度可以算作O(1)
- 时间轮？
  - P206
  - 基于升序链表的定时器使用唯一的一条链表来管理所有定时器，所以插入操作的效率随着定时器数目的增多而降低。
  - 而时间轮采用哈希表的思想，将定时器散列到不同的链表上。这样每条链表上的定时器数目都将明显少于原来的排序链表上的定时器数目，插入操作的效率基本不受定时器数目的影响。
    - 备注：时间轮上的各个链表不是升序排列的，每次触发到该槽时，就遍历该槽对应链表上的所有定时器，判断每个定时器是否到时间了
  - 添加一个定时器的复杂度：O(1)
    - 不用保证升序，直接添加到某个槽对应的链表尾
  - 删除一个定时器的复杂度：O(1)
    - 直接删除，就修改一下该节点相邻节点的指向
  - 执行定时任务的时间复杂度：O(n)
    - 备注，每次到时间了，都得遍历一下该槽对应的整条链表。
    - 但实际上执行一个定时器任务的效率要比O(n)好得多，因为时间轮将所有的定时器散列到了不同的链表是哪个。时间轮的槽越多，那一条槽上的链表长度就越短，执行定时任务的时间复杂度就越低。
  - 总结：时间轮相比单条升序链表，是大大降低了添加定时器的复杂度，但是略微增加了执行定时任务的时间复杂度
    - （执行定时任务的时间复杂度的区别就在于还用不用遍历一遍链表，来看看哪些定时器到时间了，哪些没有）
- 时间最小堆：
  - 最快要到期的定时器位于堆顶。下一次的心博函数执行的时间就设置为堆顶定时器（即最快要到期的定时器）的时间。
  - 添加一个定时器的时间复杂度是：O(lgn)
  - 删除一个定时器的复杂度：O(1)
  - 执行定时任务的时间复杂度：O(1)

### 8.如果要用到cgi来验证账号密码的话

#### 同步线程验证：主进程（其实是线程池里的线程）自己处理post请求，查询用户的账户密码是否正确

那就不用fork进程，主进程自己就查询就完事了

#### cgi方式验证（fork一个cgi进程去查询用户账户密码是否正确）

- cgi的输入就是主进程传参，传进来一套账户名密码，cgi判断一下这个账户密码对不对
- 所有的账号密码都要存到一个txt里（数据库一份，txt里一份）
- 在线程池的某个线程处理http请求时，发现此次请求是post，且是登录时，那么就在线程里fork一个进程去执行cgi程序。
- 主进程（线程池的某个线程），子进程（线程池的某个线程fork出来的进程，它就用来执行cgi程序）
- 通过管道的方式在主进程和子进程之间通信。
  - 子进程关闭标准输出，然后将标准输出重定向到管道写端`dup2(pipefd[1], 1);`。关闭管道读端。
  - 主进程关闭管道写端。等待子进程处理完毕，printf到管道里（因为标准输出被重定向了，所以printf的就到管道里了），然后从pipefd[0]上读出来处理结果。
- cgi程序每次从txt里，遍历查询，登录的用户名密码是否存在或者说正确。cgi通过管道向主进程反馈处理结果。主进程阻塞等待cgi的处理结果

## 4.整体流程

### main

- 0.在main中的全局变量

  - `sort_timer_lst timer_lst;//定时器链表`
  - `int pipefd[2];//管道`
    - 用于统一事件源（让信号事件表现的跟IO事件无异）
    - 具体实现：
      - 1.为感兴趣的几个信号各自设置（addsig，其实是sigaction）信号处理函数，不过它们的信号处理函数都是同一个（sig_handler，自定义函数）。
      - 2.信号处理函数（sig_handler）要做的事就是，一旦触发信号处理函数后，就向管道pipefd[1]写入数据，将信号值写进去。
      - 3.epoll中监听pipefd[0]的可读事件，一旦pipefd[0]可读了，就意味着有信号触发了。在epoll_wait之后再统一处理信号，要知道，IO事件比如listenfd可读了，也是在epoll_wait之后处理的。因此此时，信号就表现的跟IO事件无异了，这就叫统一事件源。

- main函数中：

- 1.创建日志文件

  - 日志是个单例。调用get_instance即可获得该单例
  - `Log::get_instance()->init("./everyday_log/ServerLog", 2000, 800000, 1000); //获得单例+初始化类内某些参数`

- 2.创建数据库连接池

  - 数据库连接池是单例。调用get_instance即可获得该单例
  - `connection_pool* connPool = connection_pool::GetInstance();//获得单例`
  - ` connPool->init("localhost", "root", "123", "yourdb", 3306, MYSQL_CONN_NUMBER);//初始化类内某些参数`

- 3.创建线程池

  - ` threadPool=new thread_pool<http_conn>(connPool,THREAD_NUMBER,MAX_REQUESTS_IN_REQUESQUEUE);//就是提前建立好一些子线程，等待处理http_conn类对象，即http连接请求`

- 4.创建内核事件表epollfd

  - `epoll_event events[MAX_EVENT_NUMBER];//events是用来存放就绪的文件描述符的`
  - ` epollfd=epoll_create(5);//创建内核事件表"epollfd"，5是提示内核可能有5个感兴趣的文件`

- 5.提前创建好65536个用于处理http_conn连接的对象

  - `   http_conn *users = new http_conn[MAX_FD]; //建立http_conn数组，包含65536个http_conn连接。`

- 6.提前创建好65536个存储客户数据的数组

  - `client_data *users_timer = new client_data[MAX_FD];//客户数据数组，跟http_conn数组大小保持,即对应最多65536个http_conn连接`

- 7.初始化管道

  - `socketpair(PF_UNIX, SOCK_STREAM, 0, pipefd);//建立双向管道pipefd[2]`
  - `setnonblocking(pipefd[1]);//管道写端设置为非阻塞`
  - `  addfd(epollfd, pipefd[0], false);//向内核事件表epollfd中注册"pipefd[0]"这个管道读端文件的 可读事件`

- 8.创建socket文件“listenfd"，作为侦听的sokcet

  - `int listenfd=socket(PF_INET,SOCK_STREAM,0);//创建IPv4的TCP socket。`
  - `bind(listenfd,(struct sockaddr*) &address,sizeof(address));//将那个listenfd文件 bind到地址 0.0.0.0:12345`
  - `listen(listenfd,5);//开始侦听，等待客户连接。其实是创建了一个listen监听队列`
  - `addfd(epollfd, listenfd, false);//向内核事件表中注册"listenfd"这个socket文件的 可读事件`

- 9.设置各个信号的处理函数都是sig_handler

  - ```
    addsig(SIGALRM, sig_handler, false);//设置信号SIGALRM的处理函数是sig_handler，即将信号值传递到pipefd[0]端
    addsig(SIGTERM, sig_handler, false);//
    addsig(SIGHUP, sig_handler, false);//-1。统一事件源，所有的信号都是一个信号处理函数（其实都是在主线程中处理的，并不在信号处理函数中处理）
    addsig(SIGINT, sig_handler, false);
    addsig(SIGQUIT, sig_handler, false);//-3
    ```

- 10.while(!stop_server)主线程循环等待epoll_wait。一个线程，监听多个IO事件

  - 当epoll_wait都返回时，得if判断，这次是哪个事件。
    - 是信号事件？即`sockfd == pipefd[0]`。接下来那还得再switch，是SIGALRM信号，还是SIGINT、SIGTERM信号?.....
    - 是listenfd可读？那说明有新用户连接了
    - 是客户连接connfd上接收到客户发来的数据？发来get、post请求了
    - 是客户连接connfd上有服务器要发给客户的数据？要传给客户响应报文了

- 

### http连接过程

- ---------------------------------------主线程处理------------------------------------------
- 1.服务器开启0.0.0.0:12345端口作为listenfd，构建listen队列。将listenfd的可读事件加入内核事件表（非oneshot）
- 2.当有新的客户连接到0.0.0.0:12345端口时，触发侦听socket即listenfd的可读事件。
  - 在主线程中accept一个连接，将该连接即connfd的可读事件加入内核事件表（**oneshot**）；
  - 初始化一个http_conn备用；
  - 初始化一个connfd配套的client_data数据结构、以及对应的定时器  备用。
- 3.当客户向服务器发送http请求（connfd可读了）
  - 主线程将数据从socket conn上读到http_conn对象内的m_read_buf上(read_once函数)，然后主线程将该http_conn对象加入（主线程与线程池之间的）请求队列中(threadPool->append(http_conn*)函数)，等待线程池中子线程处理。
    - 读下来的数据一般就是GET或者POST请求报文
- ---------------------------主线程把数据读到m_read_buf里，交由子线程处理-----------------（可以看出很明显的proactor IO模式）
- ---------------------------------------子线程处理------------------------------------------
- 4.线程池中的线程竞争去处理请求队列上的http_conn对象，某个子线程获得后，就开始执行`request->process()`，对调用http_conn类内的process函数进行处理。
  - process的第一步：process_read()。从请求报文中获取有用的信息，存至类内变量中。
    - 即从http_conn对象内的m_read_buf上，开始一行一行的分析请求报文。
    - 分析请求报文的请求行parse_request_line函数。（记录下来要访问的文件名、请求方法（GET/post）、HTTP版本）
    - 分析请求报文的首部行parse_headers函数。（记录下来host比如yadong.site 或者192.168.80.131:12345、是否keep-alive、实体主体的长度）
    - 分析请求报文的实体主体parse_content函数。（在post时，会是用户名和密码）
    - 最后在分析请求报文完整且无误时调用do_request函数。do_request是用于修改m_real_file和m_file_address参数的。（根据不同的post或者get参数，预计返回不同的页面）
  - process的第二步：process_write（）。根据precess_read的返回结果，来发送不同的响应报文给客户。值得注意的是，这一步是将响应报文写在m_write_buf里，还不发送到connfd上。
    - 如果precess_read返回值（即请求报文的解析结果）是INTERNAL_ERROR。说明是服务器内部错误，
      - 往m_write_buf里添加响应报文的状态行`add_status_line(500, error_500_title);`
      - 往m_write_buf里添加响应报文的首部行`add_headers(strlen(error_500_form));`
      - 往m_write_buf里添加响应报文的实体主体`add_content(error_500_form);`这种情况下的实体主体，也是一句短语，什么not found啊等等
    - 类似的还有precess_read返回值（即请求报文的解析结果）是BAD_REQUEST、FORBIDDEN_REQUEST等等都是回复一个响应报文，但是不发送文件给客户。
    - 如果precess_read返回值（即请求报文的解析结果）是FILE_REQUEST。说明HTTP解析成功了，
      - 往m_write_buf里添加响应报文的状态行`add_status_line(200, ok_200_title)`
      - 往m_write_buf里添加响应报文的首部行`add_headers(m_file_stat.st_size);`
      - 实体主体先不要添加，因位这种情况下的实体主体是个网页！网页文件已经被mmap到内存里了，在write函数发送时，再把响应报文和实体主体连接起来一起发送过去。即m_iv数组里的两个内容。
    - 如果precess_read返回值（即请求报文的解析结果）是NO_REQUEST。说明请求不完整，需要继续读取请求报文数据。重置该connfd的可读事件和oneshot
  - process的第三步：
    - 重置该connfd在内核事件表上的可写事件以及oneshot（这将触发一次connfd的可读事件）
  - 备注：往m_write_buf写完数据后怎么发给客户呢？
    - process_write（)函数最后的这个modfd操作，会触发一次connfd的可写事件。主线程收到这个事件后，由主线程自己发给connfd。
    - 因此这是非常典型的proactor模式。即主线程自己完成IO操作。工作线程直接拿到IO结果，进行处理。
- //-----------------------------------------------子线程把要发送的数据写到m_write_buf里，交由主线程发送---------------（可以看出很明显的proactor IO模式）
- //-----------------------------------主线程处理----------------------------------
- 5.该connfd上的可写事件触发（由子线程中的process的第三步触发）
  - 主线程调用write函数，write函数里使用writev将m_iv数组里的两个部分（响应报文+实体主体）发送给connfd上。
  - 如果往connfd发送成功，且本次HTTP请求表明需要keep-alive，那么就保持连接15秒。如果定时器15秒后也没有发生任何一方给对方发数据，那么就断开连接
  - 如果往connfd发送失败，或者是次HTTP请求表明需要立即close，那么就立即断开连接（也就是close connfd），删除内核事件表上的注册连接，删除定时器
- 6.本次处理结束

# 2.相关面试问题

## 1.项目介绍

### 为什么要做这样一个项目？

- 上面的toy级项目，是我备战秋招时准备的，当时我也是一个小白，一头雾水，没人指导，不知所措。当时学完C++基础、计算机基础知识、Linux基础后，我看了tcp/ip网络编程和游双的Linux高性能服务器编程，然后就有了上面攒的这个项目。
- 代码大部是书上的，我只是整理成一个较为完善的项目，并加了一些功能，对所有模块做了一些注释和讲解。
- 整个流程就是注册、登录访问服务器的数据库，验证通过后请求服务器上的一个图片文件，仅此而已。

### 介绍下你的项目

- 这个项目主要是对浏览器发送来的GET、POST请求进行解析处理，服务器处理完之后给浏览器客户端返回一个响应，如文字图片视频等。
- 服务器后端的处理方式使用socket通信，使用**IO复用中的epoll**，可以同时处理多个请求。当主线程收到新的客户连接时，accept该连接，并加入epoll中检测该connfd可读可写事件。
- 提前建立好数据库连接池和线程池。当有数据（比如http get请求）从客户端发送过来时，主线程从socket上读出数据，封装后放入请求队列上。线程池中的工作线程竞争去处理请求队列上的任务。处理任务即分析http请求，并生成响应报文，以及将准备发送给客户端的页面、图片、视频等mmap到内存中。触发connfd可写事件
- 主线程完成向socket上写入数据的操作。因此这是一个**标准的proactor事件处理模式**。再考虑上主线程和工作线程之间的关系，从并发模式上，属于半同步半反应堆模式。
- 本项目还配有日志系统，它是一个单例类，可以工作在同步模式或者是异步模式。
- 本项目配有定时器系统，可以定期检测不活跃的连接，并断开该连接。

## 2.线程池相关

### 1.手写线程池

#### linux-api实现（linux下的pthread_t、sem_t、pthread_mutex_t）

在这种方式下，一定要worker+run。worker得是static的。

理由是：pthread_create函数对于线程执行的函数的输入输出有限制

```c
g++ test.cpp -o test -lpthread
```

```c++
#include<iostream>
#include<list>
#include<semaphore.h>
#include <unistd.h>
using namespace std;
//------------linux api实现-------------
template<class T>
class thread_pool{
    private:
        int m_thread_number;//记录线程池中的线程数
        int m_max_requests;//记录请求队列中允许的最大请求数
        pthread_t *m_threads;       //描述线程池的数组，它是一个包含m_thread_number个元素的pthread_t数组
        list<T*> m_workqueue;//请求队列。日志里才用了阻塞队列，线程池里这个请求队列不是阻塞队列。
        pthread_mutex_t m_mutex;//保护请求队列（链表）的互斥锁。线程池不需要保护
        sem_t m_sem;            //信号量，是否有任务需要处理。也代表了请求队列中有多少任务需要处理
        bool m_stop;//线程池里的所有线程停止（虽然线程池没有实现为单例类，但是它实际上也只有一个）
    public:
        thread_pool(int thread_number = 8, int max_requests = 10000){//构造线程池
            m_thread_number=thread_number;
            m_max_requests=max_requests;
            pthread_mutex_init(&m_mutex,nullptr);//初始化互斥锁
            sem_init(&m_sem,0,0);//初始化信号量
            m_stop=false;
            m_threads=new pthread_t[m_thread_number];//申请线程数组
            for(int i=0;i<m_thread_number;i++){
                pthread_create(&m_threads[i],nullptr,worker,this);
            }
        }
        ~thread_pool(){//析构线程池
            m_stop=true;
            delete[] m_threads;//把数组删了，其实只是把获取每个子线程的方法（即pthread_t）删了，
                                //并不是把每个pthread_t对应的线程删了。这个数组删了，就无法获得每个子线程了。结束子线程
                                //是靠将my_stop设置为true，让子线程自然执行完毕而结束子线程的。而不是靠这个delete[]。
            pthread_mutex_destroy(&m_mutex);
            sem_destroy(&m_sem);
        }
        bool append(T* request){//往请求队列上添加任务
            pthread_mutex_lock(&m_mutex);//要操作请求队列了，加锁
            //如果请求队列的长度已经达到【请求队列中允许的最大请求数】了。即请求队列满了
            if(m_workqueue.size()>=m_max_requests){
                pthread_mutex_unlock(&m_mutex);
                return false;
            }
            m_workqueue.push_back(request);//将任务push到链表尾 
            pthread_mutex_unlock(&m_mutex);//解锁     
            sem_post(&m_sem);//代表请求队列中任务数量的信号量+1
            return true;
        }
    private:
        //为什么用一个worker函数呢?因为pthread_create函数规定了线程执行的函数的格式，必须是输入void* ，返回void*
        //工作线程运行的函数，它不断从工作队列中取出任务并执行之
        static void* worker(void* _thread_pool){///每个工作线程虚假的运行函数（它只是一个壳子，内部真正还是调用run()函数）。它必须是static，并且输入和返回的格式都是void*
            thread_pool<T>* threadPool = (thread_pool<T> *)_thread_pool;//传进来的参数是this，即线程池本身。
            threadPool->run();
            return nullptr;
        }
        
        void run(){
            while(!m_stop){
                sem_wait(&m_sem);//等待信号量激活
                pthread_mutex_lock(&m_mutex);//要操作请求队列了，加锁
                T* request=m_workqueue.front();//获取头结点为当前任务
                m_workqueue.pop_front();//头节点出队

                //request->process();//开始处理
                cout<<*request<<endl;
                pthread_mutex_unlock(&m_mutex);//解锁
            }
        }
};



int main(){
    thread_pool<int> mythreadpool;
    int testArray[100];
    for(int i=0;i<100;i++)
    {
        testArray[i]=i;
        mythreadpool.append(&(testArray[i]));
    }
    pause();
    return 0;
}
```

#### c++11 api实现

在这种方式下，也一定要worker+run。worker得是static的。

理由是：thread函数虽然对于线程执行的函数没有输入输出类型的限制，但是必须得是静态函数！静态函数调用非静态成员很不方便（只能通过传入this指针），因此用worker当壳子，实际函数是run函数。

```c++
#include<iostream>
#include<list>
#include<thread>
#include<mutex>
#include<semaphore.h>
#include <unistd.h>
using namespace std;

//------------c++11 api实现-------------
template<class T>
class thread_pool{
    private:
        int m_thread_number;//记录线程池中的线程数
        int m_max_requests;//记录请求队列中允许的最大请求数
        thread *m_threads;       //描述线程池的数组，它是一个包含m_thread_number个元素的pthread_t数组
        list<T*> m_workqueue;//请求队列。日志里才用了阻塞队列，线程池里这个请求队列不是阻塞队列。
        mutex m_mutex;//保护请求队列（链表）的互斥锁。线程池不需要保护
        sem_t m_sem;            //信号量，是否有任务需要处理。也代表了请求队列中有多少任务需要处理
        bool m_stop;//线程池里的所有线程停止（虽然线程池没有实现为单例类，但是它实际上也只有一个）
    public:
        thread_pool(int thread_number = 8, int max_requests = 10000){//构造线程池
            m_thread_number=thread_number;
            m_max_requests=max_requests;
            sem_init(&m_sem,0,0);//初始化信号量
            m_stop=false;
            m_threads=new thread[m_thread_number];//申请线程数组
            for(int i=0;i<m_thread_number;i++){
                m_threads[i]=thread(worker,this);
            }
        }
        ~thread_pool(){//析构线程池
            m_stop=true;
            delete[] m_threads;//把数组删了，其实只是把获取每个子线程的方法（即pthread_t）删了，
                                //并不是把每个pthread_t对应的线程删了。这个数组删了，就无法获得每个子线程了。结束子线程
                                //是靠将my_stop设置为true，让子线程自然执行完毕而结束子线程的。而不是靠这个delete[]。
            sem_destroy(&m_sem);
        }
        bool append(T* request){//往请求队列上添加任务
            m_mutex.lock();//要操作请求队列了，加锁
            //如果请求队列的长度已经达到【请求队列中允许的最大请求数】了。即请求队列满了
            if(m_workqueue.size()>=m_max_requests){
                m_mutex.unlock();
                return false;
            }
            m_workqueue.push_back(request);//将任务push到链表尾 
            m_mutex.unlock();//解锁     
            sem_post(&m_sem);//代表请求队列中任务数量的信号量+1
            return true;
        }
    private:
        //为什么用一个worker函数呢?因为pthread_create函数规定了线程执行的函数的格式，必须是输入void* ，返回void*
        //工作线程运行的函数，它不断从工作队列中取出任务并执行之
        static void* worker(void* _thread_pool){///每个工作线程虚假的运行函数（它只是一个壳子，内部真正还是调用run()函数）。它必须是static，并且输入和返回的格式都是void*
            thread_pool<T>* threadPool = (thread_pool<T> *)_thread_pool;//传进来的参数是this，即线程池本身。
            threadPool->run();
            return nullptr;
        }
        
        void run(){
            while(!m_stop){
                sem_wait(&m_sem);//等待信号量激活
                m_mutex.lock();//要操作请求队列了，加锁
                T* request=m_workqueue.front();//获取头结点为当前任务
                m_workqueue.pop_front();//头节点出队

                //request->process();//开始处理
                cout<<*request<<endl;
                m_mutex.unlock();//解锁
            }
        }
};



int main(){
    thread_pool<int> mythreadpool;
    int testArray[100];
    for(int i=0;i<100;i++)
    {
        testArray[i]=i;
        mythreadpool.append(&(testArray[i]));
    }
    pause();
    return 0;
}
```

### 2.线程的同步机制有哪些？

- pthread_join可以看做简单的线程同步方式，不过很显然它无法高效地实现复杂的同步需求，
  - 比如 控制对共享资源的独占式访问；某个条件满足之后唤醒一个线程。pthread_join都无法做到。
- POSIX信号量 semaphore
  - 信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：
    - sem_wait（sem_t *sem）：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。
    - sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。
- 互斥锁mutex
  - 互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。
  - linux api中：
    - pthread_mutex_t m;
    - pthread_mutex_init(&m,nullptr);
    - pthread_mutex_lock(&m);
    - pthread_mutex_unlock(&m);
    - pthread_mutex_destroy(&m);
  - c++11中：
    - mutex m;//互斥锁，即信号量为1
    - m.lock();//即P(m)
    - m.unlock();//即V(m)
- 条件变量
  - 条件变量，又称条件锁，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。
  - 比如：
    - 当队列为空时，消费者还要从队列取东西（pop），那么消费者线程就会阻塞在条件变量上（`my_cond.wait(my_mutex.get());`）。当生产者又生产了新的东西放入（push）队列时（队列上有东西了，可以消费了，但是所有消费者线程都在阻塞着呢，所以必须得唤醒消费者），所以就会执行`my_cond.broadcast()`，唤醒所有阻塞在条件变量my_cond上的消费者线程来从队列取东西
    - 当队列满了时，生产者还要往队列里放东西（push），那么生产者线程就会阻塞在另一个条件变量`（my_cond2.wait(my_mutex.get());`上。当消费者从队列取走（pop）一个东西时（队列不满了，可以往队列上放东西了，但是所以生产者线程都在阻塞着呢，所以必须得唤醒生产），所以就会执行`my_cond2.broadcast()`，唤醒所有阻塞在条件变量my_cond2上的生产者线程往队列放东西
  - linux api中：
    - pthread_cond_t my_cond;//条件变量。相当于一种资源的阻塞队列。
    - pthread_mutex_t m_mutex;//互斥量，就是最简单的进程互斥。
    - pthread_cond_init(&my_cond,nullptr);
    - pthread_cond_wait(&my_cond,&m_mutex); 
    - pthread_cond_signal(&my_cond);//唤醒阻塞队列上一个线程
    - pthread_cond_broadcast(&my_cond);//唤醒阻塞队列上的所有线程
    - pthread_cond_destroy(&my_cond);
  - c++ 11中
    - std::condition_variable con1;//条件变量。相当于一种资源的阻塞队列。
    - std::mutex my_mutex;//互斥量，就是最简单的进程互斥。
    - `std::unique_lock<std::mutex> lk(my_mutex);`
    - `con1.wait(lk,[this]()->bool{return counter==2;}); `// 阻塞当前线程，直到条件变量被唤醒。并且会释放lk，即解锁，好让其他线程执行。 [this]()->bool{return counter==2;}是Lambda表达式
    - con1.notify_one();//若任何线程在con1上等待，则调用 notify_one 会解阻塞(唤醒)等待线程之一。
          //换句话说，con1.notify_one()是con1.wait()的唤醒
- 个人理解 信号量和条件变量的区别
  - 信号量的阻塞：一旦有值了，线程会自动解除阻塞状态，即wait成功
  - 条件变量的阻塞：有值了，线程也是阻塞的，需要手动唤醒，才会解除阻塞状态

### 3.线程池中的工作线程是一直等待吗？

```
void run(){
    while(!my_stop){
        my_queuestat.wait();//获取信号量，即获取任务
        my_queuelocker.lock();//要操作请求队列（链表）了加锁

        T* request=my_workqueue.front();//获取头结点为当前任务
        my_workqueue.pop_front();//头结点出队
        my_queuelocker.unlock();//解锁

        connectionRAII mysqlcon(&(request->mysql),my_connPool);//从my_connPool中取一条数据库连接，放到request->mysql变量上（变量类型MYSQL *）
        request->process();//开始处理
	}
}
```

- 在我们创建线程池之初时，我们通过循环调用pthread_create往线程池中创建了8个工作线程，工作线程处理函数接口为pthread_create函数原型中第三个参数函数指针所指向的worker函数（自定义的static函数），然后在worker函数中调用线程池类成员函数run（自定义非static函数）。
  - -------这里可能会有疑问？为什么不直接将第三个参数直接指向run函数，而是要通过向worker中传入对象从而调用run呢？
  - 原因是pthread_create函数原型中第三个参数函数指针必须是类内static函数。而我们都知道静态成员函数只能访问静态成员变量，所以为了能够访问到类内非静态成员变量，我们可以通过在worker中调用run这个非静态成员变量来达到这一要求（向worker函数传入this指针，即本线程池，在worker函数中执行this->run()）。
- **工作线程执行run函数，run函数是个while循环，一个bool型的线程池关闭标志my_stop。**
- **只要没在线程池里的析构函数中，设置my_stop为true。线程就一直执行while循环**
- **当没有任务（主线程 与 线程池里工作线程 之间的 请求队列 为空）时，线程就阻塞在信号量my_queuestat（信号量的值等于 请求队列 中的任务数）上**
- 总结：
  - 线程池中的工作线程都设置为阻塞等待在请求队列是否不为空的条件上（其实就是各个线程阻塞在代表请求队列 中的任务数的信号量上），因此项目中线程池中的工作线程是处于一直阻塞等待的模式下的。

### 4.你的线程池工作线程处理完一个任务后的状态是什么？

- 工作线程执行while循环，一个bool型的线程池关闭标志my_stop。
- 情况1：线程池工作线程处理完一个任务后。请求队列为空了，没有任务了
  - 那就信号量wait阻塞，线程阻塞在信号量wait函数上
- 情况2：线程池工作线程处理完一个任务后。请求队列上还有任务
  - 那么这个线程将处于与其他线程竞争资源的状态，哪个线程信号量wait成功，哪个线程就获得了处理事件的资格，该线程就开始处理下一个请求任务

### 5.如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？

- 本项目中是通过对子线程循环调用来解决高并发的问题的。
- **我们通过子线程的run调用函数进行while循环，让每一个线程池中的线程永远都不会终止，说白了就是让他处理完当前任务就去处理下一个，没有任务就一直阻塞在那里等待。**这样就能达到服务器高并发的要求，同一时刻8个线程都在处理请求任务，处理完之后接着处理，**直到请求队列为空表示任务全部处理完成。**

### 6.如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?

- 肯定会影响接下来的客户请求，因为线程池中的线程就那么多，如果线程都在被长时间占用，就会导致接下来的客户请求在请求队列中等待很久，才会被线程处理，也就是说会导致客户的请求不能被及时地响应处理。
- **应对策略：**
  - 1.提高线程的数量
  - 2.我们可以为线程处理请求对象设置处理超时时间, 超过超时时间，先发送信号告知线程处理超时，然后设定一个时间间隔再次检测，若此时这个请求还占用线程则直接将其断开连接。

## 3.并发模型相关

### 1.并发模式：简单说一下服务器使用的并发模型？

#### 0.简介

并发模式是指IO处理单元和多个逻辑单元之间协调完成任务的方法

#### 1.半同步半异步模式（既有异步线程、又有同步线程）

**在并发模式里，这里的同步异步是指线程的同步和异步：按顺序依次执行程序就是同步，当程序的执行是由信号、中断等驱动执行，则为异步。**

- 异步线程（主线程、IO处理单元）处理IO事件
- 同步线程（线程池中的工作线程、逻辑单元）处理客户逻辑
- 半异步：异步线程异步地处理I/O事件，就是客户端向服务器端的请求的接收，是通过异步线程进行处理的，来请求触发处理，没有来的时候处理其他事情。
  - **什么叫异步地？也就是该线程是由信号、中断等驱动执行。比如主线程由epoll_wait驱动**
- 半同步：是指同步线程同步地处理请求数据，异步线程接收完请求之后会将请求封装后插入队列，工作线程就依次同步从队列中取出请求对象进行处理。
  - 什么叫同步地？就是线程按顺序执行到尾就完了，中间不用经受信号、中断等驱动执行。

#### 2.半同步半反应堆模式（半同步半异步模式+rector（反应堆））

- 半异步：异步线程异步地处理I/O事件，就是客户端向服务器端的请求的接收，是通过异步线程进行处理的，来请求触发处理，没有来的时候处理其他事情。
- 半反应堆：这是指事件处理模式。即异步线程（主线程）将socket的可读\可写等放入请求队列，然后某个工作线程被唤醒，工作线程从socket上读取客户请求和往socket上写入服务器应答

#### 3.半同步半异步模式+使用同步IO模拟的proactor模式（本项目使用）

- 本项目实际上使用的是proactor，因为主线程往请求队列上放的是解析完毕的http_conn类型的数据，工作线程从请求队列取出后可直接处理之，而无需工作线程自己去socket上读
- 工作线程处理完毕后，服务器的应答数据也是存在一个buffer里的，真正往socket上写，也是由主线程完成的。
- 所有主线程（异步线程）来执行真正的socket读写操作，这就是proactor模式

#### 4.高效的半同步/半异步模式：

上面 2和3 这两种种半反应堆模式的一个问题就是，因为有了请求队列，每次工作线程处理队列请求都需要加锁，白白消耗CPU；另一方面如果任务很多，工作线程很少，就会造成客户端响应速度变慢。

- 高效的半同步/半异步模式：解决办法就是取消任务队列，直接由主线程将各个客户端请求派发给各个工作线程，后期每个工作线程都持续响应同一个请求带来的读写。
- 每个线程（不论主线程还是线程池中各个子线程）都维持自己的事件循环，各自独立地监听不同的事件。换句话说每个线程都有自己的epool_wait。也就是每个线程都工作在异步模式，因为每个线程往下执行都是由epoll_wait来驱动的

#### 5.领导者追随者模式

没有主线程和线程池中线程的概念了。

- 任意时间点，程序都仅有一个领导者线程，它负责监听IO事件（比如侦听socket上有新的客户连接到达，连接socket上有新的数据传输）。而其他线程都是追随者线程，他们休眠在线程池中等待 被当前领导者指定来处理新的任务 或者 被指定成为新的领导者
- 一般情况下是，领导者线程监听到请求后，领导者线程首先选出新的领导者，然后旧的领导者线程就去处理该IO事件了。新的领导者线程开始负责监听等待新的IO事件。
- 核心就是：
  - 领导者线程负责监听IO事件。它可能指派追随者线程去处理IO任务，也有可能是它自己退位去处理IO任务，并指派某个追随者线程来当领导者

#### 简洁回答

- 半同步半异步模型：
  - 主线程就是异步线程，它靠epoll_wait来驱动进行。线程池中的工作线程都是同步线程，它是按序执行的。
- 半同步半反应堆（它肯定是属于半同步半异步模型）
  - 是半同步半异步模型结合了reactor或者proactor。
  - 主线程还是异步线程，它靠epoll_wait来驱动进行。线程池中的工作线程都是同步线程，它是按序执行的。
  - reactor:区别就在于，主线程将socket的可读\可写等放入请求队列，然后某个工作线程被唤醒，工作线程从socket上读取客户请求和往socket上写入服务器应答
  - proactor:区别就在于，主线程往请求队列上放的是解析完毕的http_conn类型的数据，工作线程从请求队列取出后可直接处理之，而无需工作线程自己去socket上读。工作线程处理完毕后，服务器的应答数据也是存在一个buffer里的，真正往socket上写，也是由主线程完成的。
- 领导者追随者模式
  - 任意时间点，程序都仅有一个领导者线程，而其他线程都是追随者线程。
  - 领导者线程负责监听IO事件。它可能指派追随者线程去处理IO任务，也有可能是它自己退位去处理IO任务，并指派某个追随者线程来当领导者

### 2.事件处理模式：reactor、proactor、模拟proactor模型的区别？

#### 0.简介

**在事件处理模式里，"同步"和“异步”区分的是内核向应用程序通知的是何种IO事件（是就绪事件还是完成事件），以及该由谁来完成IO读写（是应用程序还是内核）**

- 同步IO模型：要求用户代码自行执行IO操作（将数据从内核缓冲区读入用户缓冲区，获奖数据从用户缓冲区写入内核缓冲区）
  - 同步IO向应用程序通知的是就绪事件
- 异步IO模型：由内核来执行IO操作（数据在内核缓冲区和用户缓冲区之间的移动是由内核在“后台”完成的）
  - 异步IO向应用程序通知的是IO完成事件
  - 备注：从没用过异步IO模型

#### reactor（同步IO，不是内核来读写socket数据的，让工作线程读写socket数据）

- 主线程往内核事件表上注册的是**可读事件**
- 主线程（IO处理单元，异步线程（因为它是受epoll_wait驱动进行的）)只负责listenfd上是否有事件发生。有的话就立即将该事件通知工作线程（逻辑单元，同步线程（因为它是按序执行的））。
- 读写socket数据，接受新的连接，以及处理客户请求均在工作线程中完成
- 主线程往epoll内核事件表上注册socket读事件，主线程调用epoll_wait等待socket上有数据可读。当socket上有数据可读的时候，主线程把socket可读事件放入请求队列。睡眠在请求队列上的某个工作线程被唤醒，处理客户请求，然后往epoll内核上注册socket写请求事件。主线程调用epoll_wait等待写请求事件，当有事件可写的时候，主线程把socket可写事件放入请求队列。睡眠在请求队列上的工作线程被唤醒，处理客户请求。
- 总结就是：
  - 主线程负责分配任务（数据都没读出来），工作线程负责socket读写以及处理http请求
  - 内核事件表上注册的事件都是**可读事件**，来了事件内核（epoll_wait）通知主线程可读，主线程负责分配任务（数据都没读出来），让工作线程来读取数据并处理

#### Proactor（异步IO，即让内核来读写socket数据）

- 所有的IO操作都交给主线程和内核来处理。
- 主线程往内核事件表上注册的是**读完成事件（不是可读，而是读完成）**，并告诉内核  用户缓冲区的位置，以及读操作完成时如何通知应用程序（比如通过信号）
- 当数据被 内核 从内核缓冲区读到用户缓冲区后，即数据可使用了。那就放入请求队列上，让工作线程去处理。
- 写操作同理，是由工作线程注册的**写完成事件**，并告诉内核  用户缓冲区的位置，以及读操作完成时如何通知应用程序（比如通过信号）
- 当数据被 内核 从用户缓冲区 写socket后，即数据发送完了。那就发送完毕了。
- 总结就是：
  - 内核负责完成socket读写，主线程负责给工作线程分配读好的数据，工作线程负责处理http请求
  - 内核事件表上注册的事件都是**完成事件**，内核把数据读写完了再告诉你。异步网络模型，可以理解为：来了事件内核来读取，读取完了内核（epoll_wait）通知主线程，主线程收到后，主线程让工作线程来处理。

#### 模拟的proactor（同步IO，不是内核来读写socket数据的，而让主线程来读写socket数据）

- 主线程往内核事件表上注册的是**可读事件**
- 主线程往epoll内核事件表上注册socket读事件，主线程调用epoll_wait等待socket上有数据可读。当socket上有数据可读的时候，主线程自己读出来数据，然后把读好的数据封装起来，放入请求队列中。睡眠在请求队列上的某个工作线程被唤醒，处理客户请求，处理完毕后。向epoll内核上注册socket可写事件。主线程调用epoll_wait等待写请求事件，当有事件可写的时候，主线程就把处理完的请求写入socket中。
- 总结就是：
  - 主线程负责socket读写和给工作线程分配读好的数据，工作线程负责处理http请求
  - 内核事件表上注册的事件都是**可读事件**，来了事件内核（epoll_wait）通知主线程可读，主线程自己把数据读完，然后再分配给工作线程来处理

#### 简洁回答

- reactor（同步IO，因为不是内核来读写socket）
  - 主线程负责socket上**可读**，当主线程有可读事件触发时，主线程直接分配给工作线程，让工作线程自己去 读socket数据并处理。然后工作线程处理完毕后，注册一个socket可写。主线程有可写事件触发时，主线程分配一个工作线程，让工作线程去完成socket的写工作。
  - 即socket上数据的读写以及处理都是工作线程完成的。
- proactor（异步IO，因为是内核来读写socket）
  - 主线程负责socket上的**读完成**，当有socket可读时，内核来完成数据的读入，读入完毕后，触发epoll的读完成，主线程分配给工作线程，让工作线程读处理数据。然后工作线程处理完毕后，注册一个socket可写。内核来完成这个socket的写入工作。
  - 即socket上数据的读写是由内核完成的，数据的处理是由工作线程完成的
- 模拟的proactor（同步IO，因为不是内核来读写socket）
  - 主线程负责socket上**可读**，当主线程有可读事件触发时，主线程自己去完成socket的读工作，读入完毕后，主线程分配给工作线程，让工作线程读处理数据。然后工作线程处理完毕后，注册一个socket可写。主线程完成socket的写入工作。
  - 即socket上数据的读写是由主线程完成的，数据的处理是由工作线程完成的

### 3.IO复用：你用了epoll，说一下为什么用epoll，还有其他复用方式吗？区别是什么？

- 将文件描述符从用户传给内核

- - select和poll通过将所有文件描述符拷贝到内核态，每次调用都需要拷贝
  - epoll通过epoll_create建立一棵红黑树，通过epoll_ctl将要监听的文件描述符注册到红黑树上

- 内核判断就绪的文件描述符

  - select和poll通过遍历文件描述符集合，判断哪个文件描述符上有事件发生
  - **epoll**则不需要去以这种方式检查，当有活动产生时，会自动触发epoll**回调函数**通知epoll文件描述符，然后内核将这些就绪的文件描述符放到之前提到的ready list中等待epoll_wait调用后被处理。
  - 因此当活动的连接比较多时，epoll_wait的效率就变得低下了。因为此时回调函数被触发的过于频繁。因此epoll_wait适用于连接数量多，但活动的连接比较少的情况
  - 备注：这是内核的开销，即函数返回前。

- 文件描述符数量

  - poll和epoll_wait最多监听的文件描述符能达到进程允许打开的最大文件描述符数目，一般为65535。而select允许监听的最大文件描述符有限制，一般是最大1024

- 应用程序索引就绪文件描述符

  - 每次select和poll调用都返回整个用户注册的事件集合（其中包括就绪的和未就绪的），所以应用程序索引就绪文件描述符的时间复杂度为O(n)。epoll则在内核中维护一个事件表，epoll_wait仅仅返回就绪的事件，使得应用程序索引就绪文件描述符的时间复杂度为O(1)。
  - 备注：这是指函数返回后，用户再查询到底是哪些文件就绪时的复杂度

- 工作模式

  - select和poll都只能工作在相对低效的LT模式下
  - epoll则可以工作在ET高效模式，并且epoll还支持EPOLLONESHOT事件，该事件能进一步减少可读、可写和异常事件被触发的次数。 

- 应用场景

  - 当监测的fd数目较小，且各个fd都比较活跃，建议使用select或者poll
  - 当监测的fd数目非常大，成千上万，且单位时间只有其中的一部分fd处于就绪状态，这个时候使用epoll能够明显提升性能

- 总结：

  - ![image-20210417154133274](http://pichost.yangyadong.site/img/image-20210417154133274.png)

### 4.LT和ET

- LT水平触发模式

- - epoll_wait检测到文件描述符有事件发生，则将其通知给应用程序，应用程序可以不立即处理该事件。
  - 当下一次调用epoll_wait时，epoll_wait还会再次向应用程序报告此事件，直至被处理
  - 即一次可以只处理一点，没处理完的，下次epoll还会继续报告

- ET边缘触发模式

- - epoll_wait检测到文件描述符有事件发生，则将其通知给应用程序，应用程序必须立即处理该事件
  - 必须要一次性将数据读取完，使用非阻塞I/O，读取到出现eagain
  - 必须一次处理干净，本次epoll报告过的，下次epoll一定不会再报告了

- EPOLLONESHOT

- - 一个线程读取某个socket上的数据后开始处理数据，在处理过程中该socket上又有新数据可读，此时另一个线程被唤醒读取，此时出现两个线程处理同一个socket
  - 我们期望的是一个socket连接在任一时刻都只被一个线程处理，通过epoll_ctl对该文件描述符注册epolloneshot事件，一个线程处理socket时，其他线程将无法处理，**当该线程处理完后，需要通过epoll_ctl重置epolloneshot事件**
  - 另一方面，可以大幅减少可读、可写和异常事件被触发的次数。 

## 4.HTTP报文解析相关

### 1.用了状态机啊，为什么要用状态机？

状态机就是用于不同状态转换的一种数学模型。

设计机制：将程序中的不同状态进行整合，来保证不论状态发生的顺序如何，最后都能转移到需要的状态上。

好处：项目中状态机主要用于对客户端请求的处理，其中有三种状态，处理请求行，处理请求头，处理请求体，有了状态机，一方面可以避免多种状态同时发生造成混乱。另一方面保证了状态处理结束后能够正确的进行状态转移，相比只有if进行判断更加安全可靠。

### 2.状态机的转移图画一下

![image-20210417161849868](http://pichost.yangyadong.site/img/image-20210417161849868.png)

### 3.https协议为什么安全？

- HTTP请求过程中，客户端与服务器之间没有任何身份确认的过程，数据全部明文传输，“裸奔”在互联网上，所以很容易遭到黑客的攻击。
- HTTPS 相比 HTTP 多了一层 SSL/TLS
  - 就是说所有的HTTP请求明文，会被TLS层加密之后再传输。即使黑客捕捉到了，他也无法获悉内容的含义，相当于他看到的是乱码。

### 4.https的ssl连接过程

![image-20210105112129877](https://i.loli.net/2021/01/05/qzgt6CWAoxORfj4.png)

### 5.GET和POST的区别

- **GET** - 从指定的资源请求数据。
- **POST** - 向指定的资源提交要被处理的数据
- GET一般用于获取/查询资源信息，而POST一般用于更新资源信息.
- 区别：
- 1、get参数通过url传递，post放在request body中。
- 2、get请求在url中传递的参数是有长度限制的，而post没有。
  - 备注：其实url 长度限制是某些浏览器和服务器的限制，和 HTTP 协议没有关系。
  - 浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。
- 3、get比post更不安全，因为参数直接暴露在url中，所以不能用来传递敏感信息。
  - 备注：只是get比post更不安全而已，其实Post也不安全，因为http是明文的。就算post把账号密码信息藏在request body中照样可以被黑客所截获并直接读取明文。
- 4、get请求只能进行url编码，而post支持多种编码方式。
  - 在Form元素的语法中，EncType表明提交数据的格式 用 Enctype 属性指定将数据回发到服务器时浏览器使用的编码类型。 例如： application/x-www-form-urlencoded： 窗体数据被编码为名称/值对。这是标准的编码格式。 multipart/form-data： 窗体数据被编码为一条消息，页上的每个控件对应消息中的一个部分，这个一般文件上传时用。 text/plain： 窗体数据以纯文本形式进行编码，其中不含任何控件或格式字符。
  - 当action为get时候，浏览器用x-www-form-urlencoded的编码方式把form数据转换成一个字串（name1=value1&name2=value2…），然后把这个字串append到url后面，用?分割，加载这个新的url。
  - 当action为post时候，浏览器把form数据封装到http body中，然后发送到server。 如果没有type=file的控件，用默认的application/x-www-form-urlencoded就可以了。 但是如果有type=file的话，就要用到multipart/form-data了。浏览器会把整个表单以控件为单位分割，并为每个部分加上Content-Disposition(form-data或者file),Content-Type(默认为text/plain),name(控件name)等信息，并加上分割符(boundary)。
- 5、get请求浏览器主动cache，而post 请求不会被缓存。
  - 缓存是一种保存资源副本并在下次请求时直接使用该副本的技术，当 web 缓存发现请求的资源已经被存储，它会拦截请求，返回该资源的拷贝，而不会去源服务器重新下载。css样式文件、js文件、logo、图标、html文件、可以下载的内容等等不经常改变的文件都可能被浏览器缓存。
  - **HTTP缓存**的基本目的就是使应用执行的更快，更易扩展，但是HTTP缓存通常只适用于idempotent request（可以理解为查询请求，也就是不更新服务端数据的请求），这也就导致了**在HTTP的世界里，一般都是对Get请求做缓存，Post请求很少有缓存。**
    - get多用来直接获取数据，不修改数据，主要目的就是DB的search语句的感觉。用缓存(有个代理服务器的概念)的目的就是查db的速度变快。
    - post则是发送数据到服务器端去存储。类似db里的update delete和insert语句的感觉。更新db的意思。数据必须放在数据库，所以一般都得去访问服务器端。
- 6、get请求参数会被完整保留在浏览历史记录里，而post中的参数不会被保留。
- 7、GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。
- 8、GET产生一个TCP数据包；POST产生两个TCP数据包。
  - 备注：header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。
- ![image-20210116174138285](http://pichost.yangyadong.site/img/image-20210116174138285.png)

## 5.数据库登录注册相关

### 1.登录说一下？

- 1.载入数据表
  - 在程序刚运行时，执行到epoll_wait之前，会有一个初始化map的操作。将数据库里现有的所有账号密码读到一个map里。
  - （另一种策略是除了map留一份，在本地txt也留存一份，方便cgi进程不需要访问数据库，直接读取txt就行）
-  2.提取用户名和密码 
  - 把post请求里的账号密码提取出来"user=123&passwd=123"
- 3.登录校验
  - 在map里查找用户名及其对应的密码。如果不存在或者密码错误则返回登录失败的网页。
  - 备注：用的是同步线程验证，没有使用cgi程序
-  4.页面跳转
  - 如果验证成功，则返回登陆成功的网页

### 2.你这个保存状态了吗？如果要保存，你会怎么做？（cookie和session）

- HTTP 是无状态的一种协议，换句话说，服务器记不住你，可能你每刷新一次网页，就要重新输入一次账号密码进行登录。
- 使用cookie可以让http变得有状态。cookie 的作用就好比服务器给你贴个标签，然后你每次向服务器再发请求时，服务器就能够 cookie 认出你。
- **一个 cookie 可以认为是一个「变量」**，形如 `name=value`，**存储在浏览器**；**一个 session 可以理解为一种数据结构**，多数情况是「映射」（键值对），**存储在服务器上。**
  - 我说的是「一个」cookie 可以认为是一个变量，但是服务器可以一次设置多个 cookie，所以有时候说 cookie 是「一组」键值对儿，这也可以说得通。
- session 配合 cookie 解决这一问题，比如说一个 cookie 存储这样一个变量 `sessionID=xxxx`，仅仅把这一个 cookie 传给服务器，然后服务器通过这个 ID 找到对应的 session，这个 session 是一个数据结构，里面存储着该用户的购物车等详细信息，服务器可以通过这些信息返回该用户的定制化网页，有效解决了追踪用户的问题。
- **session 是一个数据结构，由网站的开发者设计，所以可以承载各种数据**，只要客户端的 cookie 传来一个唯一的 session ID，服务器就可以找到对应的 session，认出这个客户。
- 当然，由于 session 存储在服务器中，肯定会消耗服务器的资源，所以 session 一般都会有一个过期时间，服务器一般会定期检查并删除过期的 session，如果后来该用户再次访问服务器，可能就会面临重新登录等等措施，然后服务器新建一个 session，将 session ID 通过 cookie 的形式传送给客户端。

### 3.登录中的用户名和密码你是load到本地，然后使用map匹配的，如果有10亿数据，即使load到本地后hash（其实就相当于是mysql分页查询？hash是指分文件？），也是很耗时的，你要怎么优化？（这是用cgi时的方案）

- 就是mysql的分页查询？
- 那就不构造map了，一次次在mysql里分页查询
- 要不就直接上redis
- 要不就redis+mysql？redis当缓存，用来保存高频记录

### 4.用的mysql啊，redis了解吗？用过吗？

#### 简介

- MySQL是关系型数据库，可以通过多字段的检索来确定数据，而且，基于硬盘的存储，容量会大得多；Redis是NOSQL,即非关系型数据库,也是缓存数据库,即将数据存储在内存中,内存的读取速度快,能够大大的提高运行效率。
- MySQL作为持久化存储的关系型数据库,相对薄弱的地方在于每次请求访问数据库时，**都存在着I/O操作**，如果反复频繁的访问数据库.第一:会在反复链接数据库上花费大量时间，从而导致运行**效率过慢**，第二:反复的访问数据库也会导致数据库的负载过高；Redis数据库就是一款缓存数据库,用于存储使用频繁的数据,这样减少访问数据库的次数,提高运行效率.
  - 缓存就是数据交换的缓冲区(cache)当浏览器执行请求时,首先会对在缓存中进行查找,如果存在就获取;否则就访问数据库.（缓存一定是在内存中）
-  MySQL支持sql查询,可以实现一些关联的查询以及统计;
- MySQL偏向于存数据,Redis偏向于快速取数据,但Redis查询复杂的表关系时不如MySQL,所以可以把热门的数据放Redis,MySQL存基本数据.
- 使用redis时，一般会有两种场景：
  - 1.redis作为纯cache，需要 + mysql 一起。redis作纯 cache 就是把数据从 mysql 先写入 redis，用户先读 cache，miss 后再拉取 MySQL，同时 cache 做同步。
  - 2.redis作storage。一定要做好数据的持久化，必须开启 rdb 和 aof，这会导致业务只能使用一半的机器内存，所以要做好容量的监控，及时扩容。另外只要有数据 copy，就会有一致性问题，这就是另外一个很重要的话题了。

#### 自己的总结

- mysql是经典的关系型数据库，而redis是非关系型数据库。
- 这两者的主要差异在于查询：mysql则只能通过sql语句来进行查询，不能直接通过key来获取value；redis只能用key去获取value，不支持sql语句来进行查询，不能进行多条件联合检索。
- mysql的查询则是通过扫描表来进行，读取的速度取决于数据量，以及是否有合适的索引；redis的数据读取过程的时间复杂度是O(1)，也就是说和数据量无关。再加上数据保存在内存，所以读取速度在理论上已经达到了上限。
- 并且redis有缓存机制，对于频繁访问查询的数据，它的效率更高；而mysql对于再频繁查询的数据，也只会一遍又一遍的去机械重复性地查询

## 6.定时器相关

### 1.为什么要用定时器？

- 如果某一用户`connect()`到服务器之后，长时间不交换数据，一直占用服务器端的文件描述符，导致连接资源的浪费。这时候就应该利用定时器把这些超时的非活动连接释放掉，关闭其占用的文件描述符。这种情况也很常见，当你登录一个网站后长时间没有操作该网站的网页，再次访问的时候你会发现需要重新登录。

### 2.说一下定时器的工作原理

- 定时器容器：每个定时事件封装成一个定时器，所有定时器串联起来构成容器。容器可以是链表、时间轮、最小堆。
- 本项目用的容器是升序双向链表。
  - 升序定时器链表中将其中的定时器按照超时时间（超时时间在项目里使用的是绝对时间，就是那年那月几点几分那个绝对时间）做升序排序
  - 切记：expire就是绝对时间。它代表了从1970到现在的秒数。谁的expire越小，说明越早要触发定时。它就越处于链表的头部方向。谁的expire值越大，谁就越处于链表的尾部方向。（升序就是按expire的值来升序的）
- 驱动定时的动力可以有：socket选项（SO_RCVTIMEO、SO_SNDTIMEO）、SIGALRM信号（有alarm或者setitimer函数周期性触发信号）、epoll里的超时参数（epoll_wait里的最后一个参数）。
  - 本项目的驱动定时的动力肯定是SIGALRM信号。由alarm函数周期性触发。
- SIGALRM信号每次被触发，就执行一次`void sort_timer_lst::tick()`即脉搏函数。该函数首先获取当前系统时间，然后从头结点开始依次检查每个定时器，是否到时间了（即比较当前时间和每个节点的expire）。如果已经到时间了，那么就调用 `当前节点->cb_func(当前节点->user_data)`。将用户数据传入回调函数中，以执行定时任务。
  - 定时任务就是 删除非活动连接（即到时间的连接）在socket上的注册事件，并关闭该connfd。
- 类中还封装了：
  - 添加某个定时器timer至升序定时器链表中：`void add_timer(util_timer *timer)`
    - 重载的辅助函数，用于在add_timer中将定时器添加到合适位置。`void add_timer(util_timer *timer, util_timer *lst_head);`
    - 换句话说，`void add_timer(util_timer *timer)`只能处理简单的添加任务（比如添加至头尾节点），当定时器要添加到链表中间某个位置时，就得调用辅助函数`void add_timer(util_timer *timer, util_timer *lst_head);`
  - 某个定时器的expire值手动增大了，要手动调整该定时器在链表中的位置：`void adjust_timer(util_timer *timer)`
    - 当该connfd上收到新的数据时，或者服务器要向connfd上写入新的数据时，定时器的超时时间都要重新设置为当前时间的15秒后
  - 从升序定时器链表中删除某个定时器timer：`void del_timer(util_timer *timer)`
    - 断开一个connfd连接时，都要删除对应的定时器
- 相当于是每多少（TIMESLOT=5）秒，SIGALRM信号就触发一次，就执行一次tick脉搏函数，就开始检查一次链表上所有到期的定时器。因此这5s内，不管你是第1秒还是第2秒第三秒就到时了，都得等到第5秒才能去处理定时任务。因此周期TIMESLOT就反应了精度，它越小，则精度越高。

### 3.双向链表啊，删除和添加的时间复杂度说一下？还可以优化吗？

升序链表的复杂度？

- 添加一个定时器的复杂度：O(n)
  - 因为要保证升序，最坏就是添加到末尾呗
- 删除一个定时器的复杂度：O(1)
  - 直接删除，就修改一下该节点相邻节点的指向
- 执行定时任务的时间复杂度：O(1)
  - 备注：因为已经排好序了，比时间更大的定时器之后的定时器就不用检查了，因此执行定时任务的时间复杂度可以算作O(1)

优化

- 每次遍历添加和修改定时器的效率偏低(O(n))，使用最小堆结构可以降低时间复杂度降至(O(logn))。
- 每次以固定的时间间隔触发`SIGALRM`信号，调用`tick`函数处理超时连接会造成一定的触发浪费，举个例子，若当前的`TIMESLOT=5`，即每隔5ms触发一次`SIGALRM`，跳出循环执行`tick`函数，这时如果当前即将超时的任务距离现在还有`20ms`，那么在这个期间，`SIGALRM`信号被触发了4次，`tick`函数也被执行了4次，可是在这4次中，前三次触发都是无意义的。对此，我们可以动态的设置`TIMESLOT`的值，每次将其值设置为**当前最先超时的定时器与当前时间的时间差**，这样每次调用`tick`函数，超时时间最小的定时器必然到期，并被处理，然后在从时间堆中取一个最先超时的定时器的时间与当前时间做时间差，更新`TIMESLOT`的值。

### 4.最小堆优化？说一下时间复杂度和工作原理

- 时间轮？
  - P206
  - 基于升序链表的定时器使用唯一的一条链表来管理所有定时器，所以插入操作的效率随着定时器数目的增多而降低。
  - 而时间轮采用哈希表的思想，将定时器散列到不同的链表上。这样每条链表上的定时器数目都将明显少于原来的排序链表上的定时器数目，插入操作的效率基本不受定时器数目的影响。
    - 备注：时间轮上的各个链表不是升序排列的，每次触发到该槽时，就遍历该槽对应链表上的所有定时器，判断每个定时器是否到时间了
  - 添加一个定时器的复杂度：O(1)
    - 不用保证升序，直接添加到某个槽对应的链表尾
  - 删除一个定时器的复杂度：O(1)
    - 直接删除，就修改一下该节点相邻节点的指向
  - 执行定时任务的时间复杂度：O(n)
    - 备注，每次到时间了，都得遍历一下该槽对应的整条链表。
    - 但实际上执行一个定时器任务的效率要比O(n)好得多，因为时间轮将所有的定时器散列到了不同的链表是哪个。时间轮的槽越多，那一条槽上的链表长度就越短，执行定时任务的时间复杂度就越低。
  - 总结：时间轮相比单条升序链表，是大大降低了添加定时器的复杂度，但是略微增加了执行定时任务的时间复杂度
    - （执行定时任务的时间复杂度的区别就在于还用不用遍历一遍链表，来看看哪些定时器到时间了，哪些没有）
- 时间最小堆：
  - 最快要到期的定时器位于堆顶。下一次的心博函数执行的时间就设置为堆顶定时器（即最快要到期的定时器）的时间。
  - 添加一个定时器的时间复杂度是：O(lgn)
  - 删除一个定时器的复杂度：O(1)
  - 执行定时任务的时间复杂度：O(1)

## 7.日志相关

### 1.说下你的日志系统的运行机制？

- log日志是个单例类，使用单例懒汉的c++局部变量实现。
- 同步日志：就是主线程产生日志文件后，自己直接fputs到文件，没有阻塞队列，也没有额外的一个专门从阻塞队列取日志并写入文件的线程。
- 阻塞队列
  - 里边是一条条的日志记录。
  - 只有异步日志模式才会用的到。异步日志模式的原理是，主线程（相对于异步线程是主线程，其实是工作线程）往阻塞队列上push一条条的记录；异步线程是从阻塞队列上pop一条条的记录，然后异步线程紧接着fputs到日志文件中
    - 在我的实现中，只有一个异步线程，理论上也可以多个
  - 主线程往阻塞队列上push，因此主线程相当于生产者；异步线程从阻塞队列上pop，异步线程相当于消费者
- 异步日志：异步体现在有一个额外的线程去从阻塞队列取一条日志记录string，然后写入日志文件。有且仅有一个异步线程（理论上也可以多个，不过好像多了也没什么好处，因为往文件里fputs也要加锁的，有一个线程不断去取记录，fputs到文件，就足够了，多个线程在这种不断地加锁解锁中，好像没啥速度提升），相当于一个消费者线程，不断地去阻塞队列上取出记录，然后fputs到文件上。该异步线程是在init函数中pthread_create的
- 同步和异步模式，主线程都要执行write_log函数。
  - 区别在于异步模式时，主线程执行write_log时，是往阻塞队列放一条条的记录，异步线程去阻塞队列取记录，然后异步线程fputs到文件。
  - 同步模式时，主线程执行write_log时，直接主线程自己fputs到文件。

- 互斥锁
  - 1.用来保护对文件中写入这个操作的线程安全。或者更精确的说法是，保护文件这个流的输出缓冲区的线程安全。
    - 例如`fputs(single_log.c_str(), my_fp);//把字符串single_log写入到指定的流 my_fp 中，但不包括空字符。`之前要加锁
    - 例如`fflush(my_fp);`刷新输出缓冲区之前，也要加锁
  - 2.用来保护类内人工缓冲区（这里其实是暂存格式化以后的结果，准备放入队列或者直接写入文件）
    - 例如：write_log函数内，修改`char* my_buf;//人工日志缓冲区`时，要加锁。
- 流程图：
  - ![image-20210329164610144](http://pichost.yangyadong.site/img/image-20210329164610144.png)

### 2.为什么要异步？和同步的区别是什么？

- 异步体现在有一个额外的线程去从阻塞队列取一条日志记录string，然后写入日志文件。有且仅有一个异步线程（理论上也可以多个，不过好像多了也没什么好处，因为往文件里fputs也要加锁的，有一个线程不断去取记录，fputs到文件，就足够了，多个线程在这种不断地加锁解锁中，好像没啥速度提升），相当于一个消费者线程，不断地去阻塞队列上取出记录，然后fputs到文件上。该异步线程是在init函数中pthread_create的
- 异步的好处是主线程可以迅速的去执行其他命令，不必主线程亲自执行写入文件的操作。因为写入文件这个IO事件还是比较慢的，这样做可以提升程序的效率。
- 和同步的区别：
  - 同步日志：是主线程自己把一行日志（其实就是一个string）fputs到日志文件
  - 异步日志：主线程把一行日志放入阻塞队列中，让异步线程来fputs到日志文件。

### 3.现在你要监控一台服务器的状态，输出监控日志，请问如何将该日志分发到不同的机器上？（redis的消息队列）

- 多机器，借助redis数据库的消息队列的发布订阅模式。实现分布式日志系统。
- 让很多机器都订阅一个channel，比如`subscribe test`
  - 例如让客户端A订阅了test这个channel
    - ![image-20210419110736983](http://pichost.yangyadong.site/img/image-20210419110736983.png)
    - 它会阻塞在这里，等待消息
- 客户端B往test这个channel上发布信息  `publish test hhhhahahaha`
  - ![image-20210419110826605](http://pichost.yangyadong.site/img/image-20210419110826605.png)
- 客户端A就收到了这个消息
  - ![image-20210419110854476](http://pichost.yangyadong.site/img/image-20210419110854476.png)
  - 收到了一条message，是test这个channel上的，消息内容是hhahahaha
- 根据这样的原理，将日志发送给多个客户端

## 8.压测相关

### 1.服务器并发量测试过吗？怎么测试的？

- 用的压测软件叫做Webbench
- `./webbench -c 9500 -t 1 --http11 http://127.0.0.1:12345/`
  -  `-c|--clients <n>         Run <n> HTTP clients at once. Default one.`。相当于同时有9500个浏览器在访问网站
  - `-t|--time <sec>          Run benchmark for <sec> seconds. Default 30.` -运行测试时间，也就是1s内收到的回复，即浏览器发送的http响应。换句话说，这是在测试服务器1秒钟之内能处理多少请求。
  - `--http11`使用http1.1
  - 备注：模拟9500个客户连接，当成功收到请求后继续再次发生GET。直到定时器到时间，即1s。
- 结果：
  - pages/min表示每分钟输出的页面数，bytes/sec表示每秒传输的字节数，Requests:成功处理的请求数，failed：失败的请求的数。
  - 电脑配置有限，最多支持模拟9500个客户连接。
    - **9500 clients, running 1 sec.**
    - Requests: 6219 susceed, 0 failed.
    - Speed=373139 pages/min, 42350184 bytes/sec.
      - （speed=requests/1s*60s）
    - 备注：
      - webbench跟浏览器不一样，它只去要html文件，不会自动再索要css、js等文件
      - **服务器一秒钟 可返回 6219 次页面，42M数据。**

### 2.webbench是什么？介绍一下原理

- Webench是一款轻量级的网站测压工具
- 父进程fork若干个子进程，每个子进程在用户要求时间或默认的时间内对目标web循环（如果该子进程成功收到服务器的响应了，就再次向服务器发送请求，直到5秒后）发出实际访问请求。
- 父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息，父进程通过管道读端读取子进程发来的相关信息，子进程在时间到后结束，父进程在所有子进程退出后统计并给用户显示最后的测试结果，然后退出。

### 3.测试的时候有没有遇到问题？

- 一开始测试时，没有加 --http11命令，并发数值虽然很高有（即6000多pages/sec，其实这是成功收到request的频数），但是每秒钟收到的数据很少（即0.8M bytes/min）。
- 一看服务器日志，都是返回的404。原因是我的服务器程序里只接受http1.1，加上 --http11后，开始返回200。但是并发数值会降低，每秒收到的数据会增多。
- 即返回404时，1秒钟成功收到8000多requests，0.8M bytes/sec
- 返回200即html网页时，1秒钟成功收到6200多 requests，30M bytes/sec

### 4.你这个 server 的瓶颈在哪？

- **QPS（Query Per Second）：每秒请求数，就是说服务器在一秒的时间内处理了多少个请求。**
- server瓶颈是qps太低，webbench测试才6000。
  - 可能的解决方案：增加并发线程数、数据库连接数
- 主线程用的模拟的proactor模式，需要读取完数据才分发任务；而且任务分发机制也比较简单，让线程去竞争请求队列上的任务。
  - 可能的解决方案：换成reactor会比proactor效率高些，因为主线程不用自己去完成socket上的IO任务了，让线程池中的线程去完成socket上的IO任务
- 处理http请求使用的也是同步线程处理，使用cgi程序可能会更快一些？
- 只有一个epoll：
  - 负责了 listenfd、多个connfd、管道（信号可读可写）等等

## 9.综合能力

### 1.说一下前端发送请求后，服务器处理的过程，中间涉及哪些协议？

#### 服务器处理的过程

- 1.主线程上的listenfd可读，触发epoll_wait。说明有新的客户连接到达，在主线程中accept一个连接，将该连接即connfd的可读事件加入内核事件表（**oneshot**）；
- 2.刚才加入epoll的connfd上收到http的GET请求，即connfd可读了，主线程将数据从socket conn上读出来，封装到http_conn对象放入请求队列中，等待工作线程（线程池中的子线程）来处理请求
- 3.线程池中的线程竞争去处理请求队列上的http_conn对象，某个子线程获得后，就开始执行`request->process()`，对调用http_conn类内的process函数进行处理。

- 4.通过主从状态机来分析该http请求，并做出响应报文。响应报文的状态行和首部行放在一个buffer里，要返回的html文件mmap到内存中。然后触发connfd上的可写事件。
- 5.主线程epoll_wait触发，主线程将buffer里的响应报文的状态行和首部行以及内存中的html文件数据一起写入socket连接上。
- 6.等待定时器到时间后，关闭该connfd。

#### 中间涉及哪些协议

- IPv4协议
- TCP协议
- HTTP协议

