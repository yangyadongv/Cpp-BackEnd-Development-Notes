[TOC]

# 操作系统

## 1.CPU

### 1.请你说一下进程与线程的概念，以及为什么要有进程线程，其中有什么区别，他们各自又是怎么同步的

#### 1.进程与线程的基本概念：

- **进程**是对运行时程序的封装，是系统进行**资源调度**和**分配**的的基本单位，实现了操作系统的并发；
- **线程**是进程的**子任务**，**是CPU调度和分派的基本单位**，用于保证程序的实时性，实现**进程内部的并发**；线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个**线程**完成不同的任务，但是**共享**同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核**资源**。
  - 共享资源包括：内存、文件句柄、锁资源、映射文件、目标代码、打开的文件队列、其他内核资源等



#### 2.进程与线程的区别：

- 1.一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。
- 2.**进程**在执行过程中**拥有独立的内存单元**，而**多个线程共享进程的内存**。（资源分配给进程，**同一进程的所有线程共享该进程的所有资源**。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。**但是每个线程拥有自己的栈段**，栈段又叫运行时段，**用来存放函数调用时的传参，函数调用的返回地址，函数调用前后需要保持不变的寄存器。还有非静态局部变量和临时变量等等**。）
  - 用户级线程，几个线程几个栈（TCB切换，根据TCB切换来切换用户栈）
  - 核心级线程几个线程几套栈（TCB切换，根据TCB切换来切换一套栈，即用户栈和核心栈，1套就是指这2个）
- 3.进程是**资源分配的最小单位**，线程是**CPU调度的最小单位**；
- 4.**系统开销**： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I/O设备等。因此，操作系统**创建或撤销进程**所付出的**开销**将显著地**大于**在**创建或撤消线程**时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，**进程切换的开销**也远**大于线程切换的开销**。
  - ①1.**进程切换**要切换虚拟地址空间，也就是**切换页表**（PCB里只有页表的位置，没有页表的内容，页表是在内存中的。其实切换页表的开销不大，主要是TLB失效的开销很大）；2.并且切换页表以后，**TLB**就**失效**了，然后从虚拟内存到物理内存的换算过程将大幅提高。（TLB即联想寄存器，也就是快表，里边存了最近访问的虚拟内存和物理内存的访问关系，根据局部性原理可以大大提高地址从虚拟内存到物理内存的换算速度。因为TLB记录的是最近本进程的常访问的虚拟内存到物理内存的映射关系，你切换页表后，映射关系完全不同了，之前记录的TLB就失效了。新的进程想用TLB，得重新记录。）;
  - ②1.**线程切换**不需要切换地址空间，也就是**不用切页表**，因为不同线程是共用内存的，所以开销小多了;（**TLB还可以用**，可以高效的进行虚拟地址到物理地址的换算，反观进程切换，TLB失效了，高效性没了，重新记录上TLB才能恢复高效性）2.线程切换时只需保存和设置少量寄存器内容，开销很小。
  - 精简版：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
- 5.**通信**：由于同一进程中的**多个线程**具有相同的地址空间，致使它们**之间的同步和通信**的实现，也变得**比较容易**。进程间通信IPC（Inter-Process Communication，进程间通信），线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预。
- 6.进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。
- 7.进程间不会相互影响 ；线程**一个线程挂掉**将导致**整个进程挂掉**(挂掉，不是指阻塞)
  - 当一个线程向非法地址读取或者写入，无法确认这个操作是否会影响同一进程中的其它线程，所以只能是整个进程一起崩溃。
  - 线程有自己的栈(stack)和局部变量，但线程没有单独的堆（heap）和地址空间（address space），一个线程死掉(一般是栈溢出、读取或者访问了非法地址)就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮。
- 8.进程适应于多核、多机分布；线程适用于多核
  - 多机?可能是不同主机之间的进程通信？



#### 3.进程间通信的方式：

进程间通信主要包括管道、系统IPC（包括消息队列、共享内存、信号量、信号等）、以及套接字socket。

https://zhuanlan.zhihu.com/p/104713463

- **1.管道：**
  - 管道主要包括无名管道和命名管道:**普通匿名管道**可用于具有亲缘关系的**父子进程间的通信**，**有名管道**除了具有管道所具有的功能外，它还**允许无亲缘关系进程间的通信**。
  - 1.1 普通匿名管道PIPE：
    - 1)它是半双工的（即某一时间段内数据只能在一个方向上流动），具有固定的读端和写端
    - 2)它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）
    - 3)它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是**它不是普通的文件**，并**不属于其他任何文件系统**，并且**只存在于内存中**。
  - 1.2 命名管道FIFO：
    - 1)FIFO可以在无关的进程之间交换数据
    - 2)FIFO有路径名与之相关联，**它以一种特殊设备文件**形式**存在于文件系统中**。
    - 3)其他的跟普通管道一样，它也时半双工的，各进程应该互斥访问
  - **自己总结的：管道**
    - **特点**：①管道的通知机制类似于缓存，就像一个进程把数据放在某个缓存区域，然后等着另外一个进程去拿；②并且是管道是**单向传输**的，要想同时双向得用两个管道；③**a 进程给 b 进程传输数据，只能等待 b 进程取了数据之后 a 进程才能返回**。
    - **优缺点**：这种方式，通信效率低下（因为单向，并且a 进程给 b 进程传输数据，只能等待 b 进程取了数据之后 a 进程才能返回），不适合频繁通信的进程。优点是简单，能够保证数据被拿走。
- 2.系统IPC（Inter-Process Communication）：
  - 2.1 **消息队列**
    - 消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。 （消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点) 具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；
    - 特点：
    - 1)消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。
    - 2)消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。
    - 3)消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。
  - **自己总结的：消息队列**
    - 特点：例如 a 进程要给 b 进程发送消息，只需要把消息放在对应的消息队列里就行了，然后进程a就可以返回了，**无需等待**。b 进程需要的时候再去对应的消息队列取出来。
    - 优缺点：如果a进程发送的数据占用的内存比较大，并且两个进程通信特别频繁，那么意味着发送消息（也就是拷贝）这个过程要花很长时间读内存。
  - 2.2 **共享内存（Shared Memory）**
    - 它使得**多个进程可以访问同一块内存空间**，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等
    - 特点：
    - 1)共享内存是最快的一种IPC，因为进程是直接对内存进行存取
    - 2)因为多个进程可以同时操作，所以需要进行同步、互斥（上锁）
    - 3)**信号量+共享内存通常结合在一起使用**，信号量用来同步对共享内存的访问
  - **自己总结的：共享内存**
    - 特点：解决消息队列那个发送消息的拷贝操作所带来的时间开销。
    - 可以让两个进程各自拿出一块虚拟地址空间来，然后映射到相同的物理内存中，这样，两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了内存共享机制了。
  - 2.3 **信号量semaphore**（用于进程同步、进程互斥的，**主要是配合共享内存使用**，自己并不能用作进程通信）
    - 信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量**用于实现进程间的互斥与同步**，而**不是用于存储进程间通信数据**。
    - 特点：
    - 1)信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。
    - 2)信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。
    - 3)每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。
    - 4)支持信号量组。
  - **自己总结的：信号量**
    - 主要是配合共享内存使用，用于互斥或者同步访问共享内存。它自己并不能用于进程通信
  - 2.4 信号signal（没听过）
    - 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
- 3.套接字SOCKET

  - socket也是一种进程间通信机制，与其他通信机制不同的是，它**可用于不同主机之间的进程通信**。
  - 自己总结的：SOCKET
    - 在Internet上的主机一般运行了多个服务软件，同时提供几种服务。每种服务都打开一个Socket，并绑定到一个端口上，不同的端口对应于不同的服务。

#### 4.线程通信（线程互斥、线程同步）

- **线程间通信**的方式:**（线程互斥或者是同步）**
- 线程间资源时共享的，所以**讲线程间通信主要是讲保证安全的措施，或者说是实现线程同步、线程互斥。**
- 总结来说就是：临界区、互斥锁mutex、条件变量、semaphore
  - 临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；
    - 在任意时刻只允许一个线程对共享资源进行访问。如果有多个线程试图同时访问临界区，那么在有一个线 程进入后其他所有试图访问此临界区的线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操 作共享资源的目的。 
    - 实现互斥
  - 互斥量Synchronized/Lock/mutex：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
    - 也就是互斥锁，实现互斥
  - 信号量Semaphore：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。
    - 信号量机制实现互斥或者同步
  - 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。
    - 即条件变量上的wait 和 notify操作
    - 互斥或者同步，一般是同步

### 2.并发与并行

- 并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核CPU上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。
  - 指多个进程在**同一时间间隔**内发生。这些事件**宏观上是同时发生**的，但**微观上是交替发生**的。
- 并行（parallelism）：指严格物理意义上的同时运行，比如多核CPU，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的CPU都是往多核方面发展。
  - 指两个或多个线程在**同一时刻**同时执行。
- **单核CPU**同一时刻只能执行一个程序，各个程序**只能并发**地执行
  **多核CPU**同一时刻可以同时执行多个程序，多个程序**可以并行**地执行(**当然也有并发**)

### 3.有了进程为什么还要有线程

#### 1.线程产生的原因：

进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺点：

- 进程在同一时间只能干一件事
- 进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。

#### 2.线程的优势

因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性。和进程相比，**线程的优势如下：**

- 从资源上来讲，线程是一种非常"节俭"的多任务操作方式。在linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种"昂贵"的多任务工作方式。
- 从切换效率上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间。据统计，一个进程的开销大约是一个线程开销的30倍左右。（
- 从通信机制上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进城下的线程之间贡献数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。

除以上优点外，多线程程序作为一种多任务、并发的工作方式，还有如下优点：

1、使多CPU系统更加有效。操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上。（并行）

2、改善程序结构。一个既长又复杂的进程可以考虑分为多个线程，成为几个独立或半独立的运行部分，这样的程序才会利于理解和修改。



### 4.请问单核机器上写多线程程序，是否需要考虑加锁，为什么？

在单核机器上写多线程程序，仍然需要线程锁。因为线程锁通常用来实现线程的同步和通信。**在单核机器上的多线程程序，仍然存在线程同步的问题。**因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。**如果这两个线程共享某些数据，不使用线程锁的前提下，可能会导致共享数据修改引起冲突。**

### 5.请问线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的

概述：

- 进程是由内核管理和调度的，**进程的切换**只能发生在内核态。 因此，**进程的上下文不但包括虚拟内存、栈、全局变量等用户空间资源，还包括内核堆栈、寄存器等内核空间状态**。所以，进程的上下文切换比系统调用多一个步骤：保存当前进程的内核状态和 CPU 寄存器之前，先把该进程的虚拟内存、栈等保存起来；加载下一个进程的内核态后，还需要刷新进程的虚拟内存和用户栈。保存上下文和恢复上下文需要内核在 CPU 上运行才能完成。
- 内核中的任务调度实际是在调度线程，进程只是给线程提供虚拟内存、全局变量等资源。**线程上下文切换**时，共享相同的虚拟内存和全局变量等资源不需要修改。而线程自己的私有数据，如**栈和寄存器**等，上下文切换时需要保存。

准确答案：

- 线程在切换的过程中需要保**存当前线程Id、线程状态、堆栈、寄存器状态等**信息。其中寄存器主要包括SP PC EAX等寄存器，其主要功能如下：

SP:堆栈指针，指向当前栈的栈顶地址

PC:程序计数器，存储下一条将要执行的指令

EAX:累加寄存器，用于加法乘法的缺省寄存器

### 6.线程间的同步方式，最好说出具体的系统调用(其实是c++库函数？)

**参看LeetCode那里的知识总结**

- 1.信号量semaphore
  - 信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：
    - P(S):如果信号量S大于0，将它减一；如果S值为0，则挂起该线程。
    - V(S)：如果有其他进程因为等待S而挂起，则唤醒，然后将S+1；否则直接将S+1。
  - 其系统调用为：
    - sem_wait（sem_t *sem）：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。
    - sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。
  - 
- 2.互斥量mutex
  - 互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区    时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。
  - c++11中：
    - mutex m;//互斥锁，即信号量为1
    - m.lock();//即P(m)
    - m.unlock();//即V(m)
- 3.条件变量
  - 条件变量，又称条件锁，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。
  - c++ 11中
    - std::condition_variable con1;//条件变量。相当于一种资源的阻塞队列。
    -  std::mutex my_mutex;//互斥量，就是最简单的进程互斥。
    - std::unique_lock<std::mutex> lk(my_mutex);
    - con1.wait(lk,[this]()->bool{return counter==2;}); // 阻塞当前线程，直到条件变量被唤醒。并且会释放lk，即解锁，好让其他线程执行。 [this]()->bool{return counter==2;}是Lambda表达式
    -  con1.notify_one();//若任何线程在con1上等待，则调用 notify_one 会解阻塞(唤醒)等待线程之一。
              //换句话说，con1.notify_one()是con1.wait()的唤醒

### 7.多线程和多进程的区别（不是进程和线程的区别）

#### 1.多线程和多进程的区别

进程是资源分配的最小单位，而线程时CPU调度的最小单位。**多线程**之间共享同一个进程的地址空间，**线程间通信简单**，同步复杂，线程创建、销毁和切换简单，速度快，占用内存少，适用于多核分布式系统，但是线程间会相互影响，**一个线程意外终止会导致同一个进程的其他线程也终止，程序可靠性弱，也就是线程间隔离性差**。而**多进程**间拥有各自独立的运行地址空间，进程间不会相互影响，**程序可靠性强，即进程间隔离性好**，但是进程创建、销毁和切换复杂，速度慢，占用内存多，**进程间通信复杂**，但是同步简单，适用于多核、多机分布。

#### 2.适用场景：

- **多线程模型**主要优势为线程间切换代价较小，因此适用于**I/O密集型**的工作场景，因此I/O密集型的工作场景经常会由于I/O阻塞导致频繁的切换线程。同时，多线程模型也适用于**单机多核分布式**场景。
  - IO密集型：主要涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少,任务的大部分时间都在等待IO操作完成(因为IO的速度远远低于CPU和内存的速度)。对于IO密集型任务，任务越多，CPU效率越高,但也有一个限度。常见的大部分任务都是IO密集型任务,比如Web应用。
  - IO密集会频繁切换，假如用的多进程，就会频繁切换进程，代价大。
- **多进程模型**，适用于**重复操作多、且重复操作多为计算操作(CPU密集型)**，使用多进程，能够高效利用多核CPU资源，提升程序的运行速度。同时，多进程模型也适用于**多机分布式场景中，易于多机扩展。**
  - CPU密集型，那么切换的少。那么多线程和多进程都是一个线程（进程）一个核心并发执行，效率没差。但是出于稳定性考虑，没差时应该用多进程。因为多线程中，一个线程挂掉，整个进程就挂掉了。用多进程就不会有问题，一个进程一个核并行执行，一个进程挂掉不影响其他进程。

### 8.游戏服务器应该为每个用户开辟一个线程还是一个进程，为什么？

游戏服务器应该**为每个用户开辟一个进程**。因为同一进程间的线程会相互影响，一个线程死掉会影响其他线程，从而导致进程崩溃。因此**为了保证不同用户之间不会相互影响，应该为每个用户开辟一个进程**

### 9.死锁发生的条件以及如何解决死锁

（多线程多进程都类似的，都会死锁）

#### 1.死锁发生的条件

死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的下相互等待的现象。死锁发生的**四个必要条件**如下：

- 互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁(如哲学家的筷子、打印机设备)。像内存、扬声器这样可以同时让多个进程使用的资源是不会导致死锁的(因为进程不用阻塞等待这种资源)。
- 请求和保持条件：A进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求（也就是A进程）阻塞，但该进程（A进程）不会释放自己已经占有的资源
- 不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放
- 环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链，链中的每一个进程已获得的资源同时被下一个进程所请求。

#### 2.解决死锁的方法

- **预防死锁**：（破坏死锁产生的四个必要条件中的一个或几个。）
  - 破坏互斥条件：把只能互斥使用的资源改造为允许共享使用
  - 破坏请求和保持条件：资源一次性分配，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不让它投入运行。一旦投入运行后，这些资源就一直归它所有，该进程就不会再请求别的任何资源了。
  - 破坏不剥夺条件：方法①：当某个进程请求新的资源得不到满足时，它必须立即释放保持的所有资源，待以后需要时再重新申请。方法②：当某个进程需要的资源被其他进程所占有的时候，可以由操作系统协助，将想要的资源强行剥夺。这种方式一般需要考虑各进程的优先级（例如剥夺调度方式，就是剥夺CPU，也可以按这个思想剥夺任何资源）
  - 破坏循环等待条件：可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源（即编号相同的资源）一次申请完。
- **避免死锁**：（用某种方法防止系统进入不安全状态，从而避免死锁(银行家算法)）
  - **在资源分配之前预先判断这次分配是否会导致系统进入不安全状态**，以此决定是否答应资源分配请求。
  - 所谓**安全序列**，就是指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是**安全状态**。当然**，安全序列可能有多个**。如果分配了资源之后，系统中找不出任何一个安全序列，系统接下来就进入了**不安全状态**。
  - 简洁版：
    - 可利用资源向量，最大需求矩阵，分配矩阵，需求矩阵（参考王道OS笔记）
    - 每次试探着允许分配，然后进行安全性检查，一旦找不出一个安全序列，那么就拒绝这次请求
- **死锁检测和接触**：（允许死锁的发生，不过操作系统会负责检测出死锁的发生，然后采取某种措
  施解除死锁。）
  - 死锁检测算法:用于检测系统状态，以确定系统中是否发生了死锁。
  - 死锁解除算法:当认定系统中已经发生了死锁，利用该算法可将系统从死锁状态中解脱出来。

### 10.讲述一下互斥锁（mutex）机制，以及互斥锁和读写锁的区别

#### 1.互斥锁、读写锁机制

**互斥锁：**mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入阻塞，等待锁释放时被唤醒。

**读写锁：**rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入阻塞状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

#### 2.互斥锁和读写锁的区别：

1）读写锁区分读者和写者，而互斥锁不区分

2）互斥锁同一时间只允许一个线程访问该对象，无论读写；

​	  读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。

### 11.Linux的4种锁机制

- **1.互斥锁：**

  - mutex，用于保证**在任何时刻，都只能有一个线程访问该对象**。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

- **2.读写锁：**
  
  - rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。**当有一个线程获得写锁在写时，读锁也不能被其它线程获取**；写者优先于读者（一旦有写者，则后续读者必须等待，**唤醒时优先考虑写者**）。**适用于读取数据的频率远远大于写数据的频率的场合。**
  - 在没有写操作的时候，两个线程同时读一个资源没有任何问题，所以应该**允许多个线程能在同时读取共享资源**。但是如果**有一个线程想去写**这些共享资源，就**不应该再有其它线程对该资源进行读或写。**
  - 即互斥原则：
    - 读-读能共存，
    - 读-写不能共存，
    - 写-写不能共存。
  - 换个说法：
    - ①允许多个读者可以同时对文件执行读操作;
    - ②只允许一个写者往文件中写信息;
    - ③**任一写者在完成写操作之前不允许其他读者或写者工作;**
    - ④**写者执行写操作前，应让已有的读者和写者全部退出。**
  
- **3.自旋锁：**
  
  - spinlock，在任何时刻同样只能有一个线程访问对象。但是**当获取锁操作失败时，不会进入睡眠，而是会在原地自旋，直到锁被释放**。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但**如果加锁时间过长，则会非常浪费CPU资源**。
  - 自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快
  
- **4.RCU：**
  
  - 即read-copy-update，RCU锁是读写锁的扩展版本，简单来说就是**支持多读多写同时加锁**。在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改。修改完成后，再将老数据update成新的数据。使用RCU时，读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少量写操作的情况下效率非常高。
  
  - **访问原则：**
    - 读者访问临界资源时不加锁，只标记自己进入了临界资源区。
    - 写者如果要更新临界资源，首先拷贝一份要更新的数据，在拷贝上进行数据修改，修改完之后，将更新的数据作为后面进入临界区的读者要访问的数据，然后检查临界区是否有其它读者正在访问资源，如果有，等到所有读者资源访问结束，再删除旧的数据
  
  - **写者等待所有读者资源访问结束的这段时间，叫做宽限期**。**RCU访问原则的最终目的有两个：**
    - **在写者更新临界前已经访问临界区的读者**，**看到的临界区资源**在整个更新过程中**不会变化**
    - **在写者更新完后访问临界区的读者**，**看到的临界区资源是更新后的**
      注：RCU允许宽限期内的读者看到的临界区资源不一致。（不一致就在于读者是在写者更新之前还是之后来的，注意是写者更新前后，而不是原资源删除前后。更新就是指把副本更新了。）
  
  - RCU与读写锁的区别：（也就是说任意进程都共存，不互斥）
  
    - 1.写进程来的时候，不用等待其他所有的读写进程退出。直接修改副本。
  
    - 2.写者在更新临界区的时候，其他读写进程也可以执行。
  
      - 注意：（跟上边是一样的）
      - **在写者更新临界前已经访问临界区的读者**，**看到的临界区资源**在整个更新过程中**不会变化**
      - **在写者更新完后访问临界区的读者**，**看到的临界区资源是更新后的**
      - 等到更新临界区之前已经访问临界区的读者读完后，就把原数据删了，用写者更新的临界区去覆盖原数据。
  
      

### 12.进程状态转换图；动态就绪，静态就绪，动态阻塞，静态阻塞

#### 1.进程的转换图，也就是五种基本状态

![YU3PJg.png](https://s1.ax1x.com/2020/05/12/YU3PJg.png)

- 1）创建状态：进程正在被创建
- 2）就绪状态：进程被加入到就绪队列中等待CPU调度运行
- 3）执行状态：进程正在被运行
- 4）等待阻塞状态：进程因为某种原因，比如等待I/O，等待设备，而暂时不能运行。
- 5）终止状态：进程运行完毕

#### 2.交换技术（引出挂起态）

当多个进程竞争内存资源时，会造成内存资源紧张，并且，如果此时没有就绪进程，处理机会空闲，I/0速度比处理机速度慢得多，可能出现全部进程阻塞等待I/O。

针对以上问题，提出了两种解决方法：

1）交换技术：换出一部分进程到外存，腾出内存空间。（即页面置换）

2）虚拟存储技术：每个进程只能装入一部分必须的程序和数据。（即虚拟内存）

在交换技术上，将内存暂时不能运行的进程，或者暂时不用的数据和程序，换出到外存，来腾出足够的内存空间，把已经具备运行条件的进程，或进程所需的数据和程序换入到内存。

从而出现了进程的挂起状态：**进程被交换到外存，进程状态就成为了挂起状态**。凡是在外存，都挂起态（对应底下的静止）

#### 3.动态就绪，静态就绪，动态阻塞，静态阻塞

动态：在内存

静态：在外存

从5状态变成了7状态：多了 挂起阻塞（静态阻塞）和 挂起就绪（静态就绪）

1）活动阻塞：进程在内存，但是由于某种原因被阻塞了。

2）静止阻塞：进程在外存，同时被某种原因阻塞了。

3）活动就绪：进程在内存，处于就绪状态，只要给CPU和调度就可以直接运行。

4）静止就绪：进程在外存，处于就绪状态，只要调度到内存，给CPU和调度就可以运行。

从而出现了：

活动就绪 —— > 静止就绪    （内存不够，调到外存）

活动阻塞 —— > 静止阻塞    （内存不够，调到外存）

执行   ——>  静止就绪     （时间片用完）

### 13.用户态和内核态区别

用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。用户态拥有最低的特权级，内核态拥有较高的特权级。运行在用户态的程序不能直接访问操作系统内核数据结构和程序。内核态和用户态之间的转换方式包括：系统调用，异常和中断（这其实本质上都是中断）。也可以说唯一途径是中断。

### 14.如何设计server，使得能够接收多个客户端的请求（还不会）

多线程，线程池，io复用

### 15.死循环+来连接时新建线程的方法效率有点低，怎么改进？（还不会）

提前创建好一个线程池，用生产者消费者模型，创建一个任务队列，队列作为临界资源，有了新连接，就挂在到任务队列上，队列为空所有线程睡眠。改进死循环：使用select epoll这样的技术

### 16.怎么唤醒被阻塞的socket线程？（还不会）

给阻塞时候缺少的资源

### 17.就绪状态的进程在等待什么？

被调度使用cpu的运行权

### 18.多线程的同步中锁的具体细节

同步的时候用一个互斥量，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对互斥量进行加锁以后，任何其他试图再次对互斥量加锁的线程将会被阻塞直到当前线程释放该互斥锁。如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运行状态的线程可以对互斥量加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为可用。在这种方式下，每次只有一个线程可以向前执行

### 19.常用线程模型（不会）

https://www.cnblogs.com/PerkinsZhu/p/7570775.html

1、Future模型

该模型通常在使用的时候需要结合Callable接口配合使用。

Future是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。

Callable是类似于Runnable的接口，其中call方法类似于run方法，所不同的是run方法不能抛出受检异常没有返回值，而call方法则可以抛出受检异常并可设置返回值。两者的方法体都是线程执行体。

2、fork&join模型

该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一些可以进行拆分的大任务。其主要是把一个大任务逐级拆分为多个子任务，然后分别在子线程中执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果。

这里模拟一个摘苹果的场景：有100棵苹果树，每棵苹果树有10个苹果，现在要把他们摘下来。为了节约时间，规定每个线程最多只能摘10棵苹树以便于节约时间。各个线程摘完之后汇总计算总苹果树。

3、actor模型

actor模型属于一种基于消息传递机制并行任务处理思想，它以消息的形式来进行线程间数据传输，避免了全局变量的使用，进而避免了数据同步错误的隐患。actor在接受到消息之后可以自己进行处理，也可以继续传递（分发）给其它actor进行处理。在使用actor模型的时候需要使用第三方Akka提供的框架。

4、生产者消费者模型

生产者消费者模型都比较熟悉，其核心是使用一个缓存来保存任务。开启一个/多个线程来生产任务，然后再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费者只需要从缓存中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。比如，生成的任务速度较快，那么就可以灵活的多开启几个消费者线程进行处理，这样就可以避免任务的处理响应缓慢的问题。

5、master-worker模型

master-worker模型类似于任务分发策略，开启一个master线程接收任务，然后在master中根据任务的具体情况进行分发给其它worker子线程，然后由子线程处理任务。如需返回结果，则worker处理结束之后把处理结果返回给master。

### 20.说一说协程

https://www.jianshu.com/p/6dde7f92951e

https://www.liaoxuefeng.com/wiki/897692888725344/923057403198272

**1、概念：**

协程，又称微线程，纤程，英文名Coroutine。协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。

例如：

```python
def A() :
print '1'
print '2'
print '3'

def B() :
print 'x'
print 'y'
print 'z'
```

由协程运行结果可能是12x3yz。在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A。但**协程的特点在于是一个线程执行。**

自己的理解：

- 协程就是在一个线程上，按一定顺序（各协程的切换时机是用户控制的）执行各个子函数。注意**不是简单的子函数调用**，子函数调用的顺序是明确的。而协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。在一个子程序中中断，去执行其他子程序，不是函数调用，有点类似CPU的中断。
- 一个线程内可以由多个这样的特殊函数（协程）在运行，但是有一点必须明确的是，**一个线程的多个协程的运行是串行的**。如果是多核CPU，多个进程或一个进程内的多个线程是可以并行运行的，但是一个线程内协程却绝对是串行的，无论CPU有多少个核。毕竟协程虽然是一个特殊的函数，但仍然是一个函数。一个线程内可以运行多个函数，但这些函数都是串行运行的。当一个协程运行时，其它协程必须挂起。
- **协程就是伪多线程**，想营造一种多线程执行的感觉，但实际上各个“线程”（其实就是指协程）是在同一个线程里串行执行的。就算多个核也不能做到并行。
- 在通俗点，就是想做到多线程，但实际上是单线程。假装多线程。

**2、协程和线程区别**

那和多线程比，协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。

第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

**3、其他**

在协程上利用多核CPU呢——多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。

Python对协程的支持还非常有限，用在generator中的yield可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。

[![Y6o8eI.png](https://s1.ax1x.com/2020/05/16/Y6o8eI.png)](https://imgchr.com/i/Y6o8eI)

### 21.系统调用是什么，你用过哪些系统调用

**1）概念：**

在计算机中，系统调用（英语：system call），又称为系统呼叫，指运行在使用者空间的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供了用户程序与操作系统之间的接口（即系统调用是用户程序和内核交互的接口）。

操作系统中的状态分为管态（核心态）和目态（用户态）。大多数系统交互式操作需求在内核态执行。如设备IO操作或者进程间通信。特权指令：一类只能在核心态下运行而不能在用户态下运行的特殊指令。不同的操作系统特权指令会有所差异，但是一般来说主要是和硬件相关的一些指令。用户程序只在用户态下运行，有时需要访问系统核心功能，这时通过系统调用接口使用系统调用。

应用程序有时会需要一些危险的、权限很高的指令，如果把这些权限放心地交给用户程序是很危险的(比如一个进程可能修改另一个进程的内存区，导致其不能运行)，但是又不能完全不给这些权限。于是有了系统调用，危险的指令被包装成系统调用，用户程序只能调用而无权自己运行那些危险的指令。另外，计算机硬件的资源是有限的，为了更好的管理这些资源，所有的资源都由操作系统控制，进程只能向操作系统请求这些资源。操作系统是这些资源的唯一入口，这个入口就是系统调用。

**自己的理解：**

- 什么是系统调用：
  - **“系统调用”**是操作系统提供给应用程序（程序员/编程人员）使用的接口，可以理解为一种可供应用程序调用的特殊函数，**应用程序可以通过系统调用来请求获得操作系统内核的服务**
- 为什么需要系统调用：
  - 系统中的各种共享资源都由操作系统内核统一掌管，因此**凡是与资源有关的操作**（如存储分配、I/O操作、文件管理等），**都必须通过系统调用的方式向操作系统内核提出服务请求**，由操作系统内核代为完成。这样可以**保证系统的稳定性和安全性**，防止用户进行非法操作。

**2）用过哪些系统调用**：

对文件进行写操作，程序向打开的文件写入字符串“hello world”，open和write都是系统调用。如下：

```c
#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<errno.h>
#include<unistd.h>
#include<sys/types.h>
#include<sys/stat.h>
#include<fcntl.h>
int main(int argc, char *argv[])
{
    if (argc<2)
        return 0;
    //用读写追加方式打开一个已经存在的文件
    int fd = open(argv[1], O_RDWR | O_APPEND);//fd代表这是当前进程中，打开的第几个文件
    if (fd == -1)
    {
        printf("error is %s\n", strerror(errno));
    }
    else
    {
        //打印文件描述符号
        printf("success fd = %d\n", fd);
        char buf[100];
        memset(buf, 0, sizeof(buf));
        strcpy(buf, "hello world\n");
        write(fd, buf, strlen(buf));
        close(fd);
    }
    return 0;
}
```

系统调用：

- open
- read
- write
- close
- fork()、vfork()

### 22.read系统调用的具体流程（没学会）

- 当调用发生时，库函数在保存 read 系统调用号以及参数（保存到了寄存器）后，陷入 0x80 中断。这时库函数工作结束。Read 系统调用在用户空间中的处理也就完成了。 
- 0x80 中断（这个中断专门用于处理系统调用）处理程序接管执行后，先检察其系统调用号，然后根据系统调用号查找系统调用表，并从系统调用表中得到处理 read 系统调用的内核函数 sys_read ，最后传递参数并运行 sys_read 函数。 
- 读数据之前，必须先打开文件。处理 open 系统调用的内核函数为 sys_open
  - get_unuesed_fd() ：取回一个未被使用的文件描述符（每次都会选取最小的未被使用的文件描述符）。
  - filp_open() ：调用 open_namei() 函数取出和该文件相关的 dentry 和 inode （因为前提指明了文件已经存在，所以 dentry 和 inode 能够查找到，不用创建），然后调用 dentry_open() 函数创建新的 file 对象，并用 dentry 和 inode 中的信息初始化 file 对象（文件当前的读写位置在 file 对象中保存）。
  - fd_install() ：以文件描述符为索引，关联当前进程描述符和上述的 file 对象，为之后的 read 和 write 等操作作准备。
  - 函数最后返回该文件描述符。
- 根据 fd 指定的索引，从当前进程描述符中取出相应的 file 对象。
  如果没找到指定的 file 对象，则返回错误
  如果找到了指定的 file 对象：
  - 调用 file_pos_read() 函数取出此次读写文件的当前位置。
  - 调用 vfs_read() 执行文件读取操作，而这个函数最终调用 file->f_op.read() 指向的函数，代码如下：
  - 调用 file_pos_write() 更新文件的当前读写位置。
  - 调用 fput_light() 更新文件的引用计数。
  - 最后返回读取数据的字节数。
  - 到此，虚拟文件系统层所做的处理就完成了，控制权交给了 ext2 文件系统层。
- 进入到文件系统层处理
- 进入IO调度层处理请求，进行IO的请求队列，何时处理就要IO调度自己决定了
- 完成IO请求之后，通过中断方式通知CPU，如果成功，上层函数解锁IO操作所涉及的页面。之后函数不断返回。

### 23.用户态到内核态的转化原理

#### 1）为什么区分用户态和内核态

- 为了安全性。在cpu的一些指令中，有的指令如果用错，将会导致整个系统崩溃。分了内核态和用户态后，当用户需要操作这些指令时候，内核为其提供了API，可以通过系统调用陷入内核，让内核去执行这些操作。
- 辅助理解：**核心态**（又称为系统态），在此状态下，**能能执行一切指令，访问所有的寄存器内容及存区域**（用一句不严谨的话说，啥都能干。） **用户态**，是相对核心态而言的，在此状态下**，只能执行特定的一些指令，特定的一些寄存器和一些特定的区域**。 那么问题来了，为什么要区分用户态和核心态呢？原因很简单，就是为了**保护操作系统**，因为操作系统中的一些重要数据，比如PCB，是不允许修改和破坏的。

#### 2）用户态切换到内核态的3种方式:

​		总之3中方式都是中断

- 1、系统调用（内中断）
  - 这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 0x80中断。
- 2、异常（也叫内中断）
  - 当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。
- 3、外围设备的中断（外中断）
  - 当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

#### 3）切换操作（其实理解为中断响应的操作，从该线（进）程用户栈切换到该线（进）程对应内核栈）

从出发方式看，可以在认为存在前述**3种不同的类型**，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一样的，没有任何区别，**都相当于执行了一个中断响应的过程**，因为系统调用实际上最终是中断机制实现的，而异常和中断处理机制基本上是一样的，用户态切换到内核态的步骤主要包括：

- 1、从当前进程的描述符（PCB）中提取其内核栈的堆栈指针ss0及esp0信息。（提取切换前必备的信息，也就是需要**提取内核栈的位置**）
- 2、使用ss0和esp0指向的内核栈将当前进程的cs, eip，eflags，ss,esp信息保存起来，这个过程也完成了由**用户栈找到内核栈的切换过程**，同时保存了被暂停执行的程序的下一条指令。
- 3、将先前由中断向量检索得到的中断处理程序的cs，eip信息装入相应的寄存器，开始**执行中断处理程序**，这时就**转到了内核态的程序执行**了。

注：

- SS被称为堆栈段寄存器,用于存放堆栈段的基值。esp寄存器用于存放堆栈内存储单元的偏移量，用于访问栈顶。
  - SS：ESP 标志栈顶
- cs寄存器：代码段寄存器(Code Segment Register)，其值为代码段的段值；
- eip:存放下次将要执行的指令在代码段的偏移量。
  - CS：EIP  标志下一个应该执行的代码位置
- Eflags：标志寄存器
  - 包含运算结果标志位、状态控制标志位等

### 24.微内核与宏内核

- **微内核：**只有**基本的线程管理**（即CPU调度，CPU schedule），**内存管理**(virtual memory)和**进程间通信(IPC)等功能**。驱动、文件系统等都是用户态的守护进程去实现的。
  - 它只完成内核不得不完成的功能：包括时钟中断、进程创建与销毁、进程调度，内存管理，进程间通信，而其他的诸如文件系统、设备驱动等的内容都被作为系统进程放到了用户态空间。
  - 优点：稳定，驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃
    - 也就是那些非必须的进程不会影响到内核，什么设备驱动啊，文件系统啊，出问题不会导致操作系统挂掉。
  - 缺点：效率低。典型代表QNX，QNX的文件系统是跑在用户态的进程，称为resmgr的东西，是订阅发布机制，文件系统的错误只会导致这个守护进程挂掉。不过数据吞吐量就比较不乐观了。
    - 因为比如执行设备驱动时，要来回用户态内核态切换。而宏内核都放在了内核态，不用切换。设备驱动比如处理IO中断，在微内核中，内核是不直接处理IO中断管理的，来自硬件的请求将被重定向到用户服务中去，比方内核捕获了一个中断，那么内核发送给设备驱动服务就完事了，设备驱动服务会去处理这个中断。
- **宏内核（集成式内核、单体式内核）：**除了最基本的线程管理、内存管理、进程间通信外，还将虚拟文件系统（VFS）、文件系统（File System）、系统调用、设备驱动（Device Drivers），网络协议等等都集成在内核里面
  - 微内核是相对于宏内核而言的，像Linux就是典型的宏内核，它除了时钟中断、进程创建与销毁、进程调度、进程间通信外，其他的文件系统、内存管理、输入输出、设备驱动管理都需要内核完成；
  - 优点：效率高。
    - 由于用户服务（就那些设备驱动啥的）和内核服务被实现在同一空间中，这样在执行速度上要比微内核快。
  - 缺点：稳定性差，开发过程中的bug经常会导致整个系统挂掉。
    - 一旦比如设备驱动啊，文件系统啊，出问题，内核就不行了，系统死机。
- 宏内核、微内核、混合内核区别：

<img src="https://s1.ax1x.com/2020/05/16/YcqWB4.png" alt="YcqWB4.png" style="zoom: 200%;" />

<img src="https://s1.ax1x.com/2020/05/16/YgiBss.png" alt="YgiBss.png" style="zoom:80%;" />

### 25.孤儿进程、僵尸进程、守护进程

https://www.cnblogs.com/Anker/p/3271773.html

**自己的理解：**

- 孤儿进程：父进程没wait，父进程exit了，留下了没执行完的子进程变成了孤儿，孤儿子进程会被init进程收养
- 僵尸进程：
  - 父进程**有wait**，子进程exit了，父进程还没执行到wait那儿，留下了子进程的垃圾（Zombie数据结构）待清理，这时用ps命令就能看到子进程的状态是“Z”，**该子进程暂时是僵尸进程**，等父进程执行到wait就把垃圾清理了
  - 父进程**没wait**，子进程exit了，父进程还没结束（还没exit），留下了子进程的垃圾（Zombie数据结构）待清理，但是父进程还活着，没法移交给init处理，**该子进程在父进程exit之前都是僵尸进程**。要等到父进程exit以后，该子进程变成孤儿进程被init进程收留之后，init进程执行wait释放掉垃圾。

#### 1）正常进程

正常情况下，子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。

unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到：在**每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。 但是仍然为其保留一定的信息，直到父进程通过wait / waitpid来取时才释放**。

保存信息包括：（也就是该进程PCB还保留）

- 1 进程号the process ID
- 2 退出状态the termination status of the process
- 3 运行时间the amount of CPU time taken by the process等

#### 2）孤儿进程(父进程没wait，父进程结束了，留下了没运行完的子进程变成了孤儿，孤儿子进程会被init进程收养)

**一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。**孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

**孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上**，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。**因此孤儿进程并不会有什么危害。**

#### 3）僵尸进程（父进程没wait，子进程结束了，父进程没结束，留下了子进程的垃圾待清理，但是父进程还活着，没法移交给init处理）

**任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。**

**一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用（或者还没执行到）wait或waitpid获取子进程的状态信息，那么子进程的进程描述符（也就是上边的保留信息1、2、3）仍然保存在系统中。这种进程称之为僵尸进程。**

僵尸进程是一个进程必然会经过的过程：这是每个子进程在结束时都要经过的阶段。

如果子进程在exit()之后，父进程没有来得及处理，比如父进程正在sleep，还没执行到wait呢，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。

**危害：**

如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是**系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程**。此即为僵尸进程的危害，应当避免。



**场景：**

例如**有个进程，它定期的产生一个子进程**，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个**子进程的生命周期很短**，但是，**父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问**，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。**进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。** 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大量僵死进程的那个元凶枪毙掉（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。**枪毙了元凶进程（父进程）之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了。**



**解决僵尸进程的方法：**

- 外部消灭：
  - 通过kill发送SIGTERM或者SIGKILL信号**消灭产生僵尸进程的父进程**，它产生的**僵死进程就变成了孤儿进程**，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源。
- 内部解决：
  - 1、**子进程退出时向父进程发送SIGCHILD信号**，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。
    - 这样做，在子进程退出时，父进程可以立即在信号处理函数中采取wait操作，而不用等到执行到某一固定位置处wait。子进程exit时可以立即响应。
    - 这比有wait更高级一点，可以做到立即响应，而不是执行到wait函数处才能处理僵尸进程。
  - 2、fork两次，原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。
    - 这个做法不好

#### 4）守护进程（类似后台进程）

##### 1.守护进程的概念

守护进程是在后台运行**不受终端控制**的进程（如输入、输出等），一般的网络服务都是以守护进程的方式运行。它是一种**在后台执行的电脑程序**。

守护进程是脱离于终端并且在后台运行的进程，脱离终端是为了避免在执行的过程中的信息在终端上显示，并且进程也不会被任何终端所产生的终端信息所打断。

**守护进程一般的生命周期是系统启动到系统停止运行**，当然，也可以通过杀死进程的方式来结束进程的生命周期。linux系统中有很多的守护进程，最典型的就是我们经常看到的服务进程（系统启动的时候有很多的进程就已经开始跑了，这些就是服务进程）。当然，我们也经常会利用守护进程来完成很多的系统或者自动化任务。

##### 2.创建守护进程的步骤：

- 1.创建子进程，父进程退出
  - 通常，守护进程没有任何存在的父进程（即PPID=1），且在UNIX系统进程层级中直接位于init之下。守护进程程序通常通过如下方法使自己成为守护进程：对一个子进程运行fork，然后使其父进程立即终止，使得这个子进程成为孤儿进程能在init下运行。这种方法通常被称为“脱壳”。
- 2.setsid创建会话
  - 就是起到了该守护进程进程脱离原会话的控制，摆脱了原进程组的控制，摆脱了原控制终端的控制。
  - 具体的：
    - 该进程变成新会话的会话首进程，即成为session leader
    - 该进程成为一个新进程组的组长进程，即成为process group leader
    - 该进程没有控制终端，摆脱了原控制终端的控制
- 3.改变工作目录
  - 改变当前目录为根目录
  - 因为在**fork子进程的时候，子进程也继承了父进程的工作目录**。通常是**让‘/’目录作为守护进程的当前目录，可以避免很多麻烦。**防止占用别的路径的working dir的fd，导致一些block不能unmount。因此要改变守护进程的当前工作目标。
- 4.重设文件创建掩码
  - 由于**使用fork函数新建的子进程继承了父进程的文件创建掩码**，这就给该子进程使用文件带来了诸多的麻烦。因此，**把文件创建掩码设置为0，可以大大增强该守护进程的灵活性。**设置文件创建掩码的函数是umask，通常的使用方法为umask(0)。因此要把守护进程的文件创建掩码设置为0。
- 5.关闭文件描述符
  - 用**fork新建的子进程会从父进程那里继承一些已经打开了的文件**。这些被打开的文件可能永远不会被守护进程读或写，但它们一样消耗系统资源，可能导致所在的文件系统无法卸载。因此要把守护进程的文件描述关闭。

##### 3.守护进程与用&结尾的后台程序的区别

1、守护进程已经完全脱离终端控制台了，而后台程序并未完全脱离终端(在终端未关闭前还是会往终端输出结果);

2、守护进程在关闭终端控制台时不会受影响，而后台程序会随用户退出而停止，需要在以nohup command &格式运行才能避免影响;

3、守护进程的会话组和当前目录，文件描述符都是独立的。后台运行只是终端进行了一次fork，让程序在后台执行，这些都没改变;

### 26.server端监听端口，但还没有客户端连接进来，此时进程处于什么状态？（还不会）

这个需要看服务端的编程模型，如果如上一个问题的回答描述的这样，则处于阻塞状态，如果使用了epoll,select等这样的io复用情况下，处于运行状态

### 27.什么是线程池，怎么实现线程池

#### 1.线程池的概念

- 在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。**线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。**
- 辅助理解：线程池就是首先创建一些线程，它们的集合称为线程池。使用线程池可以很好地提高性能，线程池在系统启动时即创建大量空闲的线程，程序将一个任务传给线程池，线程池就会启动一条线程来执行这个任务，执行结束以后，该线程并不会死亡，而是再次返回线程池中成为空闲状态,在这里说是空闲状态其实是被条件变量阻塞了，等待执行下一个任务。

#### 2.线程池的好处

1.可以节省创建线程和销毁线程需要的系统资源;

2.可以提高响应的速度,减少用户等待时间;

3.通过控制线程池的大小,可以增强系统的可控性.

#### 3.怎么实现线程池

1.设置一个生产者消费者队列，作为临界资源
2.初始化n个线程，并让其运行起来，加锁去队列取任务运行
3.当任务队列为空的时候，所有线程阻塞
4.当生产者队列来了一个任务后，先对队列加锁，把任务挂在到队列上，然后使用条件变量去通知阻塞中的一个线程

### 28.进程疯狂申请内存，new， kill掉以后内存会不会释放 

会，进程结束以后，系统会回收它的资源，不管泄露的没泄露的内存，都会回收。

### 29.生产者消费者模型，只有各一个，用不用加锁 

- 需要查看使用队列是不是线程安全的，或者支持原子操作。
- 换句话说，需要知道生产者把产品放入缓存区这个步骤和消费者从缓存区取出一个这两个步骤是不是线程安全的，如果不安全，也就是说有可能生产者放入了一半，线程被调度走了，消费者线程来取资源了，这是非常严重的后果。所以如果放入和取出这两个步骤不是线程安全的话，就需要加锁。如果是线程安全的，就不用加锁。

### 30.无锁队列实现、CAS底层实现（还不会）

#### 0.CAS的C语言描述

```c++
bool compare_and_swap (int *addr, int oldval, int newval)
{
  if ( *addr != oldval ) {
      oldval = *addr;//这个是 compare_exchange_weak的特性
      return false;
  }
  *addr = newval;
  return true;
}
//*addr就对应compare_exchange_weak中atomic对象，也就是这个成员函数的调用者。oldval对应expected，newval对应val
```

#### 1.atomic中的CAS操作

**作为成员函数**

注意这是个类的成员函数，

```c++
bool compare_exchange_weak (T& expected, T val,
           memory_order sync = memory_order_seq_cst) volatile noexcept;
```

- 当前值(类对象的值)与期望值（T& expected）相等时，修改当前值为设定值，返回true
- 当前值与期望值不等时，将期望值修改为当前值，返回false
- 这个函数可能在满足true的情况下仍然返回false，所以只能在循环里使用，否则可以使用它的strong版本

原子性加减通常是用CAS(Compare and Swap)完成的，与平台相关。CAS的基本形式是：CAS(addr,old,new),当addr中存放的值等于old时，用new对其替换

**作为外置函数**

```c++
template <class T>
bool atomic_compare_exchange_weak (volatile atomic<T>* obj, T* expected, T val) noexcept;
```

#### 2.无锁栈的实现：(多个线程一起操作栈)

https://zhuanlan.zhihu.com/p/27053428参考这个文章，但是这个文章有个大问题，它说的compare_exchange_weak当前值与期望值不等时，~~将期望值与当前值互换~~，并返回false。实际上是当前值与期望值不等时，**将期望值修改为当前值**，并返回false。

栈的push操作步骤：

1. 新建一个节点
2. 将该节点的next指针指向现有栈顶
3. 更新栈顶为当前新建的节点

可能出问题的地方在于第3个步骤中，只要保证步骤3更新栈顶时候，栈顶是我们在步骤2中获得顶栈顶即可。如果不一样，以步骤三的当前栈顶为准。因为如果有其它线程进行操作，栈顶必然改变。

栈的pop操作步骤：

1. 取出当前栈顶，保存到临时变量里
2. 将栈顶置为原栈顶的next
3. 释放原栈顶内存

```c++
    //把表示栈顶的结点变成atomic就行。然后第3个步骤变成CAS
 1    template<typename T>
 2 class lock_free_stack
 3 {
 4 private:
 5   struct node
 6   {
 7     T data;
 8     node* next;
 9 
10     node(T const& data_): 
11      data(data_)
12     {}
13   };
14 //主要只看Push函数就行
15   std::atomic<node*> head;//把栈顶设为原子的   
16 public:
17   void push(T const& data)
18   {
19     node* const new_node=new node(data); //新建一个结点
20     new_node->next=head.load(); //将该节点的next指针指向现有栈顶
21     while(!head.compare_exchange_weak(new_node->next,new_node));//更新栈顶
    	//需要检查当前值head与期望值new_node->next，如果相等，说明一切顺利，栈顶没有被修改，修改当前值head为new_node，返回true
    	//如果当前值head与与期望值new_node->next不等，说明栈顶被修改过了，证明有其他线程更新了栈顶，那么把期望值new_node->next设置为当前值head，即被其他线程更新的新栈顶值head会被更新到new_node->next中。互换以后还在while里，再来一次检查，发现当前值是head期望值new_node->next也是head，相等了，那么把当前值head修改为new_node，返回true
22   }
23 };
//无锁只保证了，可以多线程同时操作，保证安全，但是可没有同步的作用。
	void pop()
    {
        node* temp_node=head.load();//取出栈顶
        while(temp_node && !head.compare_exchange_weak(temp_node,temp_node->next));
        //保证栈内有元素，且要保证当前栈顶和第一步取出的栈顶是一样的，如果不一样，以当前为准
        if(temp_node) delete temp_node;
    }
```



#### 3.无锁链表的实现(多个线程一起更新链表)

实现链表append 步骤：(**前插链表,跟栈几乎一样**)

1. 新建一个节点
2. 将该节点的next指针指向现有队首
3. 更新队首为当前新建结点

```c++
//把表示链表头的变量变成atomic，
//无锁只保证了，可以多线程同时操作，保证安全，但是可没有同步的作用。
#include <iostream>       // std::cout
#include <atomic>         // std::atomic
#include <thread>         // std::thread
#include <vector>         // std::vector

// a simple global linked list:
struct Node { int value; Node* next; };
std::atomic<Node*> list_head (nullptr);

void append (int val) {     // append an element to the list
	Node* newNode = new Node{ val, list_head };
	while (!list_head.compare_exchange_weak(newNode->next, newNode));
  }
}

int main ()
{
  // spawn 10 threads to fill the linked list:
  std::vector<std::thread> threads;
  for (int i=0; i<30; ++i) threads.push_back(std::thread(append,i));
    //30个线程来做30个链表append操作
  //无锁只保证了，可以多线程同时操作，保证安全，但是可没有同步的作用。  
  //所以最后形成的链表顺序肯定不是有序的，或者说肯定不是按线程创建的顺序形成的链表。
    
  for (auto& th : threads) th.join();//等待线程退出

  // print contents:
  for (Node* it = list_head; it!=nullptr; it=it->next)
    std::cout << ' ' << it->value;
  std::cout << '\n';

  // cleanup:
  Node* it; while (it=list_head) {list_head=it->next; delete it;}

  return 0;
}
```

#### 4.无锁队列的实现（多个线程一起更新队列）

https://coolshell.cn/articles/8239.html/comment-page-4

```c
Q里边的head和tail要设置成atomic
    
InitQueue(Q)//初始化队列
{
    node = new node()
    node->next = NULL;
    Q->head = Q->tail = node;
}

```

```C
//Enqueue操作
//第一步，把tail指针的next指向要加入的结点。 tail->next = p;
//第二步，把tail指针移到队尾。 tail = p;
EnQueue(Q, data) //进队列
{
    //准备新加入的结点数据
    node* n = new node();
    n->value = data;
    n->next = NULL;
    do{
        node* temp=Q->tail;
    }while(atomic_compare_exchange_weak(p->next,nullptr,n)==false);
    
    atomic_compare_exchange_weak (volatile atomic<T>* obj, T* expected, T val)
        
    do {
        p = Q->tail; //取链表尾指针的快照
    } while( CAS(p->next, NULL, n) != TRUE); 
    //while条件注释：如果没有把结点链在尾指针上，再试

    CAS(Q->tail, p, n); //置尾结点 tail = n;
}
```

### 31.PCB详解与进程分配资源

https://blog.csdn.net/lvyibin890/article/details/82193900

- PCB（progress control block），进程控制块。它就是一个结构体，用来描述进程，在Linux下，就是**task_struct结构体。**
- 每个进程运行的时候，都会拿到4G的虚拟内存，在32位Linux下，其中3G是交给用户的，1G是交给内核的，而**task_struct就是存储在这1G的内核系统空间**中。虚拟内存中这1G的内核空间是物理内存上内存共享的，也就是都映射到同一物理内存空间。
- 操作系统管理进程，也就是在内核空间中管理的，**在内核空间中通过链表管理所有进程的PCB**，如果有一个进程要被创建，实际上多分配了这么一个4G的虚拟内存，并在共享的内核空间中的双向链表中加入了自己的PCB。
- 为什么需要这个1G的内核空间，是因为进程需要调用一些系统调用，来交给内核跑，程序的一部分逻辑可能是要交给内核去跑的，所以一部分虚拟地址必须要留给内核使用。

![YXHzAe.png](https://s1.ax1x.com/2020/05/22/YXHzAe.png)

**PCB结构体里包含什么信息？**

- 标识相关：pid，ppid等等
- 文件相关：进程需要记录打开的文件信息，于是需要文件描述符表
- 内存相关：内存指针，指向进程的虚拟地址空间（用户空间）信息
- 优先级相关：进程相对于其他进程的调度优先级
- 上下文信息相关：CPU的所有寄存器中的值、进程的状态以及堆栈上的内容，当内核需要切换到另一个进程时，需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。
- 状态相关：进程当前的状态，说明该进程处于什么状态
- 信号相关：进程的信号处理函数，以及记录当前进程是否还有待处理的信号
- I/O相关：记录进程与各种I/O设备之间的交互
  

### 32.一个进程可以创建多少线程，和什么有关

#### 1.一个进程可以创建多少线程与虚拟内存大小（32位还是64位）、以及分配给线程的调用栈大小（可手动调整）有关

一个进程可以创建的线程数由**可用虚拟空间**和**线程的栈的大小**共同决定，只要虚拟空间足够，那么新线程的建立就会成功。如果需要创建超过2K以上的线程，减小你线程栈的大小就可以实现了，虽然在一般情况下，你不需要那么多的线程。

进程中的所有线程是共享进程的地址空间的，但是**系统会为每个线程分配独立的调用栈**，也就说每个线程都会有一个自己的调用栈。

创建一个线程会占用多少内存，这取决于**分配给线程的调用栈大小**，可以用ulimit -s命令来查看大小（一般常见的有**10M**或者是8M）。我们还知道，一个进程的虚拟内存是4G，在Linux32位平台下，内核分走了1G，留给用户用的只有3G，于是我们可以想到，创建一个线程需要分配10M**（这10M在虚拟内存的mmap区，也就是动态链接库区/共享内存区/mmap区）**内存给该新线程的调用栈，总共有3G用户内存可以使用。于是可想而知，最多可以创建差不多300个左右的线程。再加上虚拟内存中还有保留区、代码段（只读区）、数据段（读写区）、heap、stack等等，肯定是不够300个线程的。（其实也就是把可以malloc的内存都占满了，应该是2.9G/10M=290个。因为malloc就是mmap区和heap区，而分配调用栈是mmap区，可以把mmap和heap都当做堆栈区）

#### 2.进程栈、线程栈、内核栈

https://blog.csdn.net/yangkuanqaz85988/article/details/52403726

- 进程栈：其实可以叫做主线程栈，不与子线程共享
- 线程栈：子线程栈，每个子线程一个，互相不共享
- 内核栈：每个子线程都有一个，互相不共享，在虚拟内存的内核区了。

Linux 调度程序中并没有区分线程和进程。Linux 把所有线程都当做进程来实现，它将线程和进程不加区分的统一到了 task_struct 中。线程仅仅被视为一个与其他进程共享某些资源的进程，而是否共享地址空间几乎是进程和 Linux 中所谓线程的唯一区别。线程创建的时候，加上了 CLONE_VM 标记，这样 线程的内存描述符 将直接指向 父进程的内存描述符。换句话说，一个进程不是必须有一个线程吗，**这个线程就叫主线程，它享用虚拟内存里说的进程栈。**在这个进程里创建了其他子进程呢？他们去用mmap的线程栈啊，每个线程都有一个自己的线程栈，在mmap区。其他的呢？所有线程除了**栈是不共享的**，什么bss段、堆，都是共享一套。

### 33.linux进程终止的5种方式

- 1、main函数的自然返回，return，效果等同于调用exit()函数

- 2、调用exit函数(c语言库函数)

  - 当程序执行到`exit和_exit`时，进程会**无条件的停止剩下的所有操作**，清除包括PCB在内的各种数据结构，并终止本程序的运行。
  - exit函数和_exit函数的**最大区别在于exit函数在退出之前会检查文件的打开情况，把文件缓冲区中的内容写回文件**，也就是清理I/O缓冲。
  - exit可输出缓冲区数据，_exit无法输出缓冲区数据;
  - exit会执行调用终止处理程序，_exit不执行

- 3、调用_exit函数(系统调用)

- 4、调用abort函数。异常退出，它产生SIGABRT信号

- 5、接受能导致进程终止的信号:

  - ```c++s
    ctrl+c (^C)：发出SIGINT信号(SIGINT中断进程) 
    
     ctrl + \ (^\Quit)：发出SIGQUIT信号（进程在因收到SIGQUIT退出时会产生core文件, 在这个意义上类似于一个程序错误信号）
    ```

### 34.异常和中断的区别

- 异常：也叫内中断，例如CPU处理程序的时候一旦程序不在内存中，会产生缺页异常；当运行除法程序时，当除数为0时，又会产生除0异常。所以，大家也需要记住的是，**异常是由CPU产生的，CPU会发送给内核**，要求内核处理这些异常。
- 中断：也叫外中断，**中断是由硬件设备产生的**，而它们从物理上说就是电信号，之后，**它们通过中断控制器发送给CPU**，接着CPU判断收到的中断来自于哪个硬件设备（这定义在内核中），最后，**由CPU发送给内核**，有内核处理中断。

- 相同点：
  - 最后都是由CPU发送给内核，由内核去处理
  - 处理程序的流程设计上是相似的
- 不同点：
  -  产生源不相同，**异常是由CPU产生的**，而**中断是由硬件设备产生**的
  - 内核需要根据是异常还是中断调用不同的处理程序  
  - 中断不是时钟同步的，这意味着**中断可能随时到来**；**异常**由于是CPU产生的，所以，它**是时钟同步**的（时钟同步是指在在检测时间点上来？）
  - 当处理中断时，处于中断上下文中；处理异常时，处于进程上下文中

### 35.可重入内核和可重入函数

**可重入内核**：

- 原理和“可重入函数”相同，我们都知道单核处理器中的进程都是交替运行的，一个进程中断后，内核会保存当前进程的相关信息，然后执行下一个进程，等完成后再将上个进程从中断的位置重新恢复执行。这种内核被称为“可重入内核”。
- 所有UNIX内核都是可重入的(reentrant)，这意味着几个进程可以同时在内核态下执行，当然在单处理器系统上，只有一个进程在真正的运行，但是**许多进程可以在内核态下阻塞，或者等待CPU，或者等待一些I/O操作的完成。**

**可重入函数**：

- 当函数A在执行过程中因某原因中断，而去执行另一个函数B，函数B执行完成后，不会影响A预期的结果（主要是A内部使用的变量），称A为“可重入函数”。
- 提供可重入的一种方式是编写函数，这些函数只能修改局部变量，不能修改全局数据结构，这样的函数叫做可重入函数。

**可重入函数与可重入内核的联系：**

- 可重入函数是实现“可重入内核”的方式之一，但是由于一些对IO操作的需求，内核也必须要包含“不可重入函数”，那怎么保证数据的安全呢？内核采用了锁机制保证一次只有一个进程执行一个“不可重入函数”。这样处于内核态的每个进程只能作用于自己的内存空间，不能干预其它的进程。
- 所有的内核都是可重入的。但**可重入内核不只是包含可重入函数，也可以包含不可重入函数。**这时候信号量，自旋锁之类的同步机制就派上用场了，它们用于保证可重入内核里的不可重入函数的数据安全。

### 36.系统调用进入内核态的过程

参考hit-os笔记：系统调用的实现

- 初始时是用户态，CPL=3。
- 系统调用的第一步，保存系统调用号到寄存器，然后触发int 0x80中断，（注意是这个特殊的中断0x80，它专为系统调用而生，与键盘中断等等区别很大）。触发中断以后，查IDT表（中断向量表，这个表是由内核初始化的），一看0x80这个中断对应的DPL=3（故意设置成3，本来应该是0，为了从中断进入system_call），而CPL = 3（用户态）可以执行。
- 根据IDT表中的地址，0x80中断将跳转至存放系统调用函数system_call（所有的系统调用都要到这儿来执行）的内存位置。跳到system_call后自动地CPL就是0了（因为处于内核区内存），意味着处于核心态了。（因为0x80中断就是专门系统调用中断，其他中断将跳转至IDT表中的相应其他位置）
- 在system_call中，根据系统调用号（__NR_iam=72），算出地址call sys_call_table+4*系统调用号，jmp进去。那里就存放着iam相应的内核实现，即sys_iam函数。

### 37.内核态和用户态的区别

内核态（Kernel Mode）：运行操作系统程序（或者说内核程序），操作硬件

用户态（User Mode）：运行用户程序

**区别：**

- 程序运行在用户态意味着处于0级特权级；程序运行在内核态意味着处于3级特权级
- 运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态（比如操作硬件）。

- 处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的；处于内核态执行时，则能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占的。

**内核态和用户态的切换**

- 用户态转为内核态：
  - 异常（abort，比如除以0）、故障（fault，比如缺页故障）、陷入（trap，比如系统调用）、外中断
- 内核态转为用户态：
  - 执行一条特权指令——修改程序状态字PSW的标志位变为“用户态”，意味着内核程序让出CPU使用权

### 38.常见的进程（线程）调度算法 && linux真实的调度算法

#### 1.批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

#### 1.1先来先服务 first-come first-serverd（FCFS）

非抢占式的调度算法，按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

#### 1.2短作业优先 shortest job first（SJF）

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

#### 1.3 最短剩余时间优先 shortest remaining time next（SRTN）

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

#### 1.4高响应优先（HRRN）

在每次调度时计算各个进程的响应比，选择响应比最高的进程提供服务。响应比=（等待时间+要求服务时间）/要求服务时间。

优缺点：综合考虑等待时间和运行时间（要求服务时间）。等待时间相同时，要求服务时间短的优先(SJF的优点)
要求服务时间相同时，等待时间长的优先(FCFS 的优点)。对于长作业来说，随着等待时间越来越久，其响应比也会越来越大，从而避免了长作业饥饿的问题。不会导致饥饿。

#### 2.交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

#### 2.1时间片轮转

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

#### 2.2优先级调度

为每个进程分配一个优先级，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

#### 2.3多级反馈队列

设置多个就绪队列，分别赋予不同的优先级，比如逐级降低，队列1的优先级最高。每个队列执行时间片的长度也不同，规定优先级越低则时间片越长，比如逐级加倍。

新进程进入内存后，先投入队列1的末尾，按FCFS算法调度；若按队列1一个时间片未能执行完，则降低投入到队列2的末尾，同样按FCFS算法调度；如此下去，降低到最后的队列，则按“时间片轮转”算法调度直到完成。

**仅当较高优先级的队列为空时，才调度较低优先级的队列中的进程执行。**如果进程执行时有新进程进入较高优先级的队列，则抢先执行新进程，并把被抢先的进程投入原队列的末尾。

多级反馈队列调度算法又称反馈循环队列或多队列策略，主要思想是将就绪进程分为两级或多级，系统相应建立两个或多个就绪进程队列，较高优先级的队列一般分配给较短的时间片。处理器调度先从高级就绪进程队列中选取可占有处理器的进程，只有在选不到时，才从较低级的就绪进程队列中选取。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

**优点：**

- 为提高系统吞吐量和缩短平均周转时间而照顾短进程。
- 为获得较好的I/O设备利用率和缩短响应时间而照顾I/O型进程。
- 不必估计进程的执行时间，动态调节

![tiydlq.png](https://s1.ax1x.com/2020/05/26/tiydlq.png)

#### 3.linux真实算法

https://www.cnblogs.com/alantu2018/p/8460451.html

- 1.NOOP，电梯调度算法
  - NOOP算法的全写为No Operation。该算法实现了最最简单的FIFO队列，所有IO请求大致按照先来后到的顺序进行操作
- 2.Deadline scheduler，截止日期调度器
  -  DEADLINE在CFQ的基础上，解决了IO请求饿死的极端情况。
- 3.Anticipatory scheduler，预测调度器
  - ANTICIPATORY的在DEADLINE的基础上，为每个读IO都设置了6ms的等待时间窗口。
- 4.CFQ：Completely Fair Queuing，完全公平排队
  - 该算法的特点是按照IO请求的地址进行排序，而不是按照先来后到的顺序来进行响应。

### 39.陷阱、故障、终止、中断

- 陷阱、陷入（trap)
  - 由陷入指令引发，是应用程序故意引发的
  - 例如：系统调用
- 故障（fault）
  - 由错误条件引起的，可能被内核程序修复。内核程序修复故障后，会把CPU使用权还给应用程序，让它继续执行下去。
  - 例如：缺页故障。（内存被调到硬盘swap区了）
- 终止（abort)，异常
  - 由致命错误引起，内核无法解决，因此一般不再将CPU使用权还给引发abort的应用程序，而是直接kill该进程。
  - 如：整数除0、非法使用特权指令
- 上边3个都是来自CPU内部，与当前执行指令有关。
- 中断：
  - 与当前执行指令无关，中断信号来自CPU外部。

### 40.什么是临界区？进程进入临界区的调度原则是？

临界资源:一个时间段内只允许一个进程使用的资源。各进程需要互斥地访问临界资源。

临界区:访问临界资源的那段代码。**临界区**是一段对共享资源的保护代码，该保护代码在任意时刻只允许一个线程对共享资源访问。

进程进入临界区的调度原则是：
 ①如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入。②任何时候，处于临界区内的进程不可多于一个。如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待。③进入临界区的进程要在有限时间内退出，以便其它进程能及时进入自己的临界区。④如果进程不能进入自己的临界区，则应让出CPU，避免进程出现“忙等”现象。

## 2.内存

### 1.Linux虚拟地址空间

#### 1.虚拟内存基本概念

为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。

虚拟内存技术使得不同进程在运行过程中，它所**看到的是自己独自占有**了当前系统的**4G内存**。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表(PCB)中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会**通过缺页异常，来拷贝数据**。还有进程运行过程中，要动态分配内存，比如**malloc**时，**也只是分配了虚拟内存**，即为这块虚拟内存对应的页表项做相应设置，**当进程真正访问到此数据时，才引发缺页异常**。

请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。

> 解释一下缺页异常（缺页中断）：在请求分页系统中，每当要访问的**页面不在内存**（通过页表状态位来判断）时，便产生一个**缺页中断**，然后由操作系统的**缺页中断处理程序处理中断**。

#### 2.虚拟内存的好处：

- 1.扩大地址空间；
  - 每个进程都看似是4G，就算物理内存只有1G也没事
- 2.内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。
- 3.公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。
  - 都是4G
- 4.当进程通信时，可采用虚存共享的方式实现。
  - 可以让两个进程各自拿出一块虚拟地址空间来，然后映射到相同的物理内存中，这样，两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了内存共享机制了。
- 5.当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存
- 6.虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存（进程一般都缺页地保存在物理内存，不会全部保留在物理内存）中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高
- 7.在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片
  - 虚拟内存中是分段式，方便用户，物理内存中是分页，方便物理内存提高利用率。

#### 3.虚拟内存的代价：

- 1.虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存
- 2.虚拟地址到物理地址的转换，增加了指令的执行时间。
  - 知道虚拟地址以后，需要去内存查页表，然后再换算到物理地址。（多级页表更需要去内存查好几次，页表都是放在内存里的）
- 3.页面的换入换出需要磁盘I/O，这是很耗时的
  - 页面置换需要IO，也就是内存不够了，把不用的页面换到硬盘里，把需要的换入内存。
  - 一般页面置换发生在同一个进程的页面上，一般不是把其他进程的页面换出去，把本进程的换进来。换入换出一般就是本进程内部的页面之间的协调。
- 4.如果一页中只有一部分数据，会浪费内存。
  - 这个浪费基本可以忽略不计了，一页就4KB，一个进程最多浪费不到一页。

### 2.操作系统中的程序的内存结构

注意：

- **这底下的内存分布都是针对虚拟内存说的**
- 可执行程序位于磁盘中而内存映像位于内存中；
- 进程的内存映像是指内核在内存中如何存放可执行程序文件。 
- 可执行程序没有堆栈，因为**程序被加载到内存中才会分配堆栈**；
  - **也就是说在硬盘上的程序只有：代码区、已初始化数据区、BSS区**
- 可执行程序虽然也有未初始化数据段但它并不被储存在位于硬盘中的可执行文件中；
  - **BSS区不占用硬盘空间，也就是可执行程序的大小**
- 可执行程序是静态的、不变的，而内存映像随着程序的执行是在动态变化的，数据段随着程序的执行要存储新的变量值，栈在函数调用时也是不断变化中。

正文：



![Yij9aV.png](https://s1.ax1x.com/2020/05/05/Yij9aV.png)

一个程序本质上都是由代码段、初始化数据段（数据段）、未初始化数据段（BSS段）三个组成的。可以看到一个**可执行程序**在**存储（没有调入内存）时分为代码段、数据区和未初始化数据区三部分。**

- **代码段：**
  - 代码段中存放可执行的指令（也就是程序执行代码），这部分区域的大小在程序运行前就已经确定，并且**内存区域**属于**只读**。在代码段中，也有可能包含一些只读的常数变量。
  - 通常来讲代码段是共享的，这样多次反复执行的指令只需要在内存中驻留一个副本即可，比如 C 编译器，文本编辑器等。（反复执行？）

- **初始化数据段**（数据段、data段）：
  - 数据段是一个程序虚拟地址空间的一部分，存放程序中已**初始化的全局变量和静态变量以及它们的值**的一块内存区域。这些变量在编程时就已经被初始化。**数据段是可以修改**的，不然程序运行时变量就无法改变了，这一点和代码段不同。
  - 数据段可以细分为初始化**只读区**和初始化**读写区**。这一点和编程中的一些特殊变量吻合。比如全局变量 int global n = 1就被放在了初始化读写区，因为 global 是可以修改的。而 const int m = 2 就会被放在只读区，很明显，m 是不能修改的。
  - 数据段（已经初始化的数据）则为数据分配空间，数据保存到目标文件中。
- **未初始化数据段（BSS段）**：
  - BSS段（未进行初始化的数据）的内容并不存放在磁盘上的程序文件中。其原因是内核在程序开始运行前将它们设置为0**（未初始化的静态变量默认初始化为0）**。需要存放在程序文件中的只有正文段和初始化数据段。
  - BSS段的大小（是说大小这个数字，不是指已经为它分配内存了）从可执行文件中得到（这个大小这个数字从可执行文件中获得，真实的大小是不占用可执行文件的），然后链接器得到这个大小的内存块，紧跟在数据段的后面。当这个内存进入程序的地址空间后全部清零。包含数据段和BSS段的整个区段此时通常称为数据区。
- 注：**代码段和初始化数据段在编译时已经分配了空间（也就是保存在了可执行文件中），而BSS段并不占用可执行文件的大小，它是由链接器来获取内存的。**

**可执行程序在运行时**，又多出两个区域：栈区和堆区

- **栈区：**最大值一般是8M，可以手动修改
  - 由编译器自动释放，存放**函数的参数值（形参）、函数的返回地址、保存的上下文:包括在函数调用前后需要保持不变的寄存器、临时变量:包括函数的非静态局部变量以及编译器自动生成的其他临时变量、局部变量**等。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存放到栈中。然后这个被调用的函数再为他的自动变量和临时变量在栈上分配空间。**每调用一个函数一个新的栈帧就会被使用（每调用一个函数就是在8M的栈上开辟一个新的栈帧，而不是开辟一个新的8M线程栈）**。**栈区是从高地址位向低地址位增长的**，是一块连续的内存区域，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。
- **堆区：**
  - 用于动态分配内存，位于BSS和栈中间的地址区域。由程序员申请分配和释放。**堆是从低地址位向高地址位增长**，采用链式存储结构。频繁的malloc/free造成内存空间的不连续，产生碎片。当申请堆空间时库函数是按照一定的算法搜索可用的足够大的空间。因此堆的效率比栈要低的多。

### 3.比2.更详细细节一点的内存结构

<img src="https://s1.ax1x.com/2020/05/05/YixR8U.png" alt="YixR8U.png" style="zoom:50%;" />

https://zhuanlan.zhihu.com/p/107570048

比上边模型多了一些：

- 1.**动态链接库映射区：或者叫/共享内存区/mmap区**
  - 这个区域用于映射装载的动态链接库。在 Linux 下，如果**可执行文件依赖其它共享库**，那么系统就会为它在从 0x40000000 开始的地址分配相应的空间，并**将共享库载入该空间**。
  - 应该就是win下的dll
  - 共享内存的申请也在此，即一般是 mmap 函数所分配的虚拟地址空间。 
- 2.**保留区**：
  - 保留区并不是一个单一的内存区域，而是对内存中受到保护而禁止访问的内存区域的总称：例如大多数操作系统中，极小的地址通常都是不允许访问的，如 NULL，C 语言将无效指针赋值为 0 也是这个考虑。
- 3.**kernel space：**
  - 有1G保留为内核区，且所有进程这1G是共享内存，对应同一物理空间。

**终极参考版：**

https://blog.csdn.net/freeelinux/article/details/53782986

https://www.cnblogs.com/clover-toeic/p/3754433.html

![Yjgec4.png](https://s1.ax1x.com/2020/05/23/Yjgec4.png)

### 4.堆分配（不是很详细）

#### 1.堆分配的知识

https://www.cnblogs.com/zpcoding/p/10808969.html

https://www.cnblogs.com/dongzhiquan/p/5621906.html

- 除了可执行文件，共享库和栈之外，剩余的未分配的空间都可以用来作为堆空间。
- Linux 系统下，提供两种堆空间分配方式：
  - **brk() 系统调用和 mmap() 系统调用。**
  - 这两种方式分配的都是虚拟内存，没有分配物理内存。在**第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。**
- 在标准 C 库中，提供了malloc/free 函数分配释放内存，这两个函数底层是由 brk，mmap，munmap 这些系统调用实现的。
- **brk() 系统调用**：申请的是heap区，**小于128k的小内存分配**
  - brk() 的作用实际上就是设置进程数据段（data 和bss）的结束地址，即它可以扩大或者缩小数据段（Linux 下数据段（data）和 BBS 合并在一起统称数据段）。如果我们将数据段的结束地址向高地址移动(向堆区移动了一点)，那么扩大的那部分空间就可以被我们使用，把这块空间拿过来使用作为堆空间是最常见的做法。
  - brk会产生内存碎片。
    - 举例：假设heap是10MB，我用new依次从这个堆里得到了3块内存块，分别是：1M、2M和7M。
      假设这三块内存是连续的。那么如果你把1M和7M的块delete掉，那么这个heap里就有了8M的剩余空间，但是这个8M是不连续的：1个1M的块和1个7M的块，两者被那个2M给分隔开了。
      这时候如果你要申请一个连续的8M内存区，虽然这个heap有8M的剩余空间，但却没法给你。原因就是这个碎片（其实碎片是1M和7M，因为它俩无法被使用）。
  - 还没跟物理内存建立映射，只是分配了虚拟内存。
- **mmap() 系统调用**：申请的是mmap段的内存，**大于128k的大内存分配**
  - Mmap的第一种用法是映射磁盘文件到内存中；第二种用法是匿名映射，不映射磁盘文件，而向映射区申请一块内存。Malloc使用的是mmap的第二种用法（匿名映射）。
  - 申请一块匿名内存空间，使用匿名内存映射后，妈妈再也不用担心我的内存碎片问题了，不用直接取消映射就好，想用再映射回来。
  - 和 Windows 系统下的 VirtualAlloc 很相似，它的作用就是向操作系统申请一段虚拟地址空间，（**堆和栈中间，称为文件映射区域的地方**）这块虚拟地址空间可以映射到某个文件。
  - 还没跟物理内存建立映射，只是分配了虚拟内存。
- 无论malloc通过sbrk还是mmap实现，分配到的内存只是虚拟内存**，而且只是虚拟内存的页号，代表这块空间进程可以用，实际上还没有分配到实际的物理页面**。等你的进程访问到这个新分配的内存空间的时候，如果其**还没有对应的物理页面分配，就会产生缺页中断，**内核这个时候会给进程分配实际的物理页面，以与这个未被映射的虚拟页面对应起来，然后程序就可以欢快的继续往下跑了。
- 当**没有足够的连续空间分配**时，就会返回Null

#### 2.malloc最大值？

malloc的

从进程地址空间的布局可以看到，在有共享库的情况下，留给堆的可用空间还有两处：一处是**从.bss段到0x40000000，约不到1GB的空间；另一处是从共享库到栈之间的空间，约不到2GB。**这两块空间大小取决于栈、共享库的大小和数量。这样来看，是否应用程序可申请的最大堆空间只有2GB？事实上，这与Linux内核版本有关。在上面给出的进程地址空间经典布局图中，共享库的装载地址为0x40000000，这实际上是Linux kernel 2.6版本之前的情况了，在2.6版本里，**共享库的装载地址已经被挪到靠近栈的位置，即位于0xBFxxxxxx附近，因此，此时的堆范围就不会被共享库分割成2个“碎片”，**故kernel 2.6的32位Linux系统中，**malloc申请的最大内存理论值在2.9GB左右。**mmap其实和堆一样，实际上可以说他们都是动态内存分配，但是严格来说mmap区域并不属于堆区，反而和堆区会争用虚拟地址空间。

**而对于64位系统，可以malloc128T?**

可以。如果你了解操作系统是如何管理虚拟内存的，就会知道这跟你有多大内存其实关系不大。分配是肯定会成功的。因为64位寻址，绝对满足大于4g。不过如果你物理内存太小，在runtime会造成大量的page fault，然后操作系统会不断的swap in/out，基本你的程序，其他程序也就废了。

32位系统，寻址是2^32=4G

64位系统，用不了2^64这么大的寻址空间，16位作为保留位，实际上只有48位能用于内存寻址，即2^48=256T。

### 5.操作系统中的缺页中断

#### 1.缺页中断简介：

**缺页中断**：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所**要访问的虚拟内存页面（虚拟内存页面所对应的物理内存块）不在物理内存时**，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

- 如果内存中**有空闲块**，则为进程**分配一个空闲块**，将所缺页面装入该块，并修改页表中相应的页表项。
- 如果内存中**没有空闲块**，则**由页面置换算法选择一个页面淘汰**，若该页面在内存期间**被修改过**（通过页表修改标志位来判断），则要将其**写回外存**（页表有记录对应的外存地址）。未修改过的页面不用写回外存（因为你没修改，外存的跟内存的一模一样，再写回覆盖一遍就是浪费时间）。



#### 2.缺页中断发生的具体几种情况：

- 第一种情况：页面不仅不在物理内存，虚拟内存和物理内存的映射都没建立（也就是页表里都没这项）
  - malloc()和mmap()等堆内存分配的系统调用，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。
- 第二种情况：内面不在物理内存内，映射存在（也就是页表里有这项）
  - 缺页中断：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。
- 第三种情况：fork的子进程要修改物理页时，子进程有自己的虚拟内存，有页表，但是实际上没有真正的物理内存，它的映射的物理内存是父进程的。当子进程想修改的时候，将通过缺页中断，写时复制，重新拷贝一份物理内存，与虚拟内存对应。
  - 当使用fork等系统调用创建子进程时，子进程不论有无自己的虚拟内存地址（一般都有自己的虚拟内存地址），它的虚拟内存地址都有对于物理页的映射，但它们共同映射的这些物理页属性为只读，即linux并未给子进程真正分配物理页，当父子进程任何一方要写相应物理页时，导致缺页中断的写时复制；
  - 写时复制：被访问的页存在（有物理页），但是该页是只读的（是父进程的，不让子进程修改），想对该页进行写操作的话，内核将会将这个已存在的只读页中的数据复制到一个新的页框中，然后再修改。
    - 比如一个全局变量，fork出来的子进程可以对它修改，但是不会影响主进程里的值，因为子进程修改时发生了写时复制，修改了给它复制的那份，并没有影响主进程的值。这就是多进程的好处，隔离性特别好。所以想让父子进程数据传递，也得通过进程通信。但是多线程就不用，多线程可以方便的进行线程间通信，同样的线程间的隔离性就弱多了，一个线程崩，整个进程崩。

#### 3.缺页中断处理步骤

缺页中断处理步骤：（或者回答开头的有空闲块调入且修改页表项、没空闲块时页面置换）

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

1、保护CPU现场

2、分析中断原因

3、转入缺页中断处理程序进行处理

4、恢复CPU现场，继续执行



#### 4.缺页中断与一般中断的区别：

但是**缺页中断**是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，**与一般的中断存在区别：**

1、在指令执行期间产生和处理中断信号，**CPU通常在一条指令执行完后检查是否有中断请求**，而**缺页中断**是在**指令执行期间**，发现所要访问的指令或数据不在内存时，缺页中断才产生和处理的。

2、**一条指令在执行期间可能产生多次缺页中断**。如一条读取数据的多字节指令，指令本身跨越两个页面，若指令后一部分所在页面和数据所在页面均不在内存，则该指令的执行至少产生两次缺页中断。

3、缺页中断返回是，**执行产生中断的那一条指令**（也就是执行这个指令时缺页了，等页面回来后继续还要执行这条指令，也就是PC指针不能+1），而一般的中断返回是，**执行下一条指令**。

### 6.操作系统中的页表寻址

页式内存管理，内存分成固定长度的一个个页片。操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表，页表的内容就是该进程的虚拟地址到物理地址的一个映射。页表中的每一项都记录了这个页的基地址。通过页表，**由逻辑地址的高位部分先找到逻辑地址对应的页基地址（开头20位就是页号，物理内存分成了2^20=1M页）**，再由页基地址偏移一定长度就得到最后的物理地址，**偏移的长度由逻辑地址的低位部分(后边12位就是偏移，刚好对应0-4K，即1页)**决定。一般情况下，这个过程都可以由硬件完成，所以效率还是比较高的。页式内存管理的优点就是比较灵活，内存管理以较小的页为单位，方便内存换入换出和扩充地址空间。



Linux最初的**两级页表机制：**

两级分页机制将32位的虚拟空间分成三段，低十二位表示页内偏移，高20分成两段分别表示两级页表的偏移。

\* PGD(Page Global Directory): 最高10位，全局页目录表索引（第一级页表）

\* PTE(Page Table Entry)：中间10位，页表入口索引（第二级页表）

**参考王道OS笔记两级页表部分：**

当在进行地址转换时，结合在CR3寄存器中存放的页目录(page directory, PGD)的这一页的物理地址(对应`97*4K`)，再加上从虚拟地址中抽出高10位叫做页目录表项(内核也称这为pgd)的部分作为偏移(对应00 0000 0010), 即定位到可以描述该地址的pgd(对应 `97*4K+2`)；从该pgd中可以获取可以描述该地址的页表的物理地址(对应`3*4K`)，再加上从虚拟地址中抽取中间10位作为偏移(对应 00 0000 0001), 即定位到可以描述该地址的pte(`3*4K+1`)；在这个pte中即可获取该地址对应的页的物理地址(`4*4K`), 加上从虚拟地址中抽取的最后12位，即形成该页的页内偏移(1111 1111 1111), 即可最终完成从虚拟地址到物理地址的转换(`4*4K+4095`)。从上述过程中，可以看出，对虚拟地址的分级解析过程，实际上就是不断深入页表层次，逐渐定位到最终地址的过程，所以这一过程被叫做page table walk。

### 7.OS缺页置换算法

**参考王道OS笔记页面置换算法**

当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据**送至磁盘对换区**，替换一个页，这种现象叫做缺页置换。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

当前操作系统最常采用的缺页置换算法如下：

- 1.FIFO，First In First Out：选择**换出**的页面是**最先进入的页面**。
  - 该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。
- 2.最佳OPT，Optimal replacement algorithm：所选择的被**换出**的页面将是**最长时间内不再被访问**，通常可以保证获得最低的缺页率。
  - 操作系统无法提前预判页面访问序列。因此**，最佳置换算法是无法实现的**。
- 3.最近最久未使用LRU，Least Recently Used：虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。
  - 真实操作系统中不可能实现，每次需要记录时间戳，还得比较谁最先出现，这成本完全不能接受。虽然性能好，但是**开销太太大**
- 4.最近未使用NRU， Not Recently Used  或者叫 时钟置换算法（clock）
  - 请求分页管理中的页表中有这个访问位的记录。

    - 循环队列，只记录0/1。
    - 在访问内存时，每访问一页，就把它那页置为1，标识最近访问过。
    - 在淘汰页面时，如果指针指的那页是1，那么就置为0，指针跳到下一个。如果指针指到了0，那么就是淘汰这页了。
  - 缺点：在很少有缺页的进程中，那么几乎就退化成了顺序淘汰。
- 5.改进型的时钟置换算法
  - 再设置一个快指针，定时循环把所有页面的访问位置0，这样就可以体现出最近未用的思想了，不再怕退化成顺序淘汰。同时慢指针还按原来的策略自己慢慢的查找该淘汰谁。

### 8.虚拟内存和物理内存怎么对应

虚拟内存技术使得不同进程在运行过程中，它所**看到的是自己独自占有**了当前系统的**4G内存**。

虚拟内存采用分段存储管理，物理内存采用分页存储管理。虚拟内存与物理内存的映射关系记录在页表中，通过查页表实现映射。如果该访问某个虚拟内存了，一查页表不在物理内存里，则会产生缺页中断。

### 9.操作系统中的结构体对齐，字节对齐

详见底下博客，例子很多

https://levphy.github.io/2017/03/23/memory-alignment.html

- 1、原因：
  - 1）平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。
  - 2）性能原因：数据结构（尤其是栈）应该尽可能地在自然边界上对齐。原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。
- 2、规则
  - **1.对于结构体的各个成员，第一个成员的偏移量是0，排列在后面的成员其当前偏移量必须是当前成员类型的整数倍**
  - **2.结构体内所有数据成员各自内存对齐后，结构体本身还要进行一次内存对齐，保证整个结构体占用内存大小是结构体内最大数据成员的最小整数倍**
  - **3.如程序中有#pragma pack(n)预编译指令，则所有成员对齐以n字节为准(即偏移量是n的整数倍)，不再考虑当前类型以及最大结构体内类型**
- 3、定义结构体对齐
  - 可以通过预编译命令#pragma pack(n)，n=1,2,4,8,16来改变这一系数，其中的n就是指定的“对齐系数”。
- 4、举例

```c++
#pragma pack(2)

struct AA {

int a;    //长度4 > 2 按2对齐；偏移量为0；存放位置区间[0,3]

char b;  //长度1 < 2 按1对齐；偏移量为4；存放位置区间[4]

short c;   //长度2 = 2 按2对齐；偏移量要提升到2的倍数6；存放位置区间[6,7]

char d;  //长度1 < 2 按1对齐；偏移量为7；存放位置区间[8]；目前共9Byte
//结束时检查整个结构体要是2的倍数，一看目前只有9Byte，再添1Byte形成2的倍数。
//即总共10Byte
};

#pragma pack()
```

### 10.内存置换的方式（页面置换算法）

#### 1.FIFO（先进先出）

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

#### 2.OPT(最佳算法)

所选择的被换出将是**最长时间内不再被访问的页面**，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

#### 3.LRU（最近最久未使用）

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将**最近最久未使用的页面**换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为**每次访问都需要更新**链表，因此这种方式**实现的 LRU 代价很高。**

#### 4.第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面**既老又没有被使用，可以立刻置换掉**；**如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。**

#### 5.时钟算法（clock）

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面链接起来，再使用一个指针指向最老的页面。

- 环形链表，只记录0/1。
- 在访问内存时，每访问一页，就把它那页置为1，标识最近访问过。
- 在淘汰页面时，如果指针指的那页是1，那么就置为0，指针跳到下一个。如果指针指到了0，那么就是淘汰这页了。（体现了第二次机会的思想）
- 缺点：在很少有缺页的进程中，那么几乎就退化成了顺序淘汰。

#### 6.改进的clock算法

再设置一个快指针，定时循环把所有页面的访问位置0，这样就可以体现出最近未用的思想了，不再怕退化成顺序淘汰。同时慢指针还按原来的策略自己慢慢的查找该淘汰谁。

### 11.A* a = new A; a->i = 10;在内核中的内存分配上发生了什么？

​	可以先讲一些内存结构的知识。

A* a = new A; a->i = 10;具体发生的细节：

- 1）A *a：a是一个局部变量，类型为指针，故而操作系统在程序栈区开辟4/8字节的空间（0x000m），分配给指针a。
  - 注：a是在程序执行时分配的内存，而不是exec()载入时就有的，因为只有全局变量、静态变量等在载入程序时就有内存，而a是局部变量，是运行时分配的栈内存
- 2）new A：通过new动态的在堆区申请类A大小的空间（0x000n）。
  - 注：new指令，分配堆区
- 3）a = new A：将指针a的内存区域填入栈中类A申请到的地址的地址。即*（0x000m  栈）=0x000n   堆。
  - 注：栈、堆两个字就是我用于辅助指明这块地址是在哪个区域的
- 4）a->i：先找到指针a的地址0x000m  （栈），通过a的值0x000n和i在类a中偏移offset，得到a->i的地址0x000n + offset   （堆），进行*(0x000n + offset  堆) = 10的赋值操作，即内存0x000n + offset（堆） 的值是10。

### 12.什么是大端小端以及如何判断大端小端

- 大端(存储)模式：一个数据的低字节（低8位）内容存放在高地址中，高字节（高8位）的内容存放在低地址中。(简单的说就是：低字节，高地址。高字节，低地址。——>大端)
- 小端(存储)模式：一个数据的低字节内容存放在低地址中，高字节的内容存放在高地址中。(简单的说就是：低字节，低地址。高字节，高地址。——>小端)

我们可以根据联合体来判断该系统是大端还是小端。因为联合体变量总是从低地址存储。

![YUwdbQ.png](https://s1.ax1x.com/2020/05/12/YUwdbQ.png)

读数据都是低地址到高地址，对于数据要进行按位运算时要小心。

大端：0000 0000 0000 0001    =    1

小端：1000 0000 0000 0000    =     1

### 13.静态变量什么时候初始化（static）

https://zhuanlan.zhihu.com/p/37439983

**静态变量**存储在虚拟地址空间的**数据段（已初始化的）和bss段（未初始化的）**

全局变量、文件域的静态变量和类的静态成员变量在main执行之前的静态初始化过程中分配内存并初始化；局部静态变量（一般为函数内的静态变量）在main执行之前就会分配内存，但是在第一次使用时初始化。这里的变量包含内置数据类型和自定义类型的对象。

这里只说（面向过程的）**静态全局变量 和静态局部变量**，不考虑（面向对象的）静态成员变量和静态函数成员以及（面向过程的）静态函数。

**（面向过程的）静态全局变量：**

1. 该变量在数据区或者bss段分配内存；**（分配内存是在main函数执行之前就分配了，或者说编译时）**
2. 未经初始化的静态全局变量会（放在bss段）被程序自动初始化为0（自动变量的自动初始化值是随机的）；
3. 静态全局变量在声明它的整个文件都是可见的，而在文件之外是不可见的； 　
4. 静态变量都在全局数据区分配内存，包括后面将要提到的静态局部变量。对于一个完整的程序，在内存中的分布情况如下：【代码区】【全局数据区】【堆区】【栈区】，一般程序的由new产生的动态数据存放在堆区，函数内部的自动变量存放在栈区，静态数据（即使是函数内部的静态局部变量）存放在全局数据区。自动变量一般会随着函数的退出而释放空间，而全局数据区的数据并不会因为函数的退出而释放空间。

**（面向过程的）静态局部变量：**

1. 静态局部变量在bss段（未初始化的）分配内存；**（分配内存是在main函数执行之前就分配了，但不是编译时，虽然说是链接器起的作用，但是也不包含在可执行文件的大小里？只能说是执行Main之前）**
2. **静态局部变量在程序第一次执行到该对象的声明处时被首次初始化**，即以后的函数调用不再进行初始化；
3. 静态局部变量一般在声明处初始化，如果没有显式初始化，会被程序自动初始化为0；
4. 静态局部变量始终驻留在全局数据区，直到程序运行结束。但其作用域为局部作用域，当定义它的函数或语句块结束时，其作用域随之结束；

**用自己的话总结一下**

- 对于静态局部变量，编译时固定好内存位置，（在bss段？）
  - 加载到内存后，执行main之前，给它分配空间。这个空间（bss段）不占用可执行文件的大小。
  - 在第一次执行到该对象声明处，进行初始化。

- 对于静态全局变量，编译时就固定好内存位置了，初始化的在数据区，没初始化的在bss段，然后存放在可执行文件中（bss段不存在可执行文件中，数据段存在）。等到程序运行时，直接加载到内存对应位置。顺带把没初始化的静态全局变量置为0（我猜的是在这时候初始化）。
  - 初始化的静态全局变量，存在数据段，在编译时就分配好内存和初始化了。
  - 未初始化的静态全局变量，就存在bss段了，加载程序的时候分配bss区并初始化为0，这过程在执行Main之前（这一条是我猜的）

### 14.内存溢出和内存泄漏（virtual还不会）

内存泄漏堆积后的后果就是内存溢出。

#### 1、内存溢出out of memory

概念的三个理解：

- 内存溢出(Out Of Memory，简称OOM)：是指应用系统中存在无法回收的内存或使用的内存过多，最终使得程序运行要用到的内存大于能提供的最大内存。此时程序以正常运行该软件，而由系统配置、数据流、用户代码等原因而导致的内存溢出错误，即使用户重新执行任务依然无法避免。
- 内存溢出：是指程序在申请内存时，没有足够的内存空间供其使用，也就是说**内存不够用**，出现out of memory；比如申请了一个integer,但给它存了long才能存下的数，那就是内存溢出。
  - 例如一种内存不够用的体现：调用栈溢出。（多层递归）
- 或者当操作系统无法创建更多的虚拟内存时，现代计算机就会出现典型的OOM情况，因为它的所有潜在支持内存都已装满，或者最终用户禁用了它们。该条件可能是由于fork（）之后的写时复制而引起的。

自己总结一下：

- 1.内存泄露太多了，导致内存不够用了。
- 2.你申请的内存太多了，我无法满足，也就是内存不够用。
- 3.或者说物理内存和swap区都用光了，无法再创建更多内存了。

内存溢出： 指程序申请内存时，没有足够的内存供申请者使用，或者说，给了你一块存储int类型数据的存储空间，但是你却存储long类型的数据，那么结果就是**内存不够用**，此时就会报错OOM,即所谓的内存溢出，简单来说就是自己所需要使用的空间比我们拥有的内存大，内存不够使用，所造成的内存溢出。

当操作系统无法创建更多的虚拟内存时，现代计算机就会出现典型的OOM情况，因为它的所有潜在支持内存都已装满（物理内存和swap区都满了），或者最终用户禁用了它们。该条件可能是由于fork（）之后的写时复制而引起的。

另一种理解：（我感觉还是以上边为准吧）

内存溢出就是内存越界。内存越界有一种很常见的情况是调用栈溢出（即stackoverflow），虽然这种情况可以看成是栈内存不足的一种体现。但内存溢出并不一定跟内存分配有什么关系，因为还有一种情况是缓冲区溢出。

**内存溢出原因：**

- 内存中加载的数据量过于庞大，如一次从数据库取出过多数据
- 集合类中有对对象的引用，使用完后未清空，使得JVM不能回收（？？不会）
- 代码中存在死循环或循环产生过多重复的对象实体
- 使用的第三方软件中的BUG
- 启动参数内存值设定的过小

#### 2、内存泄漏memory leak

[https://zh.wikipedia.org/wiki/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F](https://zh.wikipedia.org/wiki/内存泄漏)

**内存泄漏的概念：**

**内存泄漏**是指由于疏忽或错误造成了程序**未能释放掉不再使用的内存**的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。

**内存泄漏的后果：**

内存泄漏会因为减少可用内存的数量从而降低计算机的性能。最终，在最糟糕的情况下，过多的可用内存被分配掉导致全部或部分设备停止正常工作，或者应用程序崩溃。

内存泄漏带来的后果可能是不严重的，有时甚至能够被常规的手段检测出来。**在现代操作系统中，一个应用程序使用的常规内存在程序终止时被释放。**这表示**一个短暂运行的应用程序中的内存泄漏不会导致严重后果**。但是例如在服务器上长时间跑一个程序时，如果这个程序有内存泄露，它可能源源不断消耗内存，造成严重后果。具体情况如下：

在以下情况，内存泄漏导致较严重的后果：

- 程序运行后置之不理，并且随着时间的流逝消耗越来越多的内存（比如服务器上的后台任务，尤其是嵌入式系统中的后台任务，这些任务可能被运行后很多年内都置之不理）；
- 新的内存被频繁地分配，比如当显示电脑游戏或动画视频画面时；
- 程序能够请求即使在程序终止之后也不会被释放的内存（比如共享内存）；
- 泄漏在操作系统内部发生；
- 泄漏在系统关键驱动中发生；
- 内存非常有限，比如在嵌入式系统或便携设备中；
- 当运行于一个程序终止时内存并不自动释放内存的操作系统（比如AmigaOS）之上时。
  - 传统的linux windows等，进程结束时所有的内存都会回收，不管是你泄露的还是没泄露的。但是AmigaOS就不会，比较落后。

**内存泄漏的分类：**

- 1、堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc，new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。
- 2、系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。
- 3、没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。（在说什么？？还不会）



### 15.堆内存和栈内存的区别；从堆和栈上建立对象哪个快？（考察堆和栈的分配效率比较）

#### 1.堆内存和栈内存的区别

（1）管理方式不同。栈由操作系统自动分配释放，无需我们手动控制；堆的申请和释放工作由程序员控制，容易产生内存泄漏；

（2）空间大小不同。每个进程拥有的栈的大小要远远小于堆的大小。理论上，程序员可申请的堆大小为虚拟内存的大小，进程栈的大小 64bits 的 Windows 默认 1MB，64bits 的 Linux 默认 10MB；

（3）生长方向不同。堆的生长方向向上，内存地址由低到高；栈的生长方向向下，内存地址由高到低。

（4）分配方式不同。堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。栈的静态分配是由操作系统完成的，比如局部变量的分配。**栈的动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由操作系统进行释放，无需我们手工实现。**

（5）分配效率不同。栈由操作系统自动分配，会在硬件层级对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了**栈的效率比较高**。堆则是由C/C++提供的库函数或运算符来完成申请与管理，实现机制较为复杂，频繁的内存申请容易产生内存碎片。显然，堆的效率比栈要低得多。

（6）存放内容不同。栈存放的内容，函数返回地址、相关参数、局部变量和寄存器内容等。当主函数调用另外一个函数的时候，要对当前函数执行断点进行保存，需要使用栈来实现，首先入栈的是主函数下一条语句的地址，即扩展指针寄存器的内容（EIP），然后是当前栈帧的底部地址，即扩展基址指针寄存器内容（EBP），再然后是被调函数的实参等，一般情况下是按照从右向左的顺序入栈，之后是被调函数的局部变量，注意静态变量是存放在数据段或者BSS段，是不入栈的。出栈的顺序正好相反，最终栈顶指向主函数下一条语句的地址，主程序又从该地址开始执行。堆，一般情况堆顶使用一个字节的空间来存放堆的大小，而堆中具体存放内容是由程序员来填充的。

#### 2.从堆和栈上建立对象哪个快？（考察堆和栈的分配效率比较）

**堆和栈的分配效率比较：**栈效率高

 1.分配和释放，堆在分配和释放时都要调用函数（MALLOC,FREE)，比如**分配时会到堆空间去寻找足够大小的空间**（因为频繁的内存申请释放后会造成内存碎片），这些都**会花费一定的时间**，具体可以看看MALLOC和FREE的源代码，他们做了很多额外的工作，而栈却不需要这些。

 2.访问时间，**访问堆的一个具体单元，需要两次访问内存**，第一次得取得指针，第二次才是真正得数据，而栈只需访问一次。另外，**堆的内容被操作系统交换到外存的概率比栈大**，栈一般是不会被交换出去的。

3.硬件对栈有支持。栈由操作系统自动分配，会在硬件层级对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。

**栈对象和堆对象比较：**

```c++
Object object;//栈对象
Object *object=new Object();//堆对象
```

- **栈对象的优势是在适当的时候自动生成，又在适当的时候自动销毁，不需要程序员操心；而且栈对象的创建速度一般较堆对象快，因为分配堆对象时，会调用 operator new操作，operator new 会采用某种内存空间搜索算法，而该搜索过程可能是很费时间的，产生栈对象则没有这么麻烦，它仅仅需要移动栈顶指针就可以了(这相当于上边效率比较的第一条)**。但是要注意的是，通常栈空间容 量比较小，一般是1MB～2MB，所以体积比较大的对象不适合在栈中分配。特别要注意递归函数中最好不要使用栈对象，因为随着递归调用深度的增加，所需的 栈空间也会线性增加，当所需栈空间不够时，便会导致栈溢出，这样就会产生运行时错误。
- **堆对象，其产生时刻和销毁时刻都要程序员精确定义**，也就是说，程序员对堆对象的生命具有完全的控制权。我们常常需要这样的对象，比如，我们需要创建一个对象，能够被多个函数所访问，但是又不想使其成为全局的，那么这个时候创建一个堆对象无疑是良好的选择，然后在各个函数之间传递这个堆对象的指针，便可以实现对该对象的共享。另外，相比于栈空间，堆的容量要大得多。实际上，当物理内存不够时，如果这时还需要生成新的堆对象，通常不会产生运行时错误，而是系统会使用虚拟内存来扩展实际的物理内存。

### 16.内存分配方式及常见错误

#### 1.内存分配方式

内存分配方式有三种：

（1） 从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。

（2） 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。

（3） 从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

#### 2.常见的内存错误及其对策

- 1.内存分配未成功，却使用了它。
  - 常用解决办法是，在使用内存之前检查指针是否为NULL。如果指针p是函数的参数，那么在函数的入口处用assert(p!=NULL)进行检查。如果是用malloc或new来申请内存，应该用if(p==NULL) 或if(p!=NULL)进行防错处理。
- 2.内存分配虽然成功，但是尚未初始化就引用它
  - 一定要初始化
- 3.内存分配成功并且已经初始化，但操作越过了内存的边界
  - 在使用数组时经常发生下标“多1”或者“少1”的操作。特别是在for循环语句中，循环次数很容易搞错，导致数组操作越界。
- 4.忘记了释放内存，造成内存泄露
  - 含有这种错误的函数每被调用一次就丢失一块内存。刚开始时系统的内存充足，你看不到错误。终有一次程序突然死掉，系统出现提示：内存耗尽。动态内存的申请与释放必须配对，程序中malloc与free的使用次数一定要相同，否则肯定有错误（new/delete同理）。
- 5.释放了内存却继续使用它
  - 函数的return语句写错了，注意不要返回指向“栈内存”的“指针”或者“引用”，因为该内存在函数体结束时被自动销毁。
  - 使用free或delete释放了内存后，没有将指针设置为NULL。导致产生“野指针”。

### 17.外部碎片和内部碎片

**外部碎片：**

- 外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。
- 外部碎片是出于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请。
- 比如：
  - 虚拟内存中的分段分配的。比如堆内存不足，没有足够的连续区域去分配了。

**内部碎片：**

- 内部碎片就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间；
- 内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程并不使用这个存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。
- 比如：
  - 物理内存中的分页分配。比如一个程序用了5KB，但是一页是4KB，那必须给2页。第二页有3KB浪费了，这3KB就是内部碎片。

## 3.文件（磁盘）

### 1. 请你回答一下软链接和硬链接区别

为了解决文件共享问题，Linux引入了软链接和硬链接。除了为Linux解决文件共享使用，还带来了隐藏文件路径、增加权限安全及节省存储等好处。

- 硬链接：1个inode号对应多个文件名，则为硬链接，即硬链接就是同一个文件使用了不同的别名,使用ln创建。
  - 即，硬链接出来的文件名与原始文件名是同一个inode，它俩平级。所以要想真正删除文件，你得把所有硬链接起来的文件名所在目录项都删除了
- 软链接：若文件用户数据块中存放的内容是另一个文件的路径名指向，则该文件是软连接。软连接是一个普通文件，有自己独立的inode,但是其数据块内容比较特殊。
  - 即，软连接出来的文件名，跟原始文件名不是同一个inode，原始文件代表本题，软连接的就是个快捷方式。要想真正删除文件得删本体文件，删除快捷方式不顶用。

**用自己的话说一下**

- 硬链接：只有把所有链接到文件的目录都删了，才能把文件删除。
  - 硬链接起来的各个目录项和原始文件是一样的权利
- 软连接（快捷方式）：删了真正的文件，没删快捷方式，那么快捷方式不能用了；删了快捷方式，没删真正的文件，那么文件没有被删。
  - 弱链接出来的快捷方式的权利比原始文件弱多了

即当删除原始文件f1后，硬连接f2不受影响，但是符号连接（也就是软连接）f1的文件（即快捷方式）无效了。

### 2.为什么要有page cache，操作系统怎么设计的page cache

- 概念:
  - page cache也叫File cache，cache里的是文件数据。page cache目的是为了加快从磁盘读取文件的速率。
  - 注意：
    - 为**快速实现内存**由虚拟地址到物理地址映射服务的cache叫**快表TLB**
    - 为**快速实现硬盘**读入服务的cache才是这个**page cache**
- 过程：
  - 当内核发起一个读请求时（例如进程发起read()请求），page cache中有一部分磁盘文件的缓存，因为从磁盘中读取文件比较慢，所以读取文件首先会检查请求的数据是否缓存到了page cache中，如果有，那么直接从内存中读取，不需要访问磁盘，这被称为cache命中（cache hit）。如果cache中没有请求的数据，即cache未命中（cache miss），就必须从磁盘中读取数据。然后内核将读取的数据缓存到cache中，这样后续的读请求就可以命中cache了。page可以只缓存一个文件部分的内容，不需要把整个文件都缓存进来。
- 怎样设计page cache
  - 在 Linux 内核中，文件的每个数据块最多只能对应一个 Page Cache 项，它通过两个数据结构来管理这些 Cache项，一个是radix tree，另一个是双向链表。Radix tree 是一种搜索树，Linux内核利用这个数据结构来通过文件内偏移快速定位Cache 项

### 3.磁盘文件系统

![YWHVPA.png](https://s1.ax1x.com/2020/05/18/YWHVPA.png)

- 引导块：引导扇区。操作系统启动需要的
- 超级块：记录两个位图有多大等信息（mount装载操作就是要读这个超级块）
- 块组描述符：没学
- 预留GDT块：没学
- 数据块位图：是一个跟block数等大的数组，用来表示哪些block是空闲的，用来指导分配block（也就是数据块）
- inode位图：是一个跟上限inode（所有的inode在磁盘同一个连续的block区域）数等大的数组，用来表示哪些inode区域是空闲的，用来指导新建inode
- inode表(存各个FCB)：第一个是'/'。这个区域存的是各个FCB。例如'/'的FCB，它会告诉你'/'的实际目录项存在数据区的哪里 (在数据区的第多少个位置处)。可以去数据区找‘/’的实际目录项，查这个数据区的目录项会告诉'/''的子文件们的FCB在哪(也就是在inode区的第多少个位置处)
- 数据块：有可能是存的真实文件，也有可能是目录项的实际位置，inode表里相当于只存了地址，真正的目录项在这里。

### 4.虚拟文件系统（VFS）

VFS是虚拟文件系统层（进程与文件系统之间的抽象层），与它相关的数据结构只存在于**物理内存**当中。其目的是屏蔽下层具体文件系统操作的差异，为上层的操作提供一个统一接口，正是由于VFS的存在，Linux中允许多个不同的文件系统共存。借助VFS可以直接使用`open()`、`read()`、`write()`这样的系统调用操作文件，而无须考虑具体的文件系统和实际的存储介质。**有了VFS以后，万物皆文件，可以以文件的方式操作外设，操作硬盘。**

VFS中包含着向物理文件系统转换的一系列数据结构，如VFS超级块、VFS的Inode、各种操作函数的转换入口等。Linux中VFS依靠四个主要的数据结构来描述其结构信息，分别为超级块、索引结点、目录项和文件对象，这些数据结构大都会与磁盘上的对应上。

- **超级块（Super Block）**：超级块对象表示一个文件系统。**它存储一个已安装的文件系统的控制信息**，包括文件系统名称（比如Ext2）、文件系统的大小和状态、块设备的引用和元数据信息（比如空闲列表等等）。**超级块与磁盘上文件系统的超级块对应。**
- **索引结点（Inode）**：索引结点对象存储了文件的相关元数据信息，例如：文件大小、设备标识符、用户标识符、用户组标识符等等。Inode分为两种：**一种是VFS的Inode，一种是具体文件系统的Inode。前者在内存中，后者在磁盘中。**所以每次其实是将磁盘中的Inode调进填充内存中的Inode，这样才是算使用了磁盘文件Inode。当创建一个文件的时候，就给文件分配了一个Inode。一个Inode只对应一个实际文件，一个文件也会只有一个Inode（Unix/Linux系统中目录也是一种文件，打开目录实际上就是打开目录文件。目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码）。
- **目录项（Dentry）**：引入目录项对象的概念主要是出于方便查找文件的目的。不同于前面的两个对象，目录项对象只存在于内存中，**实际对应的是磁盘的目录innode对象**。VFS在查找的时候，根据一层一层的目录项找到对应的每个目录项的Inode，那么沿着目录项进行操作就可以找到最终的文件。
- **文件对象（File）**：文件对象描述的是进程已经打开(open)的文件。因为一个文件可以被多个进程打开，所以一个文件可以存在多个文件对象，但多个文件对象其对应的索引节点和目录项对象肯定是惟一的，关系如下图：(没图)

### 5.文件读写使用的系统调用（不会）

### 6.海量数据的bitmap使用原理（数据块位图）

文件系统中的 **数据块位图**[：是一个跟block数等大的数组，用来表示哪些block是空闲的，用来指导分配block（也就是数据块）]   和  **inode位图**[：是一个跟上限inode（所有的inode在磁盘同一个连续的block区域）数等大的数组，用来表示哪些inode区域是空闲的，用来指导新建inode]     **就是用了bitmap的原理。**

比如一个int数组，int a[5];  一共5个int，所以占据`5*4byte=20byte=20*8bit`。它的**每一位就代表一个数字的存在与否**。比如a[0]就可以表示数字0-31，a[1]表示32-63，所以一共可以表示数字0-159的存在与否，或者表示是否空闲。

### 7.布隆过滤器原理与优点（这其实不属于操作系统）

https://www.cnblogs.com/CodeBear/p/10911177.html

类似于Hash映射，假如数据a的hash值是5，那么向量下标5处，对应元素置为1。因为有hash冲突的存在，可能多个数据对应同一hash值。所以值为1，说明数据a可能存在，也可能不存在。值为0，那么数据a肯定不存在。

所以给你一个数据b，你算出来它的hash值，去查该位置，一看是1，就判定它存在。这有一定的误判率，可能数据b不存在，是数据a跟数据b hash值相同，数据a把这个值置成的1。所以也不可以删除数据。

- 优点：由于存放的不是完整的数据，所以占用的内存很少，而且新增，查询速度够快；
- 缺点： 随着数据的增加，误判率随之增加；无法做到删除数据；只能判断数据是否一定不存在，而无法判断数据是否一定存在。

### 8.Bloom过滤器处理大规模问题（这其实不属于操作系统）

布隆过滤器应用在一些需要快速判断某个元素是否属于集合，但是并不严格要求100%正确的场合

哈希表和位图的问题是当数据量大时会出现哈希冲突，为了降低冲突，**布隆过滤器使用多个哈希函数，而不是一个。**

哈希表的内存消耗随着数据量的增大也比较严重：就算只有1亿个URL，每个URL只算50个字符，就需要5GB内存。

优点：节约缓存空间（空值的映射），不再需要空值映射，由于布隆过滤器所用的空间非常小，所有布隆过滤器可以常驻内存，Key-Value系统中Value 保存在磁盘中，使用布隆过滤器可以快速判断某个Key对应的Value是否存在，因此可以避免很多不必要的磁盘IO操作。

缺点：一般情况下不能从布隆过滤器中删除元素.我们很容易想到把位列阵变成整数数组，每插入一个元素相应的计数器加1，这样删除元素时将计数器减掉就可以了。然而要保证安全的删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面.这一点单凭这个过滤器是无法保证的。

## 4.IO设备（外设）

### 1.Unix网络编程中的5种网络IO模型

IO复用的例子比喻：知乎 https://www.zhihu.com/question/32163005/answer/255238636

IO复用图解：https://zhuanlan.zhihu.com/p/121826927

- 1.阻塞IO:
  - 当用户线程发出IO请求之后，内核会去查看数据是否就绪，**如果没有就绪**就会等待数据就绪，而**用户线程就会处于阻塞状态**，用户线程交出CPU。当数据就绪之后，内核会将数据拷贝到用户线程，并返回结果给用户线程，用户线程才解除block状态。
  - 辅助理解：当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据，对于network IO来说，一般数据在一开始还没有到达，kernel会等待足够的数据到来，而在用户进程这边，整个进程会被阻塞挂起，当kernel等到数据准备好，它就会将数据从内核缓冲区拷贝到用户进程缓冲区，然后kernel返回结果，用户进程才进入就绪状态，重新运行起来
  - 自己的话：
    - 阻塞IO模型就是用户线程发出IO请求后，就立马去看看数据准备好了没，如果没准备好，线程就被阻塞了，等待数据到来时再次唤醒。
- 2.非阻塞IO:
  - 当**用户线程**发起一个read操作后，**并不需要等待，而是马上就得到了一个结果**。如果结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦内核中的数据准备好了，并且又再次收到了用户线程的请求，那么它马上就将数据拷贝到了用户线程，然后返回。所以事实上，在非阻塞IO模型中，用户线程需要不断地询问内核数据是否就绪，也就说非阻塞IO每隔一段时间就要占用CPU去访问看看返回结果了没有。
  - 辅助理解: 当用户进程发出recvfrom操作时，如果kernel中的数据还没有准备好，那么它并不会阻塞用户进程，而是立刻返回，从用户进程角度讲 ，它发起一个recvfrom操作后，并不需要等待，而是马上就得到了一个结果，**用户线程通过结果判断数据是否准备好**，**如果没有准备好,过段时间再次发送recvfrom操作**，一旦kernel中的数据准备好了，并且又再次收到了用户进程的recvfrom调用操作，马上将数据从内核缓冲区拷贝到了用户进程缓冲区
  - 自己的话：
    - 非阻塞IO模型就是用户线程发出IO请求后，就立马去看看数据准备好了没，一看没准备好，我先把CPU调度走，线程不进入阻塞，过一会儿再来看看准备好了没，一看又没准备好，那就再过一会儿再来。
- 3.IO复用/多路转接IO:
  - io多路复用（这翻译真的很坑爹啊），指的是同一个进（线）程可以处理多个IO数据流。
  - 在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，**只需要使用一个线程就可以管理多个socket**，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并**且只有在真正有socket读写事件进行时，才会使用IO资源**，所以它大大减少了资源占用。
  - select，poll以及大名鼎鼎的epoll就是IO多路复用模型，其特点就在于单个系统调用可以同时处理多个网络连接的IO，它的基本原理就是select/poll/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程
  - 当用户进程调用了select/poll/epoll，整个进程会被阻塞，而同时，kernel会“监视”所有select/poll/epoll负责的socket，当任何一个socket中的数据准备好了，select/poll/epoll就会返回。这个时候用户进程再调用recvfrom操作，将数据从内核缓冲区拷贝到用户进程缓冲区
  - 自己的话：
    -  一个单线程来管理多个socket，当本为多进程或多线程来接收多个连接的消息变为单进程或单线程保存多个socket的状态后轮询处理。当某个socket有数据到达了，该单线程就通知用户进程。
- - 非阻塞等待，每隔一段时间就去检测IO事件是否就绪。没有就绪就可以做其他事。
- 4.信号驱动IO:
  - 信号驱动IO: linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO数据就绪到达内核时，进程收到SIGIO信号。然后处理IO事件。
  - 辅助理解: 在信号驱动IO模型中，当用户线程发起一个IO请求操作，会给对应的socket注册一个信号函数，然后**用户线程会继续执行**，当内核数据就绪时（IO传递到内核的）会发送一个信号给用户线程，用户线程接收到信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。
  - 自己的话：
    - 发出IO后，本线程先往下做着别的事（不需要此数据的事），IO数据到了会有信号通知我到了，我再去处理跟这个IO数据有关的事。（这个是系统内核通知用户进程的，而IO复用是单线程来通知用户进程的）
- 5.异步IO: 
  - 异步IO模型才是最理想的IO模型，在异步IO模型中，当用户线程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个asynchronous read之后，它会立刻返回，说明read请求已经成功发起了，因此不会对用户线程产生任何block。然后，内核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程发送一个信号，告诉它read操作完成了。也就说**用户线程完全不需要关心实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接去使用数据了。**
  - 在异步IO模型中，IO操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完成，然后发送一个信号告知用户线程操作已完成。用户线程中不需要再次调用IO函数进行具体的读写。这点是和信号驱动模型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据已经就绪，然后需要用户线程调用IO函数进行实际的读写操作；而**在异步IO模型中，收到信号表示IO操作已经完成，不需要再在用户线程中调用iO函数进行实际的读写操作。**
  - 自己的话：
    - 信号驱动IO是，进程只用张一句嘴我要什么什么，就可以去继续往下执行了。当数据就绪时，内核就告诉它，已经给你放到内核空间了，请自行读入。（通知你来自取）
    - 异步IO，进程只用张一句嘴我要什么什么，就可以去继续往下执行了。当数据就绪时，内核就告诉它，已经给你放到用户空间了。（送货上门以后再通知你到了）

## 5.linux相关

### 1.如何修改文件最大句柄数？（可同时open的文件数目）

Linux默认最大文件句柄数是1024个，在Linux服务器文件并发量比较大的情况下，系统会报"too many open files"的错误。故在Linux服务器高并发调优时，往往需要预先调优Linux参数，修改Linux最大文件句柄数。

有两种方法：

1. ulimit -n <可以同时打开的文件数>，限制当前shell以及该shell启动的进程打开的文件数量。将最大句柄数修改为指定的参数（注：该方法只针对当前shell以及该shell启动的进程有效，重新打开一个shell，参数还是之前的值）

   首先用ulimit -a查询Linux相关的参数，如下所示：

   ```c++
   core file size          (blocks, -c) 0
   data seg size           (kbytes, -d) unlimited
   scheduling priority             (-e) 0
   file size               (blocks, -f) unlimited
   pending signals                 (-i) 94739
   max locked memory       (kbytes, -l) 64
   max memory size         (kbytes, -m) unlimited
   open files                      (-n) 1024//这条就是代表最大文件句柄数
   pipe size            (512 bytes, -p) 8
   POSIX message queues     (bytes, -q) 819200
   real-time priority              (-r) 0
   stack size              (kbytes, -s) 8192
   cpu time               (seconds, -t) unlimited
   max user processes              (-u) 94739
   virtual memory          (kbytes, -v) unlimited
   file locks                      (-x) unlimited
   ```

   其中，open files就是最大文件句柄数，默认是1024个。

   修改Linux最大文件句柄数：  ulimit -n 2048， 将最大句柄数修改为 2048个。

   

   2.对所有进程都有效的方法，修改Linux系统参数

   vi /etc/security/limits.conf 添加

   soft　　nofile　　65536

   hard　　nofile　　65536

   将最大句柄数改为65536

   修改以后保存，注销当前用户，重新登录，修改后的参数就生效了

### 2.fork()与vfork()的区别

#### 1.为什么会有vfork()?

因为早期的fork()没有写时复制，也就是fork()的子进程，真的复制了一份物理内存。而fork()子进程一般都要立刻使用exec( )载入二进制映像，替换当前进程的映像，那个复制物理内存的操作就纯属浪费。所以有了vfork()，vfork的子进程暂时跟父进程共用物理内存，所以子进程是不能进行写操作的，那部分物理内存对于vfork子进程是只读的。换句话说，vfork()，专为子进程立即执行exec()而生。

#### 2.区别：

- 1.fork( )的子进程一开始与父进程共享数据段和代码段，需要写操作的时候会复制对应的页；vfork( )的子进程页与父进程共享数据段，但是不能进行写操作，它不会写时复制。
- 2.fork( )的父子进程的执行次序不确定；而vfork( )保证子进程先运行，因为vfork()出来子进程后，父进程就暂时阻塞了，因为在调用exec或exit之前与父进程数据是共享的，父进程在等待子进程调用exec或exit之后父进程才可能被调度运行。
- 3.vfork( )保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。

#### 3.用个例子比喻：

为什么会有vfork，因为以前的fork 很傻， 它创建一个子进程时，将会创建一个新的地址空间，并且拷贝父进程的资源，而往往在子进程中会执行exec 调用，这样，前面的拷贝工作就是白费力气了，这种情况下，聪明的人就想出了vfork，它产生的子进程刚开始暂时与父进程共享地址空间（其实就是线程的概念了），因为这时候子进程在父进程的地址空间中运行，所以子进程不能进行写操作，并且在儿子 霸占”着老子的房子时候，要委屈老子一下了，让他在外面歇着（阻塞），一旦儿子执行了exec 或者exit 后，相 于儿子买了自己的房子了，这时候就相当于分家了。

### 3.怎样确定当前线程是繁忙还是阻塞？（还不会）

使用ps命令查看

### 4.windows消息机制知道吗，请说一说(还不会)

当用户有操作(鼠标，键盘等)时，系统会将这些时间转化为消息。每个打开的进程系统都为其维护了一个消息队列，系统会将这些消息放到进程的消息队列中，而应用程序会循环从消息队列中取出来消息，完成对应的操作。

### 5.手写一下fork调用示例

1、概念：

Fork：创建一个和当前进程映像一样的进程可以通过fork( )系统调用：

成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。

最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。

在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。

2.fork示例

```c++
int main(void)
{
    pid_t pid;
    signal(SIGCHLD, SIG_IGN);
    printf("before fork pid:%d\n", getpid());
    int abc = 10;
    pid = fork();//fork()一个进程
	if(pid==-1)//错误返回
    {
        perror("tile");
		return -1;
    }
    if(pid>0)    //父进程空间
    {
       abc++;
        printf("parent:pid:%d \n", getpid());
        printf("abc:%d \n", abc);
        sleep(20); 
    }
    else if(pid==0)//子进程空间
    {
        abc++;
		printf("child:%d,parent: %d\n", getpid(), getppid());
		printf("abc:%d", abc);	
    }
    
    printf("fork after...\n");
    return 0;
}
```

### 6-1.源码到可执行文件的过程

**1）预编译**(.c到.i)

**主要处理源代码文件中的以“#”开头的预编译指令**。处理规则见下

1、删除所有的#define，展开所有的宏定义。

2、处理所有的条件预编译指令，如“#if”、“#endif”、“#ifdef”、“#elif”和“#else”。

3、处理“#include”预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中包含其他文件。

4、删除所有的注释，“//”和“/**/”。

5、保留所有的#pragma 编译器指令，编译器需要用到他们，如：#pragma once 是为了防止有文件被重复引用。

6、添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或警告是能够显示行号。

7、预编译之后生成的xxx.i或xxx.ii文件

**2）编译**(.i到.s)

把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码.s文件。

1、词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分割成一系列的记号。

2、语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的语法树是一种以表达式为节点的树。

3、语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定的语义。

4、优化：源代码级别的一个优化过程。

5、目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言表示。

6、目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移来替代乘法运算、删除多余的指令等。

**3）汇编**（.s到.o）

将汇编代码转变成机器可以执行的指令(机器码文件)。 汇编器的汇编过程相对于编译器来说更简单，没有复杂的语法，也没有语义，更不需要做指令优化，只是根据汇编指令和机器指令的对照表一一翻译过来，汇编过程有汇编器as完成。经汇编之后，产生目标文件(与可执行文件格式几乎一样)xxx.o(Windows下)、xxx.obj(Linux下)。

**4）链接**(.o +(其他.o)+ .lib  + .dll到.exe)

将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接：

1、静态链接：.lib     (.a)

函数和数据被编译进一个二进制文件。在使用**静态库(.lib)**的情况下，在编译链接可执行文件时，**链接器从库中复制这些函数和数据**并把它们**和应用程序的其它模块组合起来创建最终的可执行文件。**

空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本；

更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。

运行速度快：但是**静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。**

2、动态链接：.dll    (.so)

动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，**在程序运行时才将它们链接在一起形成一个完整的程序**，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。

共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本；

更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。

性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。

### 6-2 一个程序从开始运行到结束的完整过程

1.一个程序开始运行，首先进行创建进程，操作系统首先为该程序申请一个空白的PCB，然后向这个PCB中填入一些控制和管理进程的相关信息。然后分配所需要的资源（例如载入内存、分配内存等等），把可加载的段内容加载进内存，载入动态链接库等。所有资源就绪后，跳入就绪状态。

2.程序进入就绪状态，等待处理机时间片的到来，进程被调度，获得对应的时间片，就由就绪状态跳转到运行状态。注意，时间片完了之后，进程会自动从运行状态跳到就绪状态，等待下一个时间片的到来。

3.如果程序运行过程中请求某一个资源，例如IO资源，这个时候IO资源正在忙碌，此时程序主动进入阻塞状态，等待IO资源就绪。

4.当IO资源就绪时，会主动由另外一个进程唤醒正在阻塞的进程，这个时候进程转为就绪状态，等待时间片的到来。

5.运行完成之后，进行结束状态，操作系统回收一些资源的工作。

### 7.GDB调试，什么是条件断点（还需要再学）

https://blog.csdn.net/qq_37941471/article/details/81476942

https://blog.csdn.net/niyaozuozuihao/article/details/91802994

1、GDB调试

GDB 是自由软件基金会（Free Software Foundation）的软件工具之一。它的作用是协助程序员找到代码中的错误。如果没有GDB的帮助，程序员要想跟踪代码的执行流程，唯一的办法就是添加大量的语句来产生特定的输出。但这一手段本身就可能会引入新的错误，从而也就无法对那些导致程序崩溃的错误代码进行分析。

GDB的出现减轻了开发人员的负担，他们可以在程序运行的时候单步跟踪自己的代码，或者通过断点暂时中止程序的执行。此外，他们还能够随时察看变量和内存的当前状态，并监视关键的数据结构是如何影响代码运行的。

2、条件断点

条件断点是满足一定条件才会触发的断点，命令：break line-or-function if expr。

例如：(gdb)break 666 if testsize==100

### 8.说一说异步编程的事件循环（还不会）

事件循环就是不停循环等待时间的发生，然后将这个事件的所有处理器，以及他们订阅这个事件的时间顺序依次依次执行。当这个事件的所有处理器都被执行完毕之后，事件循环就会开始继续等待下一个事件的触发，不断往复。当同时并发地处理多个请求时，以上的概念也是正确的，可以这样理解：在单个的线程中，事件处理器是一个一个按顺序执行的。即如果某个事件绑定了两个处理器，那么第二个处理器会在第一个处理器执行完毕后，才开始执行。在这个事件的所有处理器都执行完毕之前，事件循环不会去检查是否有新的事件触发。在单个线程中，一切都是有顺序地一个一个地执行的！

### 9.Linux下怎么得到一个文件的100到200行（还不会）

```shell
sed -n '100,200p' inputfile

awk 'NR>=100&&NR<=200{print}' inputfile

head -200 inputfile|tail -100
```



### 10.请你来说一下linux内核中的Timer 定时器机制（还不会）

1）低精度时钟

Linux 2.6.16之前，内核只支持低精度时钟，内核定时器的工作方式：

1、系统启动后，会读取时钟源设备(RTC, HPET，PIT…)，初始化当前系统时间。

2、内核会根据HZ(系统定时器频率，节拍率)参数值，设置时钟事件设备，启动tick(节拍)中断。HZ表示1秒种产生多少个时钟硬件中断，tick就表示连续两个中断的间隔时间。

3、设置时钟事件设备后，时钟事件设备会定时产生一个tick中断，触发时钟中断处理函数，更新系统时钟,并检测timer wheel，进行超时事件的处理。

在上面工作方式下，Linux 2.6.16 之前，内核软件定时器采用timer wheel多级时间轮的实现机制，维护操作系统的所有定时事件。timer wheel的触发是基于系统tick周期性中断。

所以说这之前，linux只能支持ms级别的时钟，随着时钟源硬件设备的精度提高和软件高精度计时的需求，有了高精度时钟的内核设计。

2）高精度时钟

Linux 2.6.16 ，内核支持了高精度的时钟，内核采用新的定时器hrtimer，其实现逻辑和Linux 2.6.16 之前定时器逻辑区别：

hrtimer采用红黑树进行高精度定时器的管理，而不是时间轮；

高精度时钟定时器不在依赖系统的tick中断，而是基于事件触发。

旧内核的定时器实现依赖于系统定时器硬件定期的tick，基于该tick，内核会扫描timer wheel处理超时事件，会更新jiffies，wall time(墙上时间，现实时间)，process的使用时间等等工作。

新的内核不再会直接支持周期性的tick，新内核定时器框架采用了基于事件触发，而不是以前的周期性触发。新内核实现了hrtimer(high resolution timer)：于事件触发。

hrtimer的工作原理：

通过将高精度时钟硬件的下次中断触发时间设置为红黑树中最早到期的Timer 的时间，时钟到期后从红黑树中得到下一个 Timer 的到期时间，并设置硬件，如此循环反复。

在高精度时钟模式下，操作系统内核仍然需要周期性的tick中断，以便刷新内核的一些任务。hrtimer是基于事件的，不会周期性出发tick中断，所以为了实现周期性的tick中断(dynamic tick)：系统创建了一个模拟 tick 时钟的特殊 hrtimer，将其超时时间设置为一个tick时长，在超时回来后，完成对应的工作，然后再次设置下一个tick的超时时间，以此达到周期性tick中断的需求。

引入了dynamic tick，是为了能够在使用高精度时钟的同时节约能源，这样会产生tickless 情况下，会跳过一些 tick。

新内核对相关的时间硬件设备进行了统一的封装，定义了主要有下面两个结构：

时钟源设备(closk source device)：抽象那些能够提供计时功能的系统硬件，比如 RTC(Real Time Clock)、TSC(Time Stamp Counter)，HPET，ACPI PM-Timer，PIT等。不同时钟源提供的精度不一样，现在pc大都是支持高精度模式(high-resolution mode)也支持低精度模式(low-resolution mode)。

时钟事件设备(clock event device)：系统中可以触发 one-shot（单次）或者周期性中断的设备都可以作为时钟事件设备。

当前内核同时存在新旧timer wheel 和 hrtimer两套timer的实现，内核启动后会进行从低精度模式到高精度时钟模式的切换，hrtimer模拟的tick中断将驱动传统的低精度定时器系统（基于时间轮）和内核进程调度。

## 6.一些小知识

### 1.fflush

在fork进程时，会fork一份输出缓冲区过去。比如：

```c
printf("以下是连接出错日志信息:\n");
fflush(stdout);
const char greetings[] = "\nhost=locahost,port=6379 \n";
write(STDOUT_FILENO, greetings, sizeof(greetings));
fork();
```

即使fork在printf之后，子进程也可能会打印信息。这就需要fflush来冲洗标准输入输出缓冲区，不让它复制到子进程去。所以在多进程中使用标准输入输出一定要小心。

### 2.exit()

```c++
int tea_status;
waitpid(tea_worker_id, &tea_status, 0); //主进程等待tea进程，并获取进程的退出状态
//通过waitpid得到的退出状态其实是经过编码的，你在子进程exit(1)，在这里得到的可不一定是1，也就是tea_status得到的值可能是256。
```

### 3.父子进程通信

- 可以通过exit()来简单的从子进程传递一些进程退出信息到父进程

- 采用共享内存

  - 

  ```c++
  int pageSize = sysconf(_SC_PAGE_ SIZE);//获取一页内存多大，一般都是4K Byte
  void* addr=mmap(NULL,pageSize*1,PROT_READ|PROT_WRITE,MAP_SHARED,0,0);//申请共享内存，得到它的地址
  memcpy(addr,recipes,sizeof(recipes));//recipes里是我们希望共享的数据保存的地址
  Recipe* shared_recipies=addr;//然后从此开始，进程要访问修改recipes时，都去对shared_recipeds操作。这样父子进程都可以看到。（也就是fork出来的子进程对这块儿区域修改，父进程也看得到）
  ```

  

## 7.总结

1.CPU/进程调度算法：先来先服务FCFS、短作业优先SJF、最短剩余时间优先SRTN、高响应优先HRRN、时间片轮转、优先级调度、多级反馈队列

2.内存置换/页面置换算法（把哪个页换出内存）：先进先出FIFO、最佳算法OPT、最近最久未使用LRU、第二次机会、时钟clock、改进时钟。

3.磁盘调度（读写操作时的，访问block的顺序问题）：先来先服务FCFS、短寻道优先SSTF、电梯算法

4.缓存置换算法：类似页面置换，

## 8.待解决

https://www.nowcoder.com/tutorial/93/156e55e0579d4a678e857b34d572c278

1. 一、 请问MySQL的端口号是多少，如何修改这个端口号
4. 二、给你一个类，里面有static，virtual，之类的，来说一说这个类的内存分布
3. 三、请你来说一下awk的使用



别人的操作系统面试题目总结：

https://blog.csdn.net/chasinguu/article/details/99714466