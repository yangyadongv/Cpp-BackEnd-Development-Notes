# 		实验一

- `tar -zxvf hit-oslab-linux-20110823.tar.gz \-C /home/shiyanlou/`
- bochs：虚拟机，用来运行linux-0.11.
  - 系统：oslab/linux-0.11/Image
  - 硬盘：oslab/hdc-0.11.img
- run:运行bochs虚拟机
- 在linux-0.11目录下make all，会生成linux-0.11/Image文件
  - 修改Linux源码后，要重新make all，如果没生效，那么make clean一下，再make all
- oslab/dbg-asm：汇编级调试
- c语言级调试:dbg-c   rungdb
  - ![image-20200414000636492](C:\Users\杨亚东\AppData\Roaming\Typora\typora-user-images\image-20200414000636492.png)
- mount-hdc 挂载脚本。
  - 执行`sudo ./mount-hdc`后，hdc 目录下就是和 0.11 内核一模一样的文件系统了，可以读写任何文件（可能有些文件要用 sudo 才能访问）。
  -  `sudo umount hdc`    卸载这个文件系统。
  - 相对linux-0.11下建立一个新的**.c文件，先sudo ./mount-hdc出来，然后Ubuntu下建立好，在sudo umount hdc回去，这个c文件就保存到Linux-0.11中了。
  - 另外在 Linux 0.11 上产生的文件，如后面实验中产生的 `process.log` 文件，可以按这种方式 “拿到” Ubuntu 下用 python 程序进行处理，当然这个 python 程序在 Linux 0.11 上显然是不好使的，因为 Linux 0.11 上搭建不了 python 解释环境。
- 注意：
  - 注意 1：不要在 0.11 内核运行的时候 mount 镜像文件，否则可能会损坏文件系统。同理，也不要在已经 mount 的时候运行 0.11 内核。
  - 注意 2：在关闭 Bochs 之前，需要先在 0.11 的命令行运行 “sync”，确保所有缓存数据都存盘后，再关闭 Bochs。

# L0

- 操作系统的启动：
  - 就是把操作系统从硬盘读到内存中；
  - 并且setup，即检查硬件信息，对各种硬件设备**初始化**各种硬件对应的用于管理的**数据结构**（mem_init()、trap_init().....)
  - 然后启动shell，等待用户使用
- 接口、系统调用
  - 用户通过接口，间接使用系统调用，来实现硬件访问、使用、管理等功能
- 多进程视图
  - CPU：多线程之间的切换（也就是交替），其实核心就是TCB的切换引发的栈切换。
    - 用户级线程，仅有多个用户栈，没有核心栈。切换就是切不同的用户栈。
    - 核心级线程，每个线程既有用户栈，又有核心栈。切换就是切不同的核心栈，核心栈运行完后可以自动跳回用户栈。
    - 用户栈就是用户程序的函数跳转等等需要保存返回地址的地方。核心栈就是“系统调用”程序的函数跳转等等需要保存返回地址的地方。也就是函数执行到右括号ret以后，下一个指令去哪运行呢？去栈里取地址，那里保存着一下个指令的地址。
  - 内存
- 文件视图
  - 磁盘
  - IO设备

# L2 操作系统的启动bootsect.s

- 图灵机：一个只会做一道菜的厨师。

  - 只会读入数据，做固定的程序
  - 纸带上只有数据

- 通用图灵机：一个能看懂菜谱的厨师。

  - 可以读入纸带上的动作，以实现各种各样的程序
  - 纸带上：设置控制器动作、控制器状态+数据

- 计算机：冯诺依曼的存储程序思想。

  - 存储程序的主要思想:将程序和数据存放到计算机内部的存储器中，计算机在程序的控制下一步一步进行处理
  - 不再需要纸带了，程序存放在了内部存储器中，而不是纸带上
  - 计算机由五大部件组成:输入设备、输出设备、存储器、运算器、控制器
  - ![GxjrD0.png](https://s1.ax1x.com/2020/04/14/GxjrD0.png)
  - 核心思想：取指执行

- bootsect.s详细过程：

- 刚开机时，内存中就有一部分代码的。

  - 开机时指针先指到0xFFFF0处。因为在内存0xFFFF0处，即ROM BIOS映射区，用来检查RAM，键盘，显示器，软硬磁盘等硬件。（BIOS：Basic Input Output System）
  - （引导程序由 BIOS 加载并运行。它活动时，操作系统还不存在，整台计算机的所有资源都由它掌控，而能利用的功能只有 BIOS 中断调用。）
  - 检查完后，没有问题，将从磁盘中的0磁道0扇区处（引导扇区）读入程序（512个Byte）到内存0x7c00处。然后CPU从这里开始执行。
  - 然后从硬盘读入setup4个扇区到内存并执行，然后system模块读入到内存并执行...
  - ![Gzk4HJ.png](https://s1.ax1x.com/2020/04/14/Gzk4HJ.png)

- bootsect.s(引导扇区.汇编)

  - 总结一下boot的工作：读setup，展示logo“loading system"，读system...
  - bottsect.s退出时，要jump到setup所在的位置，交出控制权
  - bootsect.s 能在屏幕上打印一段提示信息“XXX is booting...”，其中 XXX 是你给自己的操作系统起的名字，例如 LZJos、Sunix 等（可以上论坛上秀秀谁的 OS 名字最帅，也可以显示一个特色 logo，以表示自己操作系统的与众不同。）

  - bootsect.s 能完成 setup.s 的载入，并跳转到 setup.s 开始地址执行。而 setup.s 向屏幕输出一行"Now we are in SETUP"。

**书上总结版**

- 这里先总的说明一下Linux 操作系统启动部分的主要执行流程。当PC 的电源打开后，80x86 结构的CPU 将自动进入实模式，**并从内存地址0xFFFF0 开始自动执行程序代码**，这个地址通常是**ROM-BIOS** 中的地址。PC 机的BIOS 将执行某些系统的检测，并在物理地址0 处开始初始化中断向量。此后，它将可启动设备的第一个扇区（磁盘引导扇区，512 字节。其实就是**bootsect.s**）**读入内存**绝对地址0x7C00 处，并跳转到这个地方。启动设备通常是软驱或是硬盘。这里的叙述是非常简单的，但这已经足够理解内核初始化的工作过程了。
- Linux 的最最前面部分是用8086 汇编语言编写的(boot/bootsect.s)，它将由BIOS 读入到内存绝对地址0x7C00(31KB)处，当它被执行时就会把自己移到绝对地址0x90000(576KB)处，并把启动设备中后2kB字节代码(boot/setup.s)读入到内存0x90200 处，而内核的其它部分（system 模块）则被读入到从地址0x10000 开始处，因为当时system 模块的长度不会超过0x80000 字节大小（即512KB），所以它不会覆盖在0x90000 处开始的bootsect 和setup 模块。后面setup 程序将会把system 模块移动到内存起始处，这样system 模块中代码的地址也即等于实际的物理地址，便于对内核代码和数据的操作。

**即：加电就会执行内存中ROM-BIOS代码，这部分代码结束时会加载并执行bootsect.s，即引导扇区。bootsect.s结束时会加载并执行setup.s，setup.s结束时会加载并执行system模块。**

**个人总结bootsect.s的作用：**

**操作系统安装在硬盘上。首先要把操作系统从硬盘读到内存里。**

**这就是bootsect.s干的事：将操作系统读了进来，详细说就是读入setup.s(利用int 13号中断，从硬盘加载到内存），然后显示Logo “system is loading"，然后执行setup.s**



# L3操作系统的启动setup、head、main

接下来讲讲setup.s具体做了什么事。

- **setup 程序的作用主要**是利用ROM BIOS 中断**读取机器系统数据（比如操作系统在获取你的内存是多大，硬盘是多大）**，并将这些数据保存到0x90000 开始的位置（覆盖掉了bootsect 程序所在的地方），所取得的参数和保留的内存位置见下表3–1 所示。这些参数将被内核中相关程序使用，例如字符设备驱动程序集中的ttyio.c 程序等。
- 然后 setup 程序将system 模块从0x10000-0x8ffff（当时认为内核系统模块system 的长度不会超过此值：512KB）整块向下移动到内存绝对地址0x00000 处。接下来加载中断描述符表寄存器(idtr)和全局描述符表寄存器(gdtr)，开启A20 地址线，重新设置两个中断控制芯片8259A，将硬件中断号重新设置为0x20 - 0x2f。最后设置CPU 的控制寄存器CR0（也称机器状态字），**从而进入32 位保护模式运行，并跳转到位于system 模块**最前面部分的head.s 程序继续运行。
  - 实模式和保护模式，区别是对cs:ip的解释不同，实模式是cs左移4位+ip就是地址，32位保护模式是采用gdt实现。

**head.s:system模块最前面的部分**

- head.s 程序在被编译后，会被连接成system模块的最前面开始部分，这也就是为什么称其为头部(head)
  程序的原因。从这里开始，内核完全都是在保护模式下运行了。heads.s 汇编程序与前面的语法格式不同，
  它采用的是AT&T 的汇编语言格式，并且需要使用GNU 的gas 和gld2进行编译连接。因此请注意代码
  中赋值的方向是从左到右。
- head.s完了将调到main.c函数，main.c对各个设备进行初始化。（比如，记录一下，哪些内存被操作系统使用了，哪些是没用的可以分配给用户使用的）

**操作系统启动的整体宏观轮廓**

- bootsect.s将setup读进来;然后跳到setup.s
- setup.s读取系统硬件参数，读入system模块（其实就是head.s+main.c)。最后启动32位保护模式。然后跳到head.s
- head.s初始化了一些gdt表，一些页表，然后跳到main.c
- main.c中一堆init，初始化各种硬件信息，记录下来哪些资源可用，哪些不可用
- 操作系统的启动，总的来讲就两件事：
  - 将操作系统从硬盘读入到内存（读入内存，才能取指执行）
  - 初始化（因为操作系统要管理计算机硬件，需要初始化很多的数据结构来管理这些硬件）

# L4操作系统的接口

## 用户使用计算机三种方式：

- 命令行

  - 命令，一段程序而已。

    - 例子：

    ```c++
    //output.c
    #include<stdio.h>
    int main(int argc,char*argv[])
    {
    	printf("ECHO:%s\n",argv[1]);
    }
    ```

    - 把它 `gcc -o output output.c`以后，output就算是一个命令了
    - 命令行输入`./output"hello"`
    - 输出`ECHO：hello`
    - gcc命令，也不过是一段复杂点的程序而已

  - shell其实也是一段程序而已：即/bin/sh

    - ```c++
      //shell程序主体
      int main(int argc,char*argv[])
      {
          char cmd[20];
          while(1)//shell永不停，不断地等待敲入命令
          {
              scanf("%s",cmd);//用户敲入命令
              if(!fork())
              	exec(cmd);//把命令执行起来
              else
              	wait();
          }
      }
      ```

- 图形按钮

  - 消息机制
  - ![JpkWDS.png](https://s1.ax1x.com/2020/04/14/JpkWDS.png)

- 应用程序

## 系统调用的定义

操作系统提供这样的重要函数，这就是操作系统接口：接口表现为函数调用，又由系统提供，所以称为系统调用。

举例：POSIX：Portable Operating System Interface of Unix

- fork：创建一个进程
- execl：运行一个可执行程序
- pthread_create：创建一个线程
- open：打开一个文件或目录
- EACCES：返回值，表示没有权限
- mode_t st_mode:文件头结构:文件属性

# L5系统调用的实现

- CPU分为内核态和用户态

- 内存分为内核段和用户段

- 通过CPU的“硬件设计”来检查当前程序处于什么态
  - 是由PC指针，即CS:IP，用CS最低两位来表示：0是内核态，3是用户态
  - DPL(GDT表中)>=CPL(CS)才行。即目标的特权级较低（数字大），而当前的特权级高（数字小）。
    - 解释一下，在系统初始化的时候，更具体地说head.s时，会针对内核态的代码和内核态数据建立GDT表。每次跳转或者Mov，都要访问GDT表（全局描述表，在保护模式时，需要使用这个来寻址，从而使用更多内存地址），因为是段寄存器，要通过段进入目标内存。
  
- intel x86，提供了唯一的方法进入内核，就是中断指令。
  - int指令将使CS中的CPL改成0，“进入内核”
  - 这是用户程序发起的调用内核代码的唯一方式
  - 系统调用的核心：
    - 用户程序中包含一段包含int指令的代码
    - 操作系统写中断处理，获得想调程序的编号
    - 操作系统根据编号执行相应代码
  
- 例如：iam函数

  - ```c++
    //iamm.c   用户端的api
    #define __LIBRARY__
    #include <unistd.h>
    #include <string.h>
    #include <errno.h>
    #include <stdio.h>
    _syscall1(int,iam,const char*,name)//函数定义
     //将宏换过来就是
     /*int iam(const char* name){__asm__ volatile ("int $0x80"
            : "=a" (__res)
            : "0" (__NR_iam),"b" (name);}*/
     //在这里引发0x80中断，中断里将跳往_sys_call_table+4*__NR_iam处，这里存储着sys_iam的内核代码
    int main(int argc,char* argv[])
    {
    	
        if(argc>1){// ./iamm "yyd"  argc就=2
    		if(iam(argv[1])<0){//iam(argv[1])就是系统调用，如果返回值<0，说明失败了。具体到本例子中即字符串太长，内核实现返回了-EINVAL
    			printf("SystemCall Exception!\n");
    			return -1;
    			}
        	}
        else{//如果输入参数小于等于1个（包括./iamm)说明输入少了参数
    		printf("Input Exception!\n");
    		return -1;
        }		
        return 0;
    }
    ```

  - ```c++
    //who.c   写在内核里的函数。
    #define __LIBRARY__
    #include <unistd.h>
    #include <errno.h>
    #include <asm/segment.h>
     
     
    char temp[64]={0};//系统内核的内存区域
     
     
    int sys_iam(const char* name)//对应着iam api的内核实现。由中断进入
    {//将字符串name中的内容，存放到系统内核中
       int i=0;
       while(get_fs_byte(name+i)!='\0')//在内核态中从用户态取出数据。get_fs_byte也是内核函数
            i++;
       if(i>23){   
            return -EINVAL;
       } 
       printk("%d\n",i);//内核源码中才能使用的函数
       i=0;
       while((temp[i]=get_fs_byte(name+i))!='\0'){//如果字符串的长度大于23，则表示不能存放到内核中，返回-1，设置errno
    i++;
        }   
        return i;
    }
     
     
    int sys_whoami(char* name,unsigned int size)
    {
        int i=0;
        while (temp[i]!='\0')
    i++;
        if (size<i)
        return -1;
        i=0;
        while(temp[i]!='\0'){
    put_fs_byte(temp[i],(name+i));
    i++;
        }
        return i;
    }
    ```

- 具体地：

  - 用户态下CPL=3，开始执行命令 ./iamm  "yyd"
  - iamm.c文件中的main函数里的内容，就是 iam();
    - _syscall1(int,iam,const char*,name)函数（它其实就是int iam())中，先将eax寄存器置为__NR_iam=72，即第73个系统调用。
  - 然后触发中断0x80（这个中断就是专业的系统调用中断），int 0x80指令查IDT表（中断向量表，由内核初始化）发现DPL=3 （故意设置成3，本来应该是0，为了从中断进入system_call），而CPL = 3（用户态）可以执行。
    - 根据IDT表中的地址，0x80中断将跳转至存放系统调用函数system_call（所有的系统调用都要到这儿来执行）的内存位置。跳到system_call后自动地CPL就是0了（因为处于内核区内存），意味着处于核心态了。（因为0x80中断就是专门系统调用中断，其他中断将跳转至IDT表中的相应其他位置）
  - 在system_call中，根据系统调用号（__NR_iam=72），算出地址call sys_call_table+4*系统调用号，jmp进去。那里就存放着iam相应的内核实现，即sys_iam函数。

- 再比如printf()函数
  - ![JpJ0ht.png](https://s1.ax1x.com/2020/04/14/JpJ0ht.png)
  - IDT（中断描述符表），用于读取中断函数的入口地址。

![JpUvZD.png](https://s1.ax1x.com/2020/04/14/JpUvZD.png)

![Jpdr3n.png](https://s1.ax1x.com/2020/04/14/Jpdr3n.png)

- 执行whoami()时，CPL=3。
- 先把系统调用号放在一个特定的寄存器里，然后int 0x80。int 0x80的DPL故意做成3，为了让程序进来。
- 进入中断后，CPL自动置成0（因为处于内核区内存了），以进入系统调用。//CPL被置成0，就是核心态了
- 进入sys_whoami系统调用。//这一步开始就是核心态了。
- 然后根据系统调用号，查表call_table。再具体地进入往显存write的系统调用。

总结：

- 应用程序调用库函数（API）；
- API 将系统调用号存入 EAX，把函数参数存入其它通用寄存器,然后通过中断调用使系统进入内核态；
- 内核中的中断处理函数根据系统调用号，调用对应的内核函数（系统调用）；
- 系统调用完成相应功能，将返回值存入 EAX，返回到中断处理函数；
- 中断处理函数返回到 API 中；
- API 将 EAX 返回给应用程序。

# L6操作系统的历史

# L8CPU管理直观想法

- 如果只是简单地顺序执行，或者说叫取指令执行，而运行10^6条普通指令，和一条IO指令时间几乎相等。如果我的CPU此时就在此处等待IO，而不去做别的事，那么CPU会有很多很多空闲时间，因为它需要等IO。即CPU利用率很低。
- CPU只运行一个程序的话，效率很低，因为IO操作很费时间，所以要多个程序交替执行（以避免IO等待时间）
- 一个CPU上交替的执行多个程序：并发 （为了提高CPU利用率，不用一直等IO)
  - 或者说叫多进程执行
- 切出去切回来，不仅是切换PC指针这么简单，还要保存现场信息，恢复现场信息（存到PCB里，从PCB里恢复）
- 运行起来的程序和静态的未运行的程序不一样
  - 因为运行的程序需要记录它的切出去的时候的状态，或者说叫运行起来的样子（PCB）
  - 运行起来的程序就叫进程

# L9多进程图像

## 多个进程使用CPU的图像

- 如何使用CPU
  - 让程序执行起来
- 如何充分利用CPU
  - 启动多个程序，交替执行
- 启动了的程序就是进程，所以是**多个进程推进**
  - 操作系统只需要把这些进程**记录**好（PCB）、要按照合理的次序推进（**分配资源、进行调度**）
  - 这就是多进程图像

- 开机后将执行main.c，将用fork()创建第一个进程，即shell或者是windows桌面。
- 然后比如在shell中，输入了ls命令，那么将再创建一个新的进程去执行ls命令。

## 多进程如何组织:PCB+状态+队列

操作系统不仅利用PCB来感知进程，也靠PCB来组织进程。

将PCB放在不同的队列中，不同队列就代表了不同状态，用状态转换来推进进程。

![JmZtTe.png](https://s1.ax1x.com/2020/04/18/JmZtTe.png)

## 多进程如何交替

交替的三个部分：队列操作+调度+切换

```c++
启动磁盘读写;//发生了IO等待
//队列操作
pCur.State='W';//把当前进程的PCB里的状态从运行态变成阻塞态
将pCur放到DiskWaitQueue;//当前进程的PCB加入磁盘等待队列，也就是阻塞队列里的一个
//调度+切换
schedule();//进程切换
```

```c++
schedule()
{
    //调度
    //getNext()就对应了各种进程调度（低级调度）算法
    pNew=getNext(ReadyQueue);//从就绪队列调度一个新的进程
    //切换
    //PCB中记录当时停止时的样子，停在哪里了，还有现场，将那些现场恢复。
    switch_to(pCur,pNew);//将调度来的新进程的PCB，切换到当前执行
    //其实就是把cpu里的各个寄存器里的值，直接保存在pCur对应的PCB里
    //并且把pNew的PCB的值再加载回cpu的寄存器中，包括了PC指针，即当时执行到了哪一行
}
```

## 多进程存在的问题

- 进程1的代码和进程2的代码都在内存里，很可能在执行进程2时，修改了进程1的内存部分。
  - 所以多进程的地址空间要**分离**：内存管理的主要内容
  - 每个进程有自己的映射表。
- 进程间的**合作**：比如生产者消费者问题
  - 需要进程同步：比如上锁

## 如何形成多进程图像

- 读写PCB，OS中最重要的结构，贯穿始终
- 要操作寄存器完成切换（L10，L11，L12）。即进程的切换
- 要写调度程序（L13，L14）
- 要有进程同步与合作（L16，L17）
- 要有地址映射（L20）

# L10用户级线程

## 线程的切换

**实质就是映射表不变而PC指针变。只需要保存用户寄存器的内容，程序计数器，栈指针，不需要模式切换（用户态切到核心态）。**

多线程的例子：网页浏览器

![JnD1bV.png](https://s1.ax1x.com/2020/04/18/JnD1bV.png)

TCB:thread control block

每个线程都有一个自己的栈，即用于记录返回地址的栈。每个线程对应的TCB中记录了这个线程对应的栈的地址（栈顶？）。

```c++
//浏览器的构造
void WebExplorer()
{ 
    char URL[] = “http://cms.hit.edu.cn”;
	char buffer[1000];
	ThreadCreate(..., GetData, URL, buffer);//创建进程
	ThreadCreate(..., Show, buffer); 
}
void GetData(char *URL, char *p){连接URL;下载;Yield();..};//下载数据
void Show(char *p){...};//显示
void ThreadCreate(func,arg1){申请栈;申请TCB;func程序首地址入栈;关联TCB与栈;...}
void Yield()
{
    压入现场;//即将Yield函数的下一句的地址入当前线程栈
    esp放在当前TCB中;//修改后的栈？
    Next();//调度函数
    从下个TCB取出esp;//即用下一个线程的栈覆盖当前cpu的栈
    弹栈切换线程;//其实没有这句，是靠右括号的自动ret完成的
}
//在每个线程中里边会调用Yield()函数进行线程切换。比如下载完文本后Yield一下，从下载线程Yield到了show线程。文字show完了，再Yield回下载线程下载图片，图片下载完后Yield到show线程，图片show完了再Yield回下载线程....
```

```c++
//切换线程时要做的事：仅仅是PC指针跳转，而没有现场的保护工作（指数值寄存器）。
void Yield()
{
	将Yield函数的下一句的地址入当前线程栈。//维护好当前线程的栈
    将cpu的esp=下一个线程的TCB里的esp//即用下一个线程的栈覆盖当前cpu的栈
}//右括号会自动执行从cpu的esp弹栈的操作
```

```c++
//核心:对于两个线程，就是做出两个TCB，两个栈、以及维护好初始栈（切换的初始PC在栈中）
void ThreadCreate(A)
{
    TCB *tcb=malloc();//申请一块儿内存作为TCB
    *stack=malloc();//申请一块儿内存当栈
    *stack=A;//程序的初始地址要放在栈中
    tcb.esp=stack;
}
```

用户级线程和核心级线程不同：用户级线程都执行在用户态，核心级线程执行在核心态。用户级的切换叫Yield，是程序主动切换。核心级的切换叫Schedule，是系统在调度。

# L11内核级线程

线程切换的本质就是切换TCB引发的栈的切换。

- 一个CPU，多核心，就是为线程而生的。多个核共用一套MMU（内存映射）和缓存，一个进程的不同**线程**就可以**并行**处理。但是对于不同进程，就得切换不同的MMU，多核心没有意义。
- 多进程和多用户级线程，都无法发挥CPU多核心的作用。只有多内核级线程，才能发挥CPU多核心的作用。

核心级线程和用户级线程的区别：

- 用户级线程：几个线程几个栈（TCB切换，根据TCB切换来切换用户栈）
- 核心级线程：几个线程几套栈（TCB切换，根据TCB切换来切换一套栈，即用户栈和核心栈）
  - 也就是每个线程都有一个用户栈（执行用户程序时需要的栈，比如记录函数返回等待）和一个核心栈（执行中断程序，运行进行系统调用时的程序，所需要的栈）。一套就是一个用户栈一个核心栈，核心栈与用户栈相互关联。
- 核心级线程的切换是每个线程核心栈之间的切换，每个核心栈会执行完会自动切换到自己对应的用户栈。核心级线程的切换是操作系统控制的，或者说是系统调度的。
- 用户级线程的切换就只是每个线程用户栈的切换，没有对应的核心栈。用户级线程的栈是用户程序自己写好的，是程序主动切换的，与操作系统无关。
- 用户级线程进入系统调用被阻塞后，那么整个进程就阻塞了，该进程的别的线程也无法运行，因为系统将**调度下一个就绪进程**。核心态线程进入系统调用被阻塞后，系统就会调度**下一个就绪线程**，即切换下一个线程的核心栈。

![JKSIQU.png](https://s1.ax1x.com/2020/04/19/JKSIQU.png)

比如浏览器，每开一个标签就是开了一个用户级线程。用户级线程你可以开好多标签页，但是假如是核心级线程，你开了50个标签页，系统就顶不住了。因为要占据太多内存、调度起来也麻烦，会影响其他程序的使用。

用户级线程切换：

- 切换TCB，切换用户栈。

核心级线程切换：

- 线程一执行中，需要系统调用（即主动发生中断），从线程一用户栈切换到线程一核心栈
- 1.线程一的系统调用代码执行中，有可能发生线程切换。（比如write系统调用，发生io操作，需要等待就会让它切换。或者时钟中断，即时间片用完了）  。2.线程切换即将TCB切换，这就是schedule要干的事。TCB切换时，3.也就从线程一的核心栈切换到了线程二的核心栈。
- 线程二的系统调用函数执行完后，可以自动从线程二核心栈切到线程二用户栈，继续回去执行线程二用户代码。

fork()

- 申请内存空间、创建TCB、创建内核栈和用户栈、填写两个栈、关联栈和TCB
- 注意：fork()的子进程拥有自己的TCB，内核栈，但是跟父进程共用用户栈
- 所以if(!fork()){子进程代码}。 子进程和父进程将会返回用户程序的同一个地方（返回同一个地方，是因为内核栈参数是copy的父进程的），区别是，子进程返回到fork()这一行时，返回值是0，所以进入了If。而父进程返回到fork()这一行时，返回值非0，不会进入if。
- 子进程诞生后，是直接运行return返回的，然后接着执行后面的程序，这里注意：子进程是不会执行前面父进程已经执行过的程序了得，因为PCB中记录了当前进程运行到哪里，而子进程又是完全拷贝过来的，所以PCB的程序计数器也是和父进程相同的，所以是从fork()后面的程序继续执行。

例题：

```c++
//给出如下C程序，在linux下使用gcc编译：
#include "stdio.h"
#include "sys/types.h"
#include "unistd.h"
int main()
{
    pid_t pid1;
    pid_t pid2;
    pid1 = fork();
    pid2 = fork();
    printf("pid1:%d, pid2:%d\n", pid1, pid2);

}
```

要求如下：

已知从这个程序执行到这个程序的所有进程结束这个时间段内，没有其它新进程执行。

1、请说出执行这个程序后，将一共运行几个进程。

2、如果其中一个进程的输出结果是“pid1:1001, pid2:1002”，写出其他进程的输出结果（不考虑进程执行顺序）。

答:

1、一共执行了四个进程。（P0, P1, P2, P3）

2、所有输出分别为：

pid1:1001, pid2:1002（题干给的）

pid1:0, pid2:1003

pid1:1001, pid2:0

pid1:0, pid2:0

![J1ObCt.png](https://s1.ax1x.com/2020/04/20/J1ObCt.png)

# L13操作系统那棵树

# L20内存使用和分段

- 程序一般不是整段放在连续内存中。而是分段放在连续内存中，比如分成：主程序代码段、变量集、函数库、动态数组、栈等等。
  - 这样有个好处，比如栈空间不够了，需要加空间，如果是整套内存一起分配的话。我就需要找个更大内存，给栈多分点，然后剩下的其他部分代码段啊变量段啊原样搬过去
  - 而实际上，其它段它们内存是够得，不够的只是栈。所以分段分开放的话，只重新找个大内存，把栈搬过去就好了，其他段不用动，提升效率。
- 每个段都有自己的基址。所以一个进程，会有一套基址，全部放在该进程的PCB中，叫做进程段表LDT。
- GDT表是操作系统的程序段表，LDT是进程的进程段表，每个进程都有自己的LDT，放在对应的PCB中。
- 在运行时（不是编译）修改LDT，即分配基址。假如进程阻塞了，被swap到了硬盘中，再回来继续执行时，也会有新的基址。
- 即每次运行时重定位，也就是分配进程各个段的基址。

# L21 

- 把程序分成多个段，这是编译做的事
- 找一个空闲分区就是内存分区。
  - 一个表记录已分配内存的开始地址，和占用内存大小
  - 一个表记录空闲内存的开始地址，和占用内存大小
- 分段的段对应的是虚拟内存
  - 实际内存是用分页来割的，虚拟内存是采用分区算法。
  - 最先适配（取空闲表的表头内存位置来分配，前提是大小够用，不够就依次往下找）
  - 最优适配（取空闲表中，内存大小与这个段所需要最接近的）
  - 最差适配（取空闲表中，内存大小与这个段所需要最不接近的）

- 操作系统希望内存分页，可以减少碎片，且不用内存紧缩
- 用户希望分段，因为符合编程思维。



- 对于32位系统
- 最多访问2^32=2^10 * 2^10 * 2^10 ^ 2^2=4G个地址
- 所以一个内存地址代表一个Byte，即内存大小是4G Byte
- 一页4K，所以 4G的物理内存可以被分成 4G/4K=1M页（大约100万）
- 一个进程分成好几段，每一段都有自己的base基址，每一段又分成好几页分散存储。每个段又有自己的页表。
  - <img src="https://s1.ax1x.com/2020/04/29/JTURER.png" alt="JTURER.png" style="zoom:67%;" />
  - 比如逻辑地址40，对应物理地址哪里呢？
  - 40 / 4K=0，也就是第逻辑0页。40%4K=40，偏移量40。
  - 注意啊，每个段都有这么个页表。
    - <img src="https://s1.ax1x.com/2020/04/29/JTU4C6.png" alt="JTU4C6.png" style="zoom:50%;" />
  - 然后查页表，逻辑0页，对应页框5，也就是5*4K。
    - 可以理解为，4G内存有1M个页框
  - 实际地址是5*4K+40
  - 注意，实际上都是硬件完成的，这个过程很快。通过简单的左移右移就可以完成换算真实地址的
- 页表就是记录逻辑页与实际页框的对应关系
  - 所以一个段可能占据很多页，那么就要分配很多页，那么就要都记录到页表中。页表项会非常多，也就是页表规模很庞大。
  - 所有的进程占满内存，那么所有的进程的所有的段的所有的页的页表，它们加起来应该刚好是1M项，因为一共有1M页。1M项就对应了各自逻辑页与实际页的关系。实际页有1M个，也就是页框有1M个。
  - 页表项的存储也要占空间的，一般一个页表项是4 Byte，那么1M个页表就是 4MB

- 5步
  - 1.在虚拟内存上为每个段割一块内存（即使用分区算法来割内存）
  - 2.记录好段表，将各个段假装放在虚拟内存上
  - 3.在物理内存上找空闲页
  - 4.记录页表，将虚拟内存与物理内存完成映射
  - 5.通过重定位，使用内存
- 为什么要这样？
  - 因为从用户来看，用户是分段的，符合直观想法
  - 从硬件来看，实际是分页的，提高了利用率

fork的子进程跟父进程相比，都有各自的虚拟内存，但是指向同一块儿物理内存（包括代码啊、变量啊...）。但是子进程呢，对那块儿物理内存是只读的，你要修改的话，操作系统会自动重新给你分配点物理内存来存储数据，不让你修改跟父进程共用的物理内存。

# L26 外设

IO设备都有自己的运算电路，操作系统只要通过CPU向外设发出一些指令（一般就是out指令），将这些指令写到外设的寄存器上，CPU就可以该干嘛干嘛去了。外设通过这个指令自己工作，等它工作完事了，向CPU发出设备中断。

**操作系统对外设要做的3件事**

- 1.向设备控制器的寄存器发出out指令
- 2.为了让out统一，让用户使用起来方便，封装起琐碎的细节，比如向打印机和向显示器的out代码肯定差很多，要形成**统一的接口**，也就是文件视图
  - 不管什么设备都是open,read,write,close，这就是操作系统为用户提供统一的接口
  - 根据设备文件找到控制器的地址、内容格式等待
- 3.进行设备中断的中断处理

<img src="https://s1.ax1x.com/2020/05/04/Y9es74.png" alt="Y9es74.png" style="zoom:67%;" />

<img src="https://s1.ax1x.com/2020/05/04/Y9ecN9.png" alt="Y9ecN9.png" style="zoom:67%;" />

操作系统不管操作什么外设，都是这么几句话。那么怎么知道操作的是什么外设呢？根据open的内容不同，dev里的不同文件对应着不同外设属性数据，会对open write close等指令进行不同的解释，以操作不同的外设。

# L28 磁盘

## 原始使用内存：

磁盘的访问单位是扇区。磁盘是一扇（512Byte），内存是一页（4K Byte）。

扇区大小：512Byte

柱面（cyl，选取哪个磁道，也就是圆环、柱面）、磁头（head，选取哪个盘面）、扇区（sect，圆环上的哪512Byte）、缓存位置（内存位置，即内存与硬盘数据交换）

像这样原始使用磁盘太麻烦了，让操作系统进行抽象封装。

磁盘访问时间=写入控制器的时间（CPU给它发指令写入它的寄存器的时间）+**寻道时间**（移动磁壁，选择柱面或者叫选择磁道的时间）+旋转时间（选择扇区的时间）+传输时间（数据传输的时间）

寻道时间是最主要的时间开销，即移动磁壁的时间，也就是找柱面或者叫找磁道。

## 通过盘块号block读写磁盘（一层抽象）

![Y9N0vF.png](https://s1.ax1x.com/2020/05/04/Y9N0vF.png)

## block也就是一扇，与 C、H、S的对应关系

![Y97Vqe.png](https://s1.ax1x.com/2020/05/04/Y97Vqe.png)

- 编号时从上到下一个圆柱面编完，再往外扩圆
- 知道C、H、S怎么算第block数
  - 在这个图中，一个圈也就是一个磁道7扇（sectors=7），4个盘也就是8个面（heads=8），所以是`block号=C*(Heads*Sectors)+H*Sectors+S`
  - 举例：第3号柱面（C=3），第2个磁头（H=2），第5扇（S=5）对应的block编号是多少呢？
  - `block编号=3*（8*7）+2*7+5=187`
- 逆运算，知道block怎么反算具体的C、H、S呢？
  - S=block%Sectors=block%7
  - 然后temp=block/Secots，H=temp%Heads
  - 然后C=temp/Heads
- 为什么要用block呢，这里一个block是一个扇区。但是也**可以让一个block是好多个连续扇区**。也就是block代替扇区成了分配空间的最小单位了。1个block占用的扇区数增大，我可以一次性读取或者写入更多的数据，时间变快，但是同时呢空间浪费也增大了。
- linux-0.11里一个block是2个sect
- 硬盘虽然是个圆柱，通过block编号以后，可以当做一个非常长的数组。

## 多个进程通过队列使用磁盘（第二层抽象）

![YCpQWF.png](https://s1.ax1x.com/2020/05/04/YCpQWF.png)

磁盘调度的目标：平均访问延迟小，寻道时间是主要矛盾

调度算法调整的是请求队列的顺序。

**1.FCFS：就按队列一个一个来，缺点：磁头在长途奔袭，时间开销很大**

![YC9Z1e.png](https://s1.ax1x.com/2020/05/04/YC9Z1e.png)

**2.SSTF（短寻道优先）**

就近处理，把就近的任务顺带完成了。缺点：在读写频繁时，会发生局部（磁道离得近）内来回处理，而远处（磁道离得远）的请求呢不会处理，造成饥饿

![YC9mXd.png](https://s1.ax1x.com/2020/05/04/YC9mXd.png)

**3.SCAN（扫描调度，电梯调度）**

SSTF+直接移到另一端：

![YCCIZn.png](https://s1.ax1x.com/2020/05/04/YCCIZn.png)



1.进程根据文件得到盘块号（block），算出对应的扇区号(sector)

2.用扇区号make_req即作出请求，用电梯算法add_request，即加入请求队列

3.该进程sleep_on，等待磁盘去移动磁壁，或者说还轮不到你，前边还有更急的事要做。

4.磁盘就绪后，发出磁盘中断

5.磁盘中断里，根据那个进程的请求，算出cyl,head,sector，然后发出out指令。简言之，就是该处理这个进程的请求了。可能是从硬盘往内存里读了点数据。然后唤醒该sleep进程。把它从请求队列删除。进程唤醒以后，一看哦我要的数据已经从硬盘读到内存了，可以继续往下运行了。

# L29 生磁盘到文件

**1.怎么修改文件内容**

我要修改test.c文件的第200-212个字符，已知它存放在第599盘块上。怎么做呢？

首先，发出读第599盘块操作，在电梯队列里边等调度，然后599盘块的内容就从磁盘到内存了。然后修改内存里的值，修改第200-212个字符。然后再发出写第599盘块操作，扔到电梯队列里边，然后这块儿修改后的内容就又写回硬盘了。

**2.怎么知道文件存在哪个盘块呢？**（假如是顺序结构，顺序占用盘块）

通过FCB，文件控制块。里边记录了，文件名，起始块，占用块数。

比如一个FCB是这样的： 						test.c        6                3

我要修改test.c文件的第200-212个字符。怎么算它在哪个盘块呢？

比如一个盘块只能存100个字符，所以 200/100=2，也就是之前的200字符已经占了两个盘块（假如是连续结构，占用的是连续盘块）。所以实际存在6(起始块)+200/100=8，也就是200-212字符存在第8个盘块上。

inode其实就是FCB类似物

**3.很显然连续占用盘块不合理，因为可能没有那么多的连续区域，怎么解决？**

索引结构。FCB==inode

- FCB中只告诉你索引表放在哪个磁盘块儿中。也就是说要读文件，先根据FCB去硬盘把该文件对应的索引表（里边会告诉你文件分散放在哪里了）读出来，然后根据索引表具体去读文件。
- 也就是说FCB里存的是指针，指向了数据盘块的一块，具体内容去数据盘块找。

# L31目录

inode就是FCB

要解决的问题：给我一个路径名，就可以找到该文件的FCB



![Y19yjS.png](https://s1.ax1x.com/2020/05/09/Y19yjS.png)

- 盘块位图：是一个跟block数等大的数组，用来表示哪些block是空闲的，用来指导分配block
- inode位图：是一个跟上限inode（所有的inode在磁盘同一个连续的block区域）数等大的数组，用来表示哪些inode区域是空闲的，用来指导新建inode
- 超级块：记录两个位图有多大等信息（mount装载操作就是要读这个超级块）
- 引导块：引导扇区。操作系统启动需要的

![Y1Pseg.png](https://s1.ax1x.com/2020/05/09/Y1Pseg.png)

也就是说FCB里存的是指针，指向了数据盘块的一块，具体内容去数据盘块找。



读写磁盘整个故事：



1. 给你一个路径名，根据目录树，一层一层获取inode来解析
2. 找到文件对应的inode（FCB）：（这里边存了这个文件到底在磁盘哪个block上）
3. 根据inode找到盘块号
4. 根据盘块号，往电梯队列里放
5. 然后电梯调度，发出out指令，发在磁盘控制器上
6. 根据盘块号算出C、H、S，磁盘控制器控制马达，电生磁磁生电形成数据。

输出到显示器的整个故事：

磁盘是在inode找盘块号，显示器就是在inode找设备号。磁盘out指令发在磁盘控制器，显示器就是out指令控制其他东西。整个流程类似。