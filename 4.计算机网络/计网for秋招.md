# 计网for秋招

## 1.https详解

参考 

https://zhuanlan.zhihu.com/p/27395037

https://zhuanlan.zhihu.com/p/43789231

### 1.https协议

- HTTP 协议（HyperText Transfer Protocol，超文本传输协议）：是客户端浏览器或其他程序与Web服务器之间的应用层通信协议 。
- HTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：可以理解为HTTP+SSL/TLS， 即 HTTP 下加入 SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL，用于安全的 HTTP 数据传输。
- ![image-20210104173022713](https://i.loli.net/2021/01/04/fIzEqgKZGv5np8S.png)
- HTTPS 相比 HTTP 多了一层 SSL/TLS
  - 其实SSL/TLS属于会话层
  - SSL（Secure Socket Layer，安全套接字层）：1994年为 Netscape 所研发，SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。
  - TLS（Transport Layer Security，传输层安全）：其前身是 SSL，它最初的几个版本（SSL 1.0、SSL 2.0、SSL 3.0）由网景公司开发，1999年从 3.1 开始被 IETF 标准化并改名，发展至今已经有 TLS 1.0、TLS 1.1、TLS 1.2 三个版本。SSL3.0和TLS1.0由于存在安全漏洞，已经很少被使用到。TLS 1.3 改动会比较大，目前还在草案阶段，目前使用最广泛的是TLS 1.1、TLS 1.2。
  - 现在一般都是用TLSv1 TLSv1.1 TLSv1.2。**TLS可以视为SSL的进阶版。**

### 2.为什么http被淘汰了

HTTP请求过程中，客户端与服务器之间没有任何身份确认的过程，数据全部明文传输，“裸奔”在互联网上，所以很容易遭到黑客的攻击。

可以看到，客户端发出的请求很容易被黑客截获，如果此时**黑客冒充服务器，则其可返回任意信息给客户端，而不被客户端察觉**，所以我们经常会听到一词“劫持”，即访问的网站被假的冒充了，客户端却没法察觉。

![img](https://pic4.zhimg.com/80/v2-831635f04f3732e866af0ec6ce1040e7_720w.png)

所以 HTTP 传输面临的风险有：

（1） 窃听风险：黑客可以获知通信内容。

（2） 篡改风险：黑客可以修改通信内容。

（3） 冒充风险：黑客可以冒充他人身份参与通信。

### 3.几个有关加密的概念

- 1.对称加密
  - 加密和解密都是使用的同一个密钥。
  - 例如：DES、AES-GCM、ChaCha20-Poly1305等
- 2.非对称加密
  - 公钥加密，对应私钥可以解密。私钥加密，对应公钥可以解密。
  - 公钥和算法都是公开的，私钥是保密的。
  - 非对称加密算法性能较低，但是安全性超强，由于其加密特性，非对称加密算法能加密的数据长度也是有限的。
  - 例如：RSA、DSA、ECDSA、 DH、ECDHE
- 3.哈希算法
  - 将任意长度的信息转换为较短的固定长度的值，通常其长度要比信息小得多，且算法不可逆。
  - 例如：MD5、SHA-1、SHA-2、SHA-256 等
- 4.数字签名
  - 签名就是在信息的后面再加上一段内容（信息经过hash后的值），可以证明信息没有被修改过。
    - 即**签名就是明文信息的hash结果，或者说签名就是hash值**
  - 这个签名（hash值）一般要经过公钥加密再和明文信息一起传输，以保证这个签名（hash值）不被修改。

### 4.http到https的演化过程

#### 4.1 使用对称加密：不安全

- 不可行，因为秘钥也要在网上传输，被人截获了就不安全了。
- 如果你说你不在网上传，那每一个服务器就要跟每一个客户端维持一个不同的对称秘钥并牢牢死记，这显然不可能。
  - 这么多用户呢，服务器跟每个客户端都维持一个不同的对称秘钥，不现实。
  - 你说你跟每个用户端用一样的秘钥，服务器不就只用留存一份了吗。那服务器跟每个客户端的加密方式都一样，黑客也可以获得这个对称秘钥，还是不安全。

#### 4.2使用非对称加密，仅服务器有一对公钥（S_pub）私钥（S_pri）：不安全

- 首先服务器把公钥（S_pub）给客户端
- 上行数据：客户端使用该公钥（S_pub）来加密数据，发送给服务器，服务器使用私钥（S_pri）来解密
  - 这个从客户端到服务端的上行数据是安全的，因为即使黑客截获了数据，它没有服务器私钥（S_pri）解不开密码。
- 下行数据：服务器使用私钥（S_pri）来加密数据，发送给客户端，客户端使用公钥（S_pub）来解密
  - 问题来了，服务器发给客户端的这个加密数据，要求使用公钥（S_pub）来解密。公钥可不是什么稀罕货，黑客也可以跟服务器索取，所以，黑客可以解密这个下行数据。不安全
- 总结：
  - 从客户端到服务端的**上行数据是安全的**
  - 从服务端到客户端的**下行数据不安全**

#### 4.3双方都使用非对称加密，即服务器公钥（S_pub）私钥（S_pri），客户端公钥（C_pub）私钥（C_pri）：安全，但是效率低

- 服务器把公钥（S_pub）给客户端，客户端把公钥（C_pub）给服务器
- 上行数据：客户端使用该公钥（S_pub）来加密数据，发送给服务器，服务器使用私钥（S_pri）来解密
  - 即使黑客截获了数据，它没有服务器私钥（S_pri）解不开密码。
- 下行数据：服务器使用公钥（C_pub）来加密数据，发送给客户端，客户端使用私钥（C_pri）来解密
  - 即使黑客截获了数据，它没有客户端私钥（C_pri）解不开密码。
- 总结：
  - 这个方法确实可以保证安全，但是非对称加密的加密和解密是效率极低的。

#### 4.4非对称加密+对称加密，即服务器公钥（S_pub）私钥（S_pri）+对称加密：近乎接近答案了，就差一个中间人攻击没解决

既然非对称加密耗时，非对称加密+对称加密结合可以吗？而且得尽量减少非对称加密的次数。当然是可以的，而且非对称加密、解密各只需用一次即可。
请看一下这个过程：

1. 某网站拥有用于非对称加密的公钥（S_pub）、私钥（S_pri）。
2. 浏览器向网站服务器请求，服务器把公钥（S_pub）明文给传输浏览器。
3. 浏览器随机生成一个用于对称加密的密钥X，用公钥（S_pub）加密后传给服务器。
4. 服务器拿到后用私钥（S_pri）解密得到对称密钥X。
5. 这样双方就都拥有对称密钥X了，且别人无法知道它。之后双方所有数据都用对称密钥X加密解密。

#### 4.5 如果没有CA认证，那就会发生中间人攻击！

中间人的确无法得到浏览器生成的对称密钥X，这个密钥本身被公钥（S_pub）加密了，只有服务器才有私钥（S_pri）解开拿到它呀！然而中间人却完全不需要拿到密钥（S_pri）就能干坏事了。请看：

1. 某网站（服务器）拥有用于非对称加密的公钥（S_pub）、私钥（S_pri）。
2. 浏览器向网站服务器请求，服务器把公钥（S_pub）明文给传输浏览器。
3. **中间人劫持到公钥（S_pub），保存下来，把数据包中的公钥（S_pub）替换成自己伪造的公钥（M_pub）（它当然也拥有公钥（M_pub）对应的私钥（M_pri））**。
4. 浏览器随机生成一个用于对称加密的密钥X，用**公钥（M_pub）**（浏览器不知道公钥被替换了）加密后传给服务器。
5. **中间人劫持后用私钥（M_pri）解密得到密钥X，再用公钥（S_pub）加密后传给服务器**。
6. 服务器拿到后用私钥（S_pri）解密得到密钥X。

![image-20210104205347951](https://i.loli.net/2021/01/04/dGzJI8eLf6l1TBp.png)

这样在双方都不会发现异常的情况下，中间人得到了对称密钥X。**根本原因是客户端无法确认自己收到的公钥是不是网站S的，即给了客户端一个M_pub，客户端也信了，以为它就是S_pub**。

#### 4.6 数字证书（是CA颁发给网站的，网站申请时CA给了网站一个数字证书和一个私钥）

- 以后服务器不再给客户端返回公钥S_pub了，而是返回服务器的数字证书。
- 网站在使用HTTPS前，需要向“**CA机构**”申请颁发一份**数字证书**，**数字证书里有证书持有者（域名）、证书持有者的公钥、证书过期时间、摘要算法、CA证书数字签名等信息**，服务器把证书传输给浏览器，浏览器从证书里取公钥就行了，证书就如身份证一样，可以证明“该公钥对应该网站”。

#### 4.7传数字证书为什么比直接传公钥安全（因为有CA的数字签名）

##### 4.7.1数字签名

![image-20210104212257805](https://i.loli.net/2021/01/04/pcgOLy9QIFlHY15.png)

##### 4.7.2数字签名的制作过程

- 1.首先CA有自己的非对称秘钥即CA私钥和CA公钥
- 2.CA对证书明文信息进行hash
- 3.对hash后的值用CA私钥进行加密，就得到了CA证书数字签名
- 4.将 【证书明文+CA证书数字签名】一起作为数字证书，颁发给网站。（当然网站的私钥CA也得单独发给网站）
- 5.此时网站就有 一个数字证书(pem)和一个自己的私钥（key）
  - 客服端发起请求时，网站不再是把公钥给客户端了，而是把数字证书给客户端。

那浏览器拿到服务器传来的数字证书后，如何验证它是不是真的？（有没有被篡改、掉包）

##### 4.7.3浏览器验证过程：（浏览器对CA证书的验证过程）

- 1.浏览器收到服务器传来的数字证书，可以分别拆解得到【证书明文+CA证书数字签名】
- 2.用CA机构的公钥对CA证书数字签名解密（由于是浏览器信任的机构，所以浏览器一定有CA公钥）。得到一个摘要（签名）
- 3.用证书里说明的hash算法对证书明文进行hash得到另一个摘要（签名）。
- 4.比较这两个摘要（签名）是否相等。
  - 相等，则证书可信。
  - 不相等，则可能是证书被篡改了。

##### 4.7.4 中间人有可能篡改该证书吗？（篡改后，会显示证书失效）

假设中间人篡改了证书明文的原文，由于他没有CA机构的私钥，所以无法得到此时加密后签名，无法相应地篡改签名。浏览器收到该证书后会发现证书明文和签名解密后的值不一致，则说明证书已被篡改，证书不可信，从而终止向服务器传输信息，防止信息泄露给中间人。

##### 4.7.5中间人有可能把证书调包吗？（调包后，会显示你要访问的网址跟证书不匹配）

- 假设中间人M也拿到了CA机构认证的证书，它想搞垮网站S，想劫持网站S的信息。于是它成为中间人拦截到了S传给浏览器C的证书，然后替换成自己的证书，传给浏览器。但是因为**证书里包含了网站S的信息，包括域名，浏览器把证书里的域名与自己请求的域名比对一下就知道有没有被掉包了。**
- 也就是说，你以前把M的公钥M_pub给客户端，它可能不觉得有问题。现在规则变了，我们传的都是证书。M要么没有证书，无法提供给C。要么M有个合法证书，你提供给C了，C一看你这证书里写的网站跟我访问的网站，不一致啊，浏览器自然会报警。
  - ![image-20210104213318348](https://i.loli.net/2021/01/04/mCHVSTuxNUA4Zhb.png)
  - 这就是，我要访问S：39.105.65.94，结果它出示的证书写的是M：yangyadong.site。
  - 很显然，这不是我要访问的S：39.105.65.94，我被yangyadong.site这个中间人给拦截了。
  - （其实是因为直接ip访问，我的服务器没有这个ip的证书，我的服务器只有yangyadong.site的证书。不过也可以假装为被中间人拦截的例子来学习）

##### 4.7.6为什么制作数字签名时需要hash一次？（性能问题，hash后位数少，再非对称加密解密比较快）

我初学HTTPS的时候就有这个问题，似乎以上过程中hash有点多余，把hash过程去掉也能保证证书没有被篡改。
最显然的是性能问题，前面我们已经说了非对称加密效率较差，证书信息一般较长，比较耗时。而hash后得到的是固定长度的信息（比如用md5算法hash后可以得到固定的128位的值），这样加密解密就会快很多。
当然还有安全上的原因，这部分内容相对深一些，感兴趣的可以看这篇解答：[crypto.stackexchange.com/a/12780](https://link.juejin.im/?target=https%3A%2F%2Fcrypto.stackexchange.com%2Fa%2F12780)

##### 4.7.7怎么证明CA机构的公钥是可信的？

你们可能会发现上文中说到CA机构的公钥，我几乎一笔带过，“浏览器保有它的公钥”，这是个什么保有法？怎么证明这个公钥是否可信？
让我们回想一下数字证书到底是干啥的？没错，为了证明某公钥是可信的，即“该公钥是否对应该网站/机构等”，那这个CA机构的公钥是不是也可以用数字证书来证明？没错，**操作系统、浏览器本身会预装一些它们信任的根证书，如果其中有该CA机构的根证书，那就可以拿到它对应的可信公钥了。**
实际上证书之间的认证也可以不止一层，可以A信任B，B信任C，以此类推，我们把它叫做`信任链`或`数字证书链`，也就是一连串的数字证书，由根证书为起点，透过层层信任，使终端实体证书的持有者可以获得转授的信任，以证明身份。
另外，不知你们是否遇到过网站访问不了、**提示要安装证书的情况？这里安装的就是根证书。说明浏览器不认给这个网站颁发证书的机构，那么没有该机构的根证书，你就得手动下载安装（风险自己承担）**。安装该机构的根证书后，你就有了它的公钥，就可以用它验证服务器发来的证书是否可信了。

- ![image-20210104215941166](https://i.loli.net/2021/01/04/dRlHp5M7FAQUGIT.png)
- ![image-20210104215930102](https://i.loli.net/2021/01/04/oqtZYvW8JQaPCsI.png)
- ![image-20210104215916877](https://i.loli.net/2021/01/04/Wg9uxKrFsAE2HwY.png)

### 5.HTTPS必须在每次请求中都要先在SSL/TLS层进行握手传输密钥吗？

- 显然每次请求都经历一次密钥传输过程非常耗时，那怎么达到只传输一次呢？用session就行。
  服务器会为每个浏览器（或客户端软件）维护一个session ID，在TLS握手阶段（这可不是TCP的握手）传给浏览器，浏览器生成好密钥传给服务器后，服务器会把该密钥存到相应的session ID下，之后浏览器每次请求都会携带session ID，服务器会根据session ID找到相应的密钥并进行解密加密操作，这样就不必要每次重新制作、传输对称密钥了！
- 即把对称秘钥存了下来？

### 6.以上的总结

可以看下这张图，梳理一下整个流程（SSL、TSL握手有一些区别，不同版本间也有区别，不过大致过程就是这样）：

![image-20210104220305208](https://i.loli.net/2021/01/04/ZPhrASGYmDbT8Mk.png)

### 7.细解TLS握手

![image-20210104221508613](https://i.loli.net/2021/01/04/T1CxgU3IQnFHG8e.png)

#### 1.Client Hello.

客户端通过发送Client Hello消息给服务器初始化Session连接。

- Client Hello 消息包含以下字段：

  - SSL/TLS 版本号。version 2 表示的是SSL 2.0，version 3 表示的是SSL 3.0，version 3.1表示的是TLS 1.0。
  - 随机数Random_C。一共32个字节。前面4个字节是当前时间戳，后面28个字节是一个随机数。后面协商对称加密的Session Key会用到。
  - Session ID。如果是之前已经存在的连接重连，那么Session ID会是一串数字，否则是None。
  - Cipher Suite，**加密套件**。支持的加密组件列表。例如TLS_RSA_WITH_DES_CBC_SHA, TLS 是**TLS协议版本**，TLS表示TLS1.0，RSA是**非对称密钥交换算法**，DES_CBC是**对称加密算法**，SHA是**摘要的hash算法**。
  - hash压缩算法。表示建议选用的是哪种hash压缩算法。
    - 一般写个None。因为加密套件里写了？

- 示例

  - ```
    ClientVersion 3,1
    ClientRandom[32]
    SessionID: None (new session)
    Suggested Cipher Suites:
       TLS_RSA_WITH_3DES_EDE_CBC_SHA
       TLS_RSA_WITH_DES_CBC_SHA
    Suggested Compression Algorithm: NONE
    ```

#### 2.Server Hello.及以下

服务器收到客户端的Client Hello 消息会响应一个Server Hello 消息，

- **Server Hello** 消息包括以下字段

  - SSL/TLS 版本，客户端和服务器都支持的SSL/TLS最高版本。
  - 随机数Random_S，一共32个字节，前面4个字节是当前时间戳，后面28个字节是一个随机数。后面协商对称加密的Session Key会用到。
  - Session ID，这里会有三种情况。1.产生一个新的Session ID，表示没有找到之前的Session ID或者之前没有这个Session ID。2. 返回客户端带上的之前的Session ID。（断链重连）3.Null，服务器没有办法产生新的Session ID。
  - Cipher Suite，加密套件，服务器从刚才Client Hello消息的Cipher Suite加密列表中选中的加密组件。
  - hash压缩算法，表示选中的是哪种hash压缩算法。

- 示例

  - ```
    Version 3,1
    ServerRandom[32]
    SessionID: bd608869f0c629767ea7e3ebf7a63bdcffb0ef58b1b941e6b0c044acb6820a77
    Use Cipher Suite:
    TLS_RSA_WITH_3DES_EDE_CBC_SHA
    Compression Algorithm: NONE
    ```



服务器发完Sever Hello 后还会发送下面几条消息：

- **Server Certificate**.服务器发给客户端的证书，包含公钥。客户端后面会用该密钥加密premaster secret。客户端也会校验证书的合法性，比如证书包含的域名是否就是客户端正在访问的域名。
- **Server Key Exchange.**[可选]当服务器的证书不包含公钥时，客户端会用它来加密后面的Client Key Exchange消息。
- **Client Certificate Request.**[可选]用于服务器需要验证客户端身份的情况，例如银行系统通常用U盾来证明客户端的身份。
- **Server Hello Done.**表示Server已经发送消息完毕并且在登陆客户端回复。

#### 3.客户端紧接着响应给服务器的消息：Client Certificate.及以下

- **Client Certificate.**[可选]客户端证书，包括客户端的公钥。响应上面的Client Certificate Request。
- **Client Key Exchange.**该消息**包括pre_master secret**，TLS的版本号，再次带上版本号是因为之前的版本号是明文传输的，攻击者可能会恶意修改为较低的版本号，从而降低连接的安全系数方便发起攻击。该消息字段会用公钥S.pub加密。现在一共有Random_C,Random_S, pre_master secret三个随机数，客户端和服务器端会用相同的算法，用这三个随机数作为参数，从而计算得到另外的一个随机数，即后面对称加密的密钥Session Key。
- **Certificate Verify.**[可选]该消息只针对有Client Certificate的情况。会计算出该消息字段的HASH，然后用客户端的私钥加密该HASH作为签名。服务器端会使用Client Certificate消息中得到的客户端公钥解密并验证这条消息的合法性。
- **Change Cipher Suite.**该消息通知服务器接下来的Client Finish消息将会用刚才协商的对称密钥Session Key来加密。
- **Client Finished.**该消息会列举客户端上面用到的所有加密字段，并且算出他们的HASH值，然后用对称秘钥Session Key加密。

#### 4.服务器在握手阶段最后回应给客户端的消息：**Change Cipher Suite Message.**及以下

- **Change Cipher Suite Message.**该消息通知客户端接下来的消息会用Session Key来加密。
- **Sever Finished Message.** 对整个协商阶段用到的字段算一个HASH，然后用Session Key加密。

### 8.我认为详略得当的一个版本

![image-20210105112129877](https://i.loli.net/2021/01/05/qzgt6CWAoxORfj4.png)

### 9.总结

- HTTPS必须在每次请求中都要先在SSL/TLS层进行握手传输对称密钥吗？

  - 显然每次请求都经历一次密钥传输过程非常耗时，那怎么达到只传输一次呢？用session就行。
    服务器会为每个浏览器（或客户端软件）维护一个session ID，在TLS握手阶段（这可不是TCP的握手）传给浏览器，浏览器生成好密钥传给服务器后，服务器会把该密钥存到相应的session ID下，之后浏览器每次请求都会携带session ID，服务器会根据session ID找到相应的密钥并进行解密加密操作，这样就不必要每次重新制作、传输对称密钥了！
  - 即服务器把对称秘钥保存了下来。以后连接时客户端直接使用对称秘钥加密数据传输即可。

- SSL/TLS的握手的目的

  - 目的就是为了安全地传输对称秘钥。以后服务器和客户端的通信都是用这个对称秘钥加密的。
  - 这其中当然需要对网站证书进行验证，他的证书都不可靠，跟他通信肯定不可靠。

- 为什么不直接使用对称加密

  - 对称秘钥不敢在网上直接传

- 为什么不直接使用非对称加密

  - 只有服务器有公钥S.pub和私钥S.pri，首先客户端请求到公钥S.pub。
  - 这样只能保证上行数据安全，即客户端使用公钥S.pub加密数据，服务器使用私钥S.pri解密
  - 下行数据危险，因为服务器使用私钥S.pri加密，客户端使用公钥S.pub解密，黑客也可以拿到公钥S.pub来解密

- 为什么不两边都用非对称加密

  - 这样确实可以保证安全
  - 上行：客户端使用服务器公钥S.pub加密数据，服务器使用私钥S.pri解密
  - 下行：服务器使用公钥C.pub加密数据，客户端使用私钥C.pri解密
  - 缺点：纯非对称加密加密和解密数据的效率非常低。不适合在网上传输大规模内容。

- 为什么不直接使用非对称+对称

  - 即**服务器传给客户端公钥S.pub**，然后客户端生成对称秘钥X，使用S.pub传给服务器，服务器解密出这个对称秘钥X
  - 以后都用对称加密来传数据
  - 问题：中间人攻击！详见上文。

- 中间人攻击的解决途径

  - 可能遭遇中间人攻击的本质：客户端无法验证拿到的公钥是真的网站的S.pub，还是中间人的M.pub
  - 解决途径：以后服务器不传公钥了，改成传证书，证书是由CA颁发的，没法伪造

- 现行方案简言之：

  - 服务器传给客户端证书，客户端验证证书没问题，并取出公钥S.pub，然后然后客户端生成对称秘钥X，使用S.pub传给服务器，服务器解密出这个对称秘钥X
  - 以后都用对称加密来传数据
  - 备注：这是简单理解！实际上比这复杂的多。

- 现行方案

  - 服务器向CA申请证书：详细流程参看

    - ##### 另一本笔记的4.7.2数字签名的制作过程

      - 1.网站自己生成一对非对称秘钥，公钥S.pub私钥S.pri
      - 2.CA肯定也有自己的非对称秘钥即CA公钥CA.pub和CA私钥CA.pri
      - 3.CA对证书明文信息【证书明文包括：证书持有者(域名)、证书持有者的公钥S.pub、证书过期时间、摘要算法等信息】进行hash
      - 4.对hash后的值用CA私钥CA.pri进行加密，就得到了CA证书数字签名
      - 5.将 【证书明文+CA证书数字签名】一起作为数字证书，颁发给网站。
      - 6.此时网站就有 一个数字证书(pem文件)和一个自己的私钥（S.pri即key文件）
        - 客服端发起请求时，网站不再是把公钥给客户端了，而是把数字证书给客户端。

  - 客户端验证证书是否有效：详细流程参看：

    - ##### 另一本笔记的4.7.3浏览器验证过程：（浏览器对CA证书的验证过程）

      - 1.浏览器收到服务器传来的数字证书，可以分别拆解得到【证书明文+CA证书数字签名】
      - 2.用CA机构的公钥CA.pub对CA证书数字签名解密（由于是浏览器信任的机构，所以浏览器一定有CA公钥）。得到一个摘要（签名）
      - 3.用证书里说明的hash算法对证书明文进行hash得到另一个摘要（签名）。
      - 4.比较这两个摘要（签名）是否相等。
        - 相等，则证书可信。
        - 不相等，则可能是证书被篡改了。

  - SSL/TLS握手

    - 本质上就上在 验证服务器证书是否有效、有效后通过各种措施，来安全地实现双方达成对称秘钥的一致。
    - 握手完了，以后数据都用对称秘钥加密传输。除了这个服务器和这个客户端，其他人谁也得不到这个对称秘钥。
    - 详细流程参见
      - 8.我认为详略得当的一个版本
      - 7.细解TLS握手
      - 7和8其实是一样的，只是两个总结的详略侧重点不同。

## 2.TCP详解

### 2.1TCP可靠传输理论（一个发送端，一个接收端，如何实现数据可靠传输）

停止等待（包含简易确认机制和简易超时重传机制）、连续ARQ、滑动窗口协议、超时重传、选择确认（其实选择确认并不是可靠传输的部分，而仅仅是提升传输效率的手段）。

#### 停止等待协议（自动重传请求ARQ）

- 停止等待协议包含确认应答和超时重传机制。
- ARQ（Automactic Repeat Request），意思是重传的请求是自动进行的（超时以后就自动重传，即超过一定时间，没收到确认回复，就重传那个分组），接收方不需要请求发送方重传某个出错的分组。
- 总结：
  - 停止等待协议能够在不可靠的传输网络上实现可靠的通信。每发送完一个分组，就停止发送，等待对方的确认。在收到确认后再发送下一个分组，分组需要进行编号（多少字节为一组，然后一组一组的发）。
  - 超时重传是指只要超过了一段时间仍没有收到确认，就重传前面发送过的分组（认为刚才发送的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求（ARQ）
  - 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认

#### 连续ARQ协议（改进的停止等待协议，每次发一个窗口的分组，而不是只发一个分组了）

- 普通的停止等待协议是，发一个分组，就等那个分组的确认
- 连续ARQ协议是，发一个窗口的分组（一个窗口可能0组，可能1组，也可能很多组），然后等待确认
- 接收方都会使用累计确认的方式，即在收到好几个分组后，对按序到达的最后一个分组发送确认，这就表示：到这个分组为止的所有分组都已正确收到了。
- 总结：
  - 连续ARQ协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组都可连续发送出去，而不需要等待对方的确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已正确收到了。

#### 滑动窗口协议（发送窗口如何移动）

- 其实TCP通信时双向的，客户端既有发送窗口也有接收窗口，服务器也是既有发送窗口也有接收窗口。出于简单考虑，比如仅考虑服务器S给客服端C传送数据，服务器S是发送方，那么只考虑它的发送窗口。客户端C是接收方，那么只考虑它的接收窗口。
- TCP首部中的窗口字段，指出了现在允许对方发送的数据量。窗口值是经常在动态变化着的。
- TCP使用滑动窗口机制。发送窗口里面的序号表示允许发送的序号。发送窗口后沿的后面部分（小序号方向）表示发送且已收到了确认，而发送窗口前沿的前面部分（大序号方向）表示不允许发送的。发送窗口后沿的变化情况有两种可能，即不动（没有收到新的确认）和前移（收到了新的确认）。发送窗口前沿通常是不断向前移动的。
- ![image-20210111145320038](https://i.loli.net/2021/01/11/jTBaX37AVC45qRO.png)
- 总结：
  - TCP使用滑动窗口机制。发送窗口里面的序号表示允许发送的序号，在一个窗口大小内，不用一定要等到应答才能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。
  - 如果不使用窗口控制，每一个没收到确认应答的数据都要重发。
  - 使用窗口控制，如果数据段1001-2000丢失，后面数据每次传输，确认应答都会不停地发送序号为1001的应答，表示我要接收1001开始的数据，发送端如果收到3次相同应答，就会立刻进行重发；但还有种情况有可能是数据都收到了，但是有的应答丢失了，这种情况不会进行重发，因为发送端知道，如果是数据段丢失，接收端不会放过它的，会疯狂向它提醒......

#### 超时重传时间的选择

- 超时重传机制：每一组（一般是1460byte）数据包发出后，就会记录其发送时间，超过超时重传时间RTO后还未收到其确认，就重传。
  - 注意：比如第一组是序号0开始的，但是收到的确认号是4381，这就意味着前三组都收到了，所以第一组肯定也是收到了。
- 超时重传时间RTO一般是略大于一个报文段的往返时间RTT，具体RTO细节详见课本。

#### 选择确认SACK（它其实只是提升传输效率的方法，对可靠传输没有帮助）

- **选择确认SACK：**（其实不是可靠传输的组成，而是仅仅是提升传输效率的手段而已）
- 若收到的报文段无差错，只是未按序号，中间还缺少一些序号的数据，设法只传送缺少的数据而不重传已经正确到达接收方的数据。
- ACK：说明这之前的数据部分，都已经连续收到，无缺失。
- SACK：这出现在选项部分，指明一对儿左右边界内的数据，也已收到。（详见课本）
- 一个TCP报文，最多指明4块儿已收到的不连续字节块。

### 2.2TCP流量控制（一个发送端，一个接收端，如何调整发送速率，两台计算机之间去协调）

#### 1.通过window字段来限制发送窗口

- 流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收
- 流量控制是一个端到端的问题，是接收端抑制发送端发送数据的速率，以便使接收端来得及接收。
- **其实就是由接收方发给发送方里的确认包里的TCP首部的window字段来控制，也叫rwnd。接收方回复确认包时，根据自身缓存情况动态调整这个窗口值**，来告诉发送方，你下次最多只能给我发多少多少字节，再多我的缓存就放不下了。
  - 注意：不是等发送方把发送窗口内的都发完了，接收方才会回复确认。接收方可以根据自身缓存情况来发送确认。

#### 2.通过三种机制来限制报文段大小

- 应用进程把数据传送到TCP的发送缓存后，剩下的发送任务就由TCP来控制了。
- 可以使用三种机制来控制TCP报文段的发送时机
  - 第一种机制：TCP维持一个变量，它等于最大报文段长度MSS。只要缓存中存放的数据达到MSS字节时，就组装成一个TCP报文段发送出去。
  - 第二种机制：由发送方的应用进程指明要求发送报文段，即TCP支持的推送（push）操作
  - 第三种机制：发送方的一个计时器期限到了，这时就把当前已有的缓存数据装入报文段（但长度不能超过MSS）发送出去。
- 这里还有个Nagle算法，来提升传输效率。（详见课本）

### 2.3TCP拥塞控制（网络中所有的计算机、路由器等共同实现的拥塞控制，而不是两台计算机之间）

- 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况就叫做拥塞。
- 拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不至过载。
- 拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。
- 为了进行拥塞控制，TCP的**发送方要维持一个拥塞窗口cwnd的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接收窗口中较小的一个。**
- 如果把窗口定的很大，发送端连续发送大量的数据，可能会造成网络的拥堵（大家都在用网，你在这狂发，吞吐量就那么大，当然会堵），甚至造成网络的瘫痪。所以TCP在为了防止这种情况而进行了拥塞控制。
- TCP的拥塞控制采用了四种算法，慢开始和拥塞避免、快重传和快恢复。
  - 慢开始
    - 定义拥塞窗口，一开始将该窗口大小设为1，之后每次收到确认应答（经过一个rtt），将拥塞窗口大小*2。
  - 拥塞避免
    - 设置慢启动阈值，一般开始都设为65536。拥塞避免是指当拥塞窗口大小达到这个阈值，拥塞窗口的值不再指数上升，而是加法增加（每次确认应答/每个rtt，拥塞窗口大小+1），以此来避免拥塞。
    - 将报文段的超时重传看做拥塞，则一旦发生超时重传，我们需要先将阈值设为当前窗口大小的一半，并且将窗口大小设为初值1，然后重新进入慢启动过程。
  - 快重传
    - 在遇到3次重复确认应答（高速重发控制）时，代表收到了3个报文段，但是这之前的1个段丢失了，便对它进行立即重传。
    - 3个重复确认即意味着请求快重传，快重传即意味着丢包了，丢包即意味着网络拥塞。所以执行快重传时，应立即执行快恢复。
  - 快恢复
    - 快恢复：先将阈值设为当前窗口大小的一半，然后将拥塞窗口大小设为慢启动阈值+3的大小。
- ![image.png](https://i.loli.net/2021/01/11/7ZyuDvzdXcLnglW.png)

### 2.4TCP三次握手建立连接

- ![image-20210111204848649](http://pichost.yangyadong.site/img/image-20210111204848649.png)
- 第一次握手：A向B发出连接请求报文段，SYN=1，并选定一个seq=x
- 第二次握手：B向A发送确认，SYN=1，ACK=1，并选定一个seq=y，由于A刚才发来的seq是x，所以ack=x+1。（+1字节，其实第一次握手数据部分为0字节，但是规定要SYN=1时，不携带数据也要消耗一个序号，所以从本应该的ack=x+0变成了ack=x+1，就像是第一次握手带了一字节数据一样）
- 第三次握手：A向B发送确认，ACK=1，由于B给A的ack是x+1，所以A该给B发seq=x-1开始的数据了。由于B给A的第二次握手SYN=1，也要消耗一个序号，所以ack=y+1。
- ack计算方法（数据传输无误时）
  - 当接收的包SYN=1时，无论ACK是多少，回复包的ack=接收包seq+1
  - 当接收的包ACK=1且SYN=0时，回复包的ack=接收包seq+TCP数据长度
- seq计算方法
  - 接受的包ack是多少，那么回复包的seq就是多少
- 抓包工具里，会把x、y换算成相对数值，实际上是个很大的数。相对数值把x、y都当0就行。
- ![image-20210111205815080](http://pichost.yangyadong.site/img/image-20210111205815080.png)

### 2.5TCP四次挥手结束连接

- 跟SYN一样，FIN即使不携带数据，也要消耗一个序号。（本来ack应该等于u+0的，因为这个规定，才变成了u+1）
- ![image-20210111211343487](http://pichost.yangyadong.site/img/image-20210111211343487.png)

### 2.6 SYN攻击

![image-20210111213532458](http://pichost.yangyadong.site/img/image-20210111213532458.png)

## 1.应用层

### 1.1HTTP和HTTPS的区别，以及HTTPS有什么优缺点？

#### HTTP和HTTPS的区别

- （1）HTTP协议是以明文的方式在网络中传输数据，而HTTPS协议传输的数据则是经过TLS加密后的，HTTPS具有更高的安全性
- （2）HTTPS在TCP三次握手阶段之后，还需要进行SSL 的handshake，协商加密使用的对称加密密钥
- （3）HTTPS协议需要服务端申请证书，浏览器端安装对应的根证书
- （4）HTTP协议端口是80，HTTPS协议端口是443

#### HTTPS有什么优缺点？

- 优点
  - HTTPS需要服务器提供证书，确保服务器的真实性，即允许用户证实服务器的身份，以防中间人攻击
  - 如有必要，也可以进行客户鉴别，允许服务器证实客户的身份
  - HTTPS传输数据过程中使用协商好的对称密钥进行加密，所以安全性更高
- 缺点
  - HTTPS握手阶段延时较高：由于在进行HTTP会话之前还需要进行SSL握手，因此HTTPS协议握手阶段延时增加
  - 由于有数据的对称加密解密过程，降低了用户的访问速度
  - HTTPS部署成本高：
    - 一方面指，HTTPS协议需要使用证书来验证自身的安全性，所以服务器需要购买CA证书
    - 另一方面指：HTTPS协议需要进行加解密的计算，占用CPU资源较多，相比于http其需要更多的计算机资源来支撑

### 1.2请你说一说HTTP返回码（指的是响应报文的状态行中的状态码）

**5大类响应报文的状态码**

- 1xx：指示信息--表示请求已接收，继续处理。
- 2xx：成功--表示请求已被成功接收、理解、接受。
- 3xx：重定向--要完成请求必须进行更进一步的操作。
- 4xx：客户端错误--请求有语法错误或请求无法实现。
- 5xx：服务器端错误--服务器未能实现合法的请求。

**常见的响应报文状态行：**

- HTTP/1.1 202 Aceepted        				 {接受}
- HTTP/1.1 301 Moved Permanently      {永久性地转移了}
- HTTP/1.1 400 Bad Request                    {错误的请求}
- HTTP/1.1 404 Not Found                        {找不到}

### 1.3HTTP请求报文中GET和POST的区别

#### 简介

在客户机和服务器之间进行请求-响应时，两种最常被用到的方法是：GET 和 POST。

- **GET** - 从指定的资源请求数据。
- **POST** - 向指定的资源提交要被处理的数据
- GET一般用于获取/查询资源信息，而POST一般用于更新资源信息.

#### 概括

- get请求

  - 请注意，查询字符串（名称/值对）是在 GET 请求的 URL 中发送的：

    - `/test/demo_form.asp?name1=value1&name2=value2`
  - GET 请求可被缓存
  - GET 请求保留在浏览器历史记录中
  - GET 请求可被收藏为书签
  - GET 请求不应在处理敏感数据时使用
    - 比如发送账号密码，绝对不应该使用GET，而应该使用POST
  - GET 请求有长度限制
    - 其实url 长度限制是某些浏览器和服务器的限制，和 HTTP 协议没有关系。
  - GET 请求只应当用于取回数据

- post方法

  - 请注意，查询字符串（名称/值对）是在 POST 请求的 HTTP 消息主体中发送的：

    - ```
      POST /test/demo_form.asp HTTP/1.1
      Host: w3schools.com
      name1=value1&name2=value2
      ```

  - POST 请求不会被缓存

  - POST 请求不会保留在浏览器历史记录中

  - POST 不能被收藏为书签

  - POST 请求对数据长度没有要求

- 最为关键的：

  - 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；
  - 对于POST，一般而言，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）
    - 备注：header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。

#### 区别

- 1、get参数通过url传递，post放在request body中。
- 2、get请求在url中传递的参数是有长度限制的，而post没有。
  - 备注：其实url 长度限制是某些浏览器和服务器的限制，和 HTTP 协议没有关系。
  - 浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。
- 3、get比post更不安全，因为参数直接暴露在url中，所以不能用来传递敏感信息。
  - 备注：只是get比post更不安全而已，其实Post也不安全，因为http是明文的。就算post把账号密码信息藏在request body中照样可以被黑客所截获并直接读取明文。
- 4、get请求只能进行url编码，而post支持多种编码方式。
  - 在Form元素的语法中，EncType表明提交数据的格式 用 Enctype 属性指定将数据回发到服务器时浏览器使用的编码类型。 例如： application/x-www-form-urlencoded： 窗体数据被编码为名称/值对。这是标准的编码格式。 multipart/form-data： 窗体数据被编码为一条消息，页上的每个控件对应消息中的一个部分，这个一般文件上传时用。 text/plain： 窗体数据以纯文本形式进行编码，其中不含任何控件或格式字符。
  - 当action为get时候，浏览器用x-www-form-urlencoded的编码方式把form数据转换成一个字串（name1=value1&name2=value2…），然后把这个字串append到url后面，用?分割，加载这个新的url。
  - 当action为post时候，浏览器把form数据封装到http body中，然后发送到server。 如果没有type=file的控件，用默认的application/x-www-form-urlencoded就可以了。 但是如果有type=file的话，就要用到multipart/form-data了。浏览器会把整个表单以控件为单位分割，并为每个部分加上Content-Disposition(form-data或者file),Content-Type(默认为text/plain),name(控件name)等信息，并加上分割符(boundary)。
- 5、get请求浏览器主动cache，而post 请求不会被缓存。
  - 缓存是一种保存资源副本并在下次请求时直接使用该副本的技术，当 web 缓存发现请求的资源已经被存储，它会拦截请求，返回该资源的拷贝，而不会去源服务器重新下载。css样式文件、js文件、logo、图标、html文件、可以下载的内容等等不经常改变的文件都可能被浏览器缓存。
  - **HTTP缓存**的基本目的就是使应用执行的更快，更易扩展，但是HTTP缓存通常只适用于idempotent request（可以理解为查询请求，也就是不更新服务端数据的请求），这也就导致了**在HTTP的世界里，一般都是对Get请求做缓存，Post请求很少有缓存。**
    - get多用来直接获取数据，不修改数据，主要目的就是DB的search语句的感觉。用缓存(有个代理服务器的概念)的目的就是查db的速度变快。
    - post则是发送数据到服务器端去存储。类似db里的update delete和insert语句的感觉。更新db的意思。数据必须放在数据库，所以一般都得去访问服务器端。
- 6、get请求参数会被完整保留在浏览历史记录里，而post中的参数不会被保留。
- 7、GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。
- 8、GET产生一个TCP数据包；POST产生两个TCP数据包。
  - 备注：header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。
- ![image-20210116174138285](http://pichost.yangyadong.site/img/image-20210116174138285.png)

### 1.4说一说http协议

https://www.cnblogs.com/ranyonsue/p/5984001.html

#### 1.4.1HTTP协议

- HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写，是用于从万维网（WWW:World Wide Web）服务器传输超文本到本地浏览器的传送协议。
- HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件，图片文件，查询结果等）。
- HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。目前在WWW中使用的是HTTP/1.0的第六版，HTTP/1.1的规范化工作正在进行之中，而且HTTP-NG（Next Generation of HTTP）的建议已经提出。
- HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。
- ![img](https://upload-images.jianshu.io/upload_images/2964446-5a35e17f298a48e1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2)

#### 1.4.2HTTP协议特点

- 1、简单快速：
- 客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。
- 2、灵活：
  - HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。
- 3、无连接：
  - 无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。
- 4、无状态：
  - HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。
- 5、支持B/S及C/S模式。
- 6、默认端口80
- 7、基于TCP协议

#### 1.4.3HTTP过程概述：

HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。

以下是 HTTP 请求/响应的步骤：

- 1、客户端连接到Web服务器
  - 一个HTTP客户端，通常是浏览器，与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接。例如，http://www.baidu.com。
- 2.发送HTTP请求
  - 通过TCP套接字，客户端向Web服务器发送一个文本的请求报文，一个请求报文由请求行、请求头部、空行和请求数据4部分组成。
- 3.服务器接受请求并返回HTTP响应
  - Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。一个响应由状态行、响应头部、空行和响应数据4部分组成。
- 4.释放连接TCP连接
  - 若connection 模式为close，则服务器主动关闭TCP连接，客户端被动关闭连接，释放TCP连接;若connection 模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求;
- 5.客户端浏览器解析HTML内容
  - 客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的HTML文档和文档的字符集。客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示。

#### 1.4.4举例

在浏览器地址栏键入URL，按下回车之后会经历以下流程：

- 1、浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址；
- 2、解析出 IP 地址后，根据该 IP 地址和默认端口80，和服务器建立TCP连接；
- 3、浏览器发出读取文件（URL中域名后面部分对应的文件）的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器；
- 4、服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器；
- 5、释放 TCP连接；
- 6、浏览器将该 html 文本并显示内容；

### 1.5cookie干啥的（cookie在服务器和客户端各存一份，客户端发送的HTTP请求报文中携带上cookie，用于网站跟踪用户动态）

#### 原理

- HTTP中使用的。
  - **万维网站点可以使用cookie来跟踪用户**
- 当用户张三浏览某个使用cookie的网站比如阿里云时，**该网站的服务器就为张三产生一个为一个识别码（即cookie）**比如36593464，并以此作为索引在服务器的后端数据库中产生一个项目。接着**服务器给张三发的HTTP响应报文中添加一个首部行** `Set-cookie：36593464`。
- 张三收到服务器传回来的HTTP响应报文，**浏览器就在Cookie文件后添加一行，记录下来 服务器主机名和Set-cookie后边的识别码。**
- **以后张三再浏览这个网站时，每次发送的HTTP请求报文，浏览器都会从Cookie文件中取出这个网站的识别码，并放到HTTP请求报文的Cookie首部行中**`Cookie:36593464`。
- 于是网站就可以跟踪用户36593464（张三）在该网站上的所有活动。比如知道36593464这个用户什么时间访问了什么页面；如果张三是在购物，那么服务器可以为张三维护一个所购物品列表即购物车，使得张三在浏览多个页面后，购物车里的东西还在，可以一起结算。

#### cookie应用--记住密码

- 记住密码
  - 比如客户端本地储存了阿里云服务器的cookie。
  - ![image-20210115165111008](http://pichost.yangyadong.site/img/image-20210115165111008.png)
  - 那我在打开https://account.aliyun.com/时，HTTP请求报文中会自动带上我的Cookie。然后阿里云服务器收到我的HTTP请求，阿里云查它那里存的记录，该Cookie对应的账号密码是多少，返回给我页面时，就自动把账号密码填上了。
- 比如用chrome普通模式，允许使用cookie
  - 用浏览器直接输入：https://account.aliyun.com/。我的账号密码就已经填上了，因为我以前登陆过，并选择了记住密码。
  - ![image-20210115170022105](http://pichost.yangyadong.site/img/image-20210115170022105.png)
- 如果使用chrome无痕模式，默认是禁止使用某些cookie的。像这种记住密码的cookie就被禁用了，因此阿里云服务器的响应界面，就没有自动填上账号密码。
  - ![image-20210115172112193](http://pichost.yangyadong.site/img/image-20210115172112193.png)

#### cookie的其他主要应用

- 保持登录状态
- 记住购物车中的商品
- 网站可以利用cookie查看客户在该网站上的浏览活动，以便为我推荐商品。
- ![image-20210115172524516](http://pichost.yangyadong.site/img/image-20210115172524516.png)

### 1.6TCP 连接上面能发多少个 HTTP 请求

一道经典的面试题是从 URL 在浏览器被被输入到页面展现的过程中发生了什么，大多数回答都是说请求响应之后 DOM 怎么被构建，被绘制出来。但是你有没有想过，收到的 HTML 如果包含几十个图片标签，这些图片是以什么方式、什么顺序、建立了多少连接、使用什么协议被下载下来的呢？

要搞懂这个问题，我们需要先解决下面五个问题：

#### 1.6.1 现代浏览器在与服务器建立了一个 TCP 连接后是否会在一个 HTTP 请求完成后断开？什么情况下会断开？

- HTTP/1.0，一个服务器在发送完一个 HTTP 响应后，会断开 TCP 链接。这种叫做非持续连接。
- HTTP/1.1，使用了持续连接。服务器对 Connection: keep-alive 的 Header 进行了支持。意思是说，完成这个 HTTP 请求之后，不要断开 HTTP 请求使用的 TCP 连接。这样的好处是连接可以被重新使用，之后发送 HTTP 请求的时候不需要重新建立 TCP 连接，以及如果维持连接，那么 SSL 的开销也可以避免。
- 答案：
  - 现代浏览器都支持http/1.1，默认情况下建立 TCP 连接不会断开，只有在请求报头中声明 Connection: close 才会在请求完成后关闭连接。

#### 1.6.2 一个 TCP 连接可以对应几个 HTTP 请求？

了解了第一个问题之后，其实这个问题已经有了答案，如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。

#### 1.6.3 一个 TCP 连接中 HTTP 请求发送可以一起发送么（比如客户端一起发三个请求，再三个响应一起接收）？

- HTTP/1.1 存在一个问题，单个 TCP 连接在同一时刻只能处理一个请求，意思是说：两个请求的生命周期不能重叠，任意两个 HTTP 请求从开始到结束的时间在同一个 TCP 连接里不能重叠。（非流水线方式）
- 在 HTTP/1.1 存在 Pipelining 技术可以完成这个多个请求同时发送，但是浏览器默认关闭该方式，因为实践中有很多问题。（流水线方式）
- 答案：
  - HTTP/1.1有非流水线和流水线两种方式。虽然HTTP/1.1流水线方式可以支持客户在收到HTTP响应报文之前就能够接着发送新的请求报文，即比如客户端一起发三个请求，再三个响应一起接收。但是HTTP/1.1的流水线方式非常不好用，默认都关闭，因此可以视为HTTP/1.1不支持这种操作。
  - HTTP2 提供了 Multiplexing 多路传输特性，可以在一个 TCP 连接中同时完成多个 HTTP 请求。在 HTTP2 中由于 Multiplexing 特点的存在，多个 HTTP 请求可以在同一个 TCP 连接中并行进行。
- 那么在 HTTP/1.1 时代，又一般不使用流水线方式，浏览器是如何提高页面加载效率的呢？
  - 1.维持和服务器已经建立的 TCP 连接，在同一连接上顺序处理多个请求。（非流水线方式）
  - 2.和服务器建立多个 TCP 连接。

#### 1.6.4为什么有的时候刷新页面不需要重新建立 SSL 连接？

在第一个问题的讨论中已经有答案了，TCP 连接有的时候会被浏览器和服务端维持一段时间（HTTP/1.1以后都是这样）。TCP 不需要重新建立，SSL 自然也会用之前的。

#### 1.6.5 浏览器对同一 Host（服务器） 建立 TCP 连接到数量有没有限制？

- 假设我们还处在 HTTP/1.1 时代，那个时候没有多路传输（即HTTP2的Multiplexing），当浏览器拿到一个有几十张图片的网页该怎么办呢？肯定不能只开一个 TCP 连接顺序下载（即采用非流水线方式，流水线方式一般被禁用，因为实践中有很多问题），那样用户肯定等的很难受。
- 但是如果每个图片都开一个 TCP 连接发 HTTP 请求，那电脑或者服务器都可能受不了，要是有 1000 张图片的话总不能开 1000 个TCP 连接吧，你的电脑同意 ，NAT 也不一定会同意。
- 所以答案是：有。Chrome 最多允许对同一个 Host（服务器） 建立六个 TCP 连接。不同的浏览器有一些区别。
  - ![image-20210116161233647](http://pichost.yangyadong.site/img/image-20210116161233647.png)
  - 用chrome访问我的网站时，TCP连接就2个（其实最大可以6个）。

#### 1.6.6收到的 HTML 如果包含几十个图片标签，这些图片是以什么方式、什么顺序、建立了多少连接、使用什么协议被下载下来的呢？

- 如果图片都是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手之后会和服务器商量能不能用 HTTP2，如果能的话就使用 Multiplexing 功能在这个连接上进行多路传输。不过也未必会所有挂在这个域名的资源都会使用一个 TCP 连接去获取，但是可以确定的是 Multiplexing 很可能会被用到。
- 如果发现用不了 HTTP2 呢？或者用不了 HTTPS（**现实中的 HTTP2 都是在 HTTPS 上实现的**，所以也就是只能使用 HTTP/1.1），只能使用 HTTP/1.1一般还都是使用非流水线方式。那浏览器就会在一个 HOST（服务器） 上建立多个 TCP 连接，连接数量的最大限制取决于浏览器设置（chrome最多允许客户端跟同一服务器建立6个TCP连接），这些连接会在空闲的时候被浏览器用来发送新的请求，如果所有的连接都正在发送请求呢？那其他的请求就只能等等了。

### 1.7URL组成

就以下面这个URL为例，介绍下普通URL的各部分组成

`http://www.aspxfans.com:8080/news/index.asp?boardID=5&ID=24618&page=1#name`

- 从上面的URL可以看出，一个完整的URL包括以下几部分：
- **1、**协议部分：该URL的协议部分为“http：”，这代表网页使用的是HTTP协议。在Internet中可以使用多种协议，如HTTP，FTP等等本例中使用的是HTTP协议。在"HTTP"后面的“//”为分隔符
- **2、**域名部分：该URL的域名部分为“www.aspxfans.com”。一个URL中，也可以使用IP地址作为域名使用
- **3、**端口部分：跟在域名后面的是端口，域名和端口之间使用“:”作为分隔符。端口不是一个URL必须的部分，如果省略端口部分，将采用默认端口80
- **4、**虚拟目录部分：从域名后的第一个“/”开始到最后一个“/”为止，是虚拟目录部分。虚拟目录也不是一个URL必须的部分。本例中的虚拟目录是“/news/”
- **5、**文件名部分：从域名后的最后一个“/”开始到“？”为止，是文件名部分，如果没有“?”,则是从域名后的最后一个“/”开始到“#”为止，是文件部分，如果没有“？”和“#”，那么从域名后的最后一个“/”开始到结束，都是文件名部分。本例中的文件名是“index.asp”。文件名部分也不是一个URL必须的部分，如果省略该部分，则使用默认的文件名
- **6、**锚部分：从“#”开始到最后，都是锚部分。本例中的锚部分是“name”。锚部分也不是一个URL必须的部分
- **7、**参数部分：从“？”开始到“#”为止之间的部分为参数部分，又称搜索部分、查询部分。本例中的参数部分为“boardID=5&ID=24618&page=1”。参数可以允许有多个参数，参数与参数之间用“&”作为分隔符。

### 1.8http/https 1.0、1.1、2.0的特点和区别

#### 理论

HTTP 2.0 和 HTTP 1.1 相比有哪些优势呢？ - Java3y的回答 - 知乎 https://www.zhihu.com/question/306768582/answer/595200654

- HTTP1.0
  - 1.0的HTTP版本，是一种无状态，无连接的应用层协议。
  - 短连接：
    - 浏览器每次请求都需要与服务器建立一个TCP连接，服务器处理完成以后立即断开TCP连接（无连接），服务器不跟踪也每个客户单，也不记录过去的请求（无状态）。
  - 所以HTTP1.0的最大弊端：
    - 短连接：每次请求都需要与服务器建立一个TCP连接，服务器处理完成以后立即断开TCP连接
- HTTP1.1（多个TCP连接+每个TCP连接里假并行）
  - 长连接：
    - HTTP1.1增加Connection字段，通过设置**Keep-Alive**保持HTTP连接不断卡。避免每次客户端与服务器请求都要重复建立释放建立TCP连接。提高了网络的利用率。
    - 如果客户端想关闭HTTP连接，可以在请求头中携带Connection:false来告知服务器关闭请求。
  - 管道化（pipelining）— 尴尬的假并行传输（即流水线方式），其实还是单个TCP连接上进行假并行
    - 即流水线方式的HTTP1.1。客户在收到HTTP响应报文之前，就能够接着发送新的请求报文。
    - HTTP Pipelining其实是把多个HTTP请求放到一个TCP连接中一一发送，而在发送过程中不需要等待服务器对前一个请求的响应；只不过，**客户端还是要按照发送请求的顺序来接收响应！**
    - **这种方式在实践中有很多问题（主要是线头阻塞问题，前一个请求非常耗时（顾客磨蹭），那么后续请求都会受到影响。），因此一般不用，默认关闭。**
    - 注意：这个pipelining仅仅是**限于理论场景下**，大部分桌面浏览器仍然会**选择默认关闭**HTTP pipelining！
    - 所以现在使用HTTP1.1协议的应用，都是有**可能会开多个TCP连接**的！
  - 缓存处理 — 强缓存、协商缓存，启发式缓存（新增）
    - HTTP1.1还加入了缓存处理（强缓存和协商缓存），新的字段如cache-control，支持断点传输，以及增加了Host字段（使得一个服务器能够用来创建多个Web站点）
  - 允许客户端与服务器建立多个TCP连接（这个算是个真并行）
    - chrome规定最多跟一个服务器（域名）建立6个TCP连接。所以比如网站想给你发12个文件过来，那很有可能就是每个TCP连接上，按顺序发送两个文件给你。
  - 所以，HTTP1.1的最大弊端：
    - 客户端还是要按照发送请求的顺序来接收响应，管道化这种单个TCP连接上假并行方式没有啥用。
  - 优点：长连接这种方式还算有点用，提高了效率；允许客户端与服务器建立多个TCP连接，这个是真并行，有用。
- HTTP2（单个TCP连接+二进制分帧）
  - HTTP2与HTTP1.1最重要的区别就是**解决了线头阻塞的**问题！其中最重要的改动是：**多路复用 (Multiplexing)**
  - 二进制分帧
    - HTTP2.0通过在应用层和传输层之间增加一个二进制分层帧（不再以文本格式明文来传输了，它定义了如何封装http消息并在客户端与服务器之间传输），突破了HTTP1.1的性能限制，改进传输性能。
    - 问：文本虽然是明文，传输时不也是二进制吗，跟这个二进制分帧有什么区别吗？答：这个二进制流是明文二进制经过压缩（编码）的，这个压缩（编码）再解压（解码）对于传输效率的提升是很明显的。
  - 多路复用（链接共享）— 真并行传输：
    - HTTP2.0实现了真正的并行传输，它能够在一个TCP上进行任意数量的HTTP请求。而这个强大的功能基于“二级制分帧”的特性。
    - 单TCP连接+多个二级制帧，即将响应内容打散成多个二进制帧，类似于BT下载中的文件块。
    - **对于IO这个事情，连接个数越多不代表越高效，因为连接之间切来切去也要消耗资源**。单TCP连接+多个二级制帧比多TCP连接方式可能还要高效。
  - 头部压缩
    - 在HTTP1.X中，头部元数据都是以纯文本的形式发送的，通常会给每个请求增加500-8000字节的负荷。
    - HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header_files表，既避免重复header的传输，又减少了需要传输的大小。
    - 高效的压缩算法可以很大的压缩header，减少发送包的数量从而降低延迟。
  - 服务器推送
    - 服务器除了最初请求的响应外，服务器还可以额外向客户端推送资源，而无需客户端明确的需求。
  - 最大优点：
    - 访问一个域名只需要占用一个 TCP 连接，消除了因多个 TCP 连接而带来的延时和内存消耗。
    - 单个连接可以承载任意数量的双向数据流。
    - 数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。
- HTTP3（2019年提出，尚未落实）
  - 从基于TCP变成基于UDP

#### 实例

访问网站

https://http2.akamai.com/demo。演示了同样的数据用http1.1和http2来传输的差别

![image-20210118171252053](http://pichost.yangyadong.site/img/image-20210118171252053.png)

#### http2远快于http1.1的原因

- 1.就一个TCP连接，不用切来切去，消除了因多个 TCP 连接而带来的延时和内存消耗
  - 什么叫切来切去。比如网站传输400个图片给你，你只有6个TCP连接，那只能先传输第1-6张图片，然后第一张传输完了，那就在第一个TCP连接上传输第7张。第二张传输完了，那就在第二个TCP连接上传输第8张....以此类推。所以6个TCP承担了400张图片的下载任务，切来切去，前一个图片没有传输完，后边的就不能传，排着队等待。
- 2.多路复用（链接共享）— 真并行传输：
  - HTTP2.0实现了真正的并行传输，它能够在一个TCP上进行任意数量的HTTP请求。而这个强大的功能基于“二级制分帧”的特性。
  - 单TCP连接+多个二级制帧，即将响应内容打散成多个二进制帧，类似于BT下载中的文件块。
  - 对于IO这个事情，TCP连接个数越多不代表越高效，因为连接之间切来切去也要消耗资源。单TCP连接+多个二级制帧比多TCP连接方式可能还要高效。
- 3.二进制分帧里有压缩算法
  - 其实就是二进制编码和解码。编码就是一种压缩。
- 4.头部压缩
  - gzip压缩 http1.1也有，并不是http2的压缩技术。gzip是对消息主体的压缩
  - http2的头部压缩技术是基于静态哈夫曼码表的哈夫曼编码（Huffman Coding）

#### 注意

- 虽然理论上HTTP2.0其实可以支持非HTTPS的，但是现在主流的浏览器像chrome，firefox表示还是只支持基于 TLS 部署的HTTP2.0协议，所以要想升级成HTTP2.0还是先升级HTTPS为好。
- 所以目前的浏览器，如果想用http2，必须得用https。
- 所以
  - https，不一定是http2，很有可能SSL\TLS上层的应用层是http1.1。
  - http2，一定是https。因为目前的浏览器规定，http2底下必须得有SSL\TLS层，否则不支持。
- 用firefox查看http1.1和http2.0
  - https底下跑http1.1的例子
    - ![image-20210118174432422](http://pichost.yangyadong.site/img/image-20210118174432422.png)
  - https底下跑http2.0的例子
    - ![image-20210118174406432](http://pichost.yangyadong.site/img/image-20210118174406432.png)
  - 备注：得用Firefox浏览器才行，chrome看不到http2类型。只能看http1.1类型。
- 不过在chrome下可以根据Respense Headers有没有view source选项，来判断是http1.1还是http2.0
  - https底下跑http1.1的例子
    - ![image-20210118174756366](http://pichost.yangyadong.site/img/image-20210118174756366.png)
  - https底下跑http2.0的例子
    - ![image-20210118174849358](http://pichost.yangyadong.site/img/image-20210118174849358.png)

## 2.传输层

### 2.1TCP怎么保证可靠性

- 1.停止等待协议（序号、确认应答、超时重传机制）
  - 序号：对TCP缓存里的数据按字节编上序号。
  - 确认应答：数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认号说明了接收方下一次需要接收的数据序号。
  - 超时重传机制：如果发送方迟迟未收到确认应答，那么可能是发送的数据丢失，也可能是确认应答丢失，这时发送方在等待一定时间（超时重传时间RTO）后会进行重传。这个时间（超时重传时间RTO）一般是RTT(报文段往返时间）+一个偏差值。
- 2.连续ARQ、滑动窗口协议、高速重发控制/快速重传
  - TCP会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定要等到应答才能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。
  - 两种重传机制：
    - 一种是停止等待里提到的超时重传机制。如果发送方迟迟未收到确认应答，在等待一定时间（超时重传时间RTO）后会进行重传。
    - 另一种是快重传机制。使用窗口控制，如果数据段1001-2000丢失，后面数据每次传输，确认应答都会不停地发送序号为1001的应答，表示我要接收1001开始的数据，发送端如果收到3次相同应答，就会立刻进行重发

### 2.2TCP三次握手

#### 三次握手细节

![image-20210112163212081](http://pichost.yangyadong.site/img/image-20210112163212081.png)

- 第一次握手：客户端给服务器发送请求连接报文，SYN=1，序号seq=x。客户端从closed进入SYN-SENT状态
- 第二次握手：服务器给客服端发送连接确认报文，SYN=1，ACK=1，序号seq=y，确认号ack=x+1。服务器从listen进入SYN-RCVD状态。
  - 本来这个ack=x+0的，因为三次握手都是纯TCP首部，没有TCP数据。但是规定，SYN等于1的数据包（这里指第一次握手那个数据包）必须消耗一个序号，所以ack=x+1了。
- 第三次握手：客户端给服务器发送确认的确认报文，ACK=1，序号seq=x+1，确认号ack=y+1。服务器从SYN-SENT进入ESTABLISHED状态
  - 服务端收到这个第三次握手信息后，也从SYB-RCVD状态进入ESTABLISHED状态
  - 同理，这里的ack也本该是y+0，但是由于第二次握手SYN=1，所以这里变成ack=y+1了。

#### 为什么是三次握手不用两次握手

- 谢希仁版本解释：
  - 假如只有二次握手，客户端A的请求报文在网络滞留，【客户端A超时重传了请求报文，服务端B建立连接，传输数据，释放连接之后】，服务器B又收到了客户端A滞留的请求报文，发送确认给A，然后进入ESTABLISHED状态一直等待客户端发送数据。但是此时客户端A认为没有发送连接请求啊，不会理睬B的确认，但B却认为连接已经建立了，B一直等待客户端发数据却再也等不到，B的许多资源就这样白白浪费了。
  - 当采用三次握手时，再发生上边这种情况时，服务器B又收到了客户端A滞留的请求报文，发送确认给A，此时A认为没有发送连接请求啊，不发送第三次握手信息，所以B收不到第三次握手，只在SYN-RCVD状态，就不进入ESTABLISHED状态空耗大量资源了。
    - 注意：其实服务器维持大量的SYN-RCVD状态也会崩溃的，SYN攻击就是这个原理。
- 换个角度理解：
  - 二次握手只能保证单向通信。因为SYN设计的初衷是用来同步时钟（序号）的。
  - 1.A --> B SYN my sequence number is X 
  - 2.A <-- B ACK your sequence number is X 。 SYN my sequence number is Y
  - 到此戛然而止的话，不能够确保A收到了B的序号Y
    - 换句话说只有A --> B这个单向是可靠的，A <-- B并不可靠，因为没有确保A收到了序号Y。

#### 为什么是三次握手不用四次握手

挥手是四次，为什么握手就只有三次。

握手其实应该是4次，但是简化成了三次

- 首先要明白，SYN设计的初衷是用来同步时钟（序号）的。
  - 1.A给B一个SYN，2.B就该给A一个ACK。
  - 3.然后B给A一个SYN，4.A给B一个ACK。

- 1.A --> B SYN my sequence number is X
- 2.A <-- B ACK your sequence number is X 
- 3.A <-- B SYN my sequence number is Y
- 4.A --> B ACK your sequence number is Y
- 2与3都是 B 发送给 A，因此可以合并在一起

**所以真正的三次握手**

- 1.A --> B SYN my sequence number is X 
- 2.A <-- B ACK your sequence number is X ，SYN my sequence number is Y
- 3.A --> B ACK your sequence number is Y

### 2.3TCP四次挥手

#### 四次挥手细节

这里以客户端发起的主动挥手为例。

![image-20210112160934843](http://pichost.yangyadong.site/img/image-20210112160934843.png)

2MSL的另一个理由：2MSL后，这次连接的所有报文都会消失，不会影响下一次连接。防止下一个新的连接中出现旧的连接请求报文段。

具体的四次挥手：

- 第一次挥手
  - 数据传输结束后，客户端的应用进程发出连接释放报文段，并停止发送数据，客户端进入FIN_WAIT_1状态，此时客户端依然可以接收服务器发送来的数据。
  - 当主动方发送断开连接的请求（即FIN报文）给被动方时，仅仅代表主动方不会再发送数据报文了，但主动方仍可以接收数据报文。
- 第二次挥手
  - 服务器接收到FIN后，发送一个ACK给客户端，确认序号为收到的序号+1，服务器进入CLOSE_WAIT状态。客户端收到后进入FIN_WAIT_2状态。
  - 被动方此时有可能还有相应的数据报文需要发送，因此需要先发送ACK报文，告知主动方“我知道你想断开连接的请求了”。这样主动方便不会因为没有收到应答而继续发送断开连接的请求（即FIN报文）。
- 第三次挥手
  - 当服务器没有数据要发送时，服务器发送一个FIN报文，此时服务器进入LAST_ACK状态，等待客户端的确认
  - 被动方在处理完数据报文后，便发送给主动方FIN报文；这样可以保证数据通信正常可靠地完成。发送完FIN报文后，被动方进入LAST_ACK阶段（超时等待）。
- 第四次挥手
  - 客户端收到服务器的FIN报文后，给服务器发送一个ACK报文，确认序列号为收到的序号+1。此时客户端进入TIME_WAIT状态，等待2MSL（MSL：报文段最大生存时间），然后关闭连接。
  - 如果主动方及时发送ACK报文进行连接中断的确认，这时被动方就直接释放连接，进入可用状态。

#### 为什么是四次挥手

- 原因：
  - 其实握手也应该是四次，但是建立连接不需要应用层决定，所以2、3步骤直接合并了
  - 二次挥手不行。因为挥手时，被动方应用层数据还没发完，不可以直接切断连接。所以第二次挥手完，仅仅切断了单向通路，要等到被动方数据传输完毕，才可以切断另一向通路。

### 2.4总体把握三次握手和四次挥手

![image-20210112160320415](http://pichost.yangyadong.site/img/image-20210112160320415.png)



### 2.4TCP状态转移

![20180521143137644](http://pichost.yangyadong.site/img/20180521143137644.jpg)

### 2.5请你说一说TCP拥塞控制？以及达到什么情况的时候开始减慢增长的速度？

#### 拥塞控制

- 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况就叫做拥塞。
- 拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不至过载。
- 拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。
- 为了进行拥塞控制，TCP的**发送方要维持一个拥塞窗口cwnd的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接收窗口中较小的一个。**
- 如果把窗口定的很大，发送端连续发送大量的数据，可能会造成网络的拥堵（大家都在用网，你在这狂发，吞吐量就那么大，当然会堵），甚至造成网络的瘫痪。所以TCP在为了防止这种情况而进行了拥塞控制。
- TCP的拥塞控制采用了四种算法，慢开始和拥塞避免、快重传和快恢复。
  - 慢开始（一开始的窗口很小，指数增大到慢开始门限ssthresh）
    - 最开始发送方的拥塞窗口为1（1是指一个分组，不是一个byte），由小到大逐渐增大发送窗口和拥塞窗口。每经过一个传输轮次（指的是把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认），拥塞窗口cwnd*2。当cwnd超过慢开始门限ssthresh，则使用拥塞避免算法线性增加，不再是指数增加了，避免cwnd增长过大。
  - 拥塞避免算法（达到慢开始门限ssthresh后，线性增加）
    - 每经过一个传输轮次，就把发送方的拥塞窗口cwnd加1。
  - 快重传算法（接收方一旦发现失序报文段到达，即大序号的先来了，小序号的一直没来，就发送三次重复确认）
    - 接收方发现失序报文，则意味着丢包了，立马发送三次重复的确认表示快重传。
    - 发送方收到三次重复的确认，则知道这是快重传的意思。快重传即意味着丢包了，丢包即意味着网络有可能快要拥塞了。
    - 发送方立马重传丢失的数据包，并启动快恢复。
  - 快恢复
    - 慢开始门限ssthresh乘法减半（即更新慢开始门限为当前cwnd的一半，注意是cwnd的一半，不是ssthresh的一半），然后将当前的cwnd设置为更新后的慢开始门限，并且之后采用拥塞避免算法线性增加cwnd。
- ![image.png](https://i.loli.net/2021/01/11/7ZyuDvzdXcLnglW.png)

#### 达到什么情况的时候开始减慢增长的速度？

- 采用纯粹慢开始和拥塞避免算法的时候（这种模式已经被淘汰了）
  - （1）一旦cwnd>慢开始门限，就采用拥塞避免算法，减慢增长速度
  - （2）一旦出现丢包的情况，就重新进行慢开始，减慢增长速度
- 采用慢开始+拥塞避免+快重传+快恢复（当前主流）
  - （1）一旦cwnd>慢开始门限，就不再采用指数增长了，而是采用拥塞避免算法线性增长，减慢增长速度。
  - （2）一旦发送方连续收到了三个重复确认，就采用拥塞避免算法，减慢增长速度

### 2.6TCP和UDP的区别，以及TCP和UDP各自适用的场景

#### TCP和UDP的区别

- 1.连接
  - UDP无连接。
  - TCP是面向连接的传输层协议，即传输数据之前必须先建立好连接。
- 2.服务对象
  - UDP支持一对一，一对多，多对一，多对多的交互通信。
  - TCP是点对点的两点间服务，即一条TCP连接只能有两个端点；
- 3.首部长度
  - UDP首部长度固定8字节
  - TCP首部长度20-60字节，包含20字节固定长度，选项长度可变0-40字节
- 4.数据部分长度
  - UDP面向报文，UDP对应用层交下来的报文，既不合并，也不拆分，保留这些报文的边界
    - 若应用层报文太长，那UDP交给IP层后，IP层在传送时可能要进行分片。(IP层到数据链路层时分片)
  - TCP面向字节流，最大报文段长度MSS是建立连接时协商的（即最大多少byte为一组，或者说叫一段，一个报文段）。具体地到底多少字节为一组，由三种机制控制。因此TCP的数据报文段的长度不固定，但最大不超过MSS。
    - 第一：缓存中存放的数据达到MSS字节时，就组装成一个TCP报文段发送出去。
    - 第二：发送方的应用程序指明要求发送报文段，即TCP支持的push操作。
    - 第三：发送方的一个计时器期限到了，这时就把当前已有的缓存数据装入报文段（不能超过MSS）发送出去。
- 4.可靠性
  - UDP是尽最大努力交付，不保证可靠交付。
  - TCP是可靠交付：无差错，不丢失，不重复，按序到达。
- 5.流量控制、拥塞控制
  - UDP没有拥塞控制，网络拥塞，不会影响源主机的发送效率。
  - TCP有流量控制，来协调两台计算机之间的通信速率。TCP有拥塞控制，协调网络上所有使用TCP协议的设备，避免出现网络拥塞。

#### TCP和UDP适用场景

- UDP
  - 1.要传输的内容一个数据包就完成了。（比如DNS域名解析）
  - 2.传输实时的语音和视频，因为这个需求实时性。中间丢几句话没听见，也不重传。要求实时。
  - 3.多播（电视台视频节目）
  - 换句话说，UDP不保证可靠传输。中间丢包没传过去，它不管，它就发一次。想使用UDP，还保证对方能收到，那得是应用层在操心。（例如qq发聊天消息）
- TCP
  - 要传输的内容需要分成多个数据包来传输
  - 在传输层需要 分段、编号。接收端收到以后，还得按照编号组装成完整的内容。
  - 主要应用场景：
    - 需要保证数据的完备性时。比如下载电影、下载文件、网页传输。
  - 换句话说，TCP保证可靠传输，中间丢包了，TCP自己就会重传，无需应用操心。
- yyd备注：
  - 卡了一会儿，数据还是来了，数据是完整的，那应该是TCP。TCP适合完整性要求高的。
    - 在线看腾讯视频
  - 卡了一会儿，数据丢了一些，那应该是UDP。UDP适合要求实时的。
    - 微信电话

### 2.7TCP首部与UDP首部

- UDP
  - ![image-20210116210731954](http://pichost.yangyadong.site/img/image-20210116210731954.png)
- TCP
  - ![image-20210116210829026](http://pichost.yangyadong.site/img/image-20210116210829026.png)

### 2.8TCP重发机制

TCP是可靠的传输协议，意味着必须按序，无差错的传送数据和目的端。通过校验和，确认应答，重传来保证。校验和应答已经介绍过，这里主要讲解重传机制。重传分为两种：超时重传和快速重传。

- **超时重传（RTO）**
  - 当一个包被发送后，就开启一个定时器，如果定时时间到了，还未收到能确认该发送包的应答包，就重传一份数据。注意收到的应答包可能是该包也可能是后面包的，但是只要能确认该包被收到就行。另外如果，是因为网络延时造成重传，则接受端收到重复数据包后丢弃该包。
- **快速重传**
  - 当如果发送端收到一个包的三次应答包后，立即重传，比超时重传更高效
- ![这里写图片描述](https://img-blog.csdn.net/20170401195948811?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2hhbmdoYWlydW94aWFv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

### 2.9TCP流量控制中的Nagle算法（用于减少发送那种小于MSS的分组，尽量让一次发送的分组数据容量都是MSS）

- Nagle算法要求，一个TCP连接在任意时刻，最多只能有一个没有被确认的小段，在该小段（即一个小分组，不够MSS的分组）ack到达之前不能发送其他的小分组，tcp需要收集这些少量的分组，并在ack到来时以一个分组的方式发送出去。
  - 只能有一个没有被确认的小段，但是可以有多个没有被确认的“大段”。小段即远小于1460byte的分组。大段即标准的MSS大小的分组。
  - 所谓“小段”指的是小于MSS的数据块，“没有被确认”指的是一个数据块发送出去后，没有收到对方发送的ACK确认。
- 该算法的优越之处在于它是自适应的，确认到达的越快，数据也就发送的越快；而在希望减少微小分组（即数据里内容很少，远少于1460byte的分组）数目的低速广域网上，则会发送更少的分组；

Nagle算法的实现规则：

1. 如果包长度达到MSS，则允许发送；
2. 如果该包含有FIN，则允许发送；
3. 设置了TCP_NODELAY选项，则允许发送；
4. 未设置TCP_CORK选项时，若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送；
5. 上述条件都未满足，但发生了超时（一般为200ms），则立即发送。

### 2.10TCP的拥塞控制使用的算法和具体过程、TCP的窗口滑动

详见之前的笔记。

拥塞控制使用的算法：

- 慢开始
- 拥塞避免
- 快重传
- 快恢复

TCP窗口滑动：详见前文。

## 4.网络层、链路层、物理层

### 4.1IP地址作用，以及MAC地址作用

- **数据包的目标IP地址决定了数据包最终到达哪一个计算机**
- 而**目标MAC地址决定了该数据包下一跳由哪个设备接收，不一定是终点（很有可能是路由器）**

<img src="https://i.loli.net/2020/11/23/KLjP3vxUJBZrWh5.png" alt="image.png" style="zoom:150%;" />

- 想从IP地址为10.0.0.2发送到IP地址为12.0.0.2的计算机。
  - 因为这个IP是唯一的，所以可以精准定位到目标地址
- 那要MAC地址干嘛？
  - MAC地址其实是用于短程托运工作，相当于暂时停靠的驿站
- **网络层里数据包，从来都不修改（NAT除外）**。从上图可以看到
  - 第一个步骤是，从发出信息的计算机MAC为MA，到路由器1的左口MAC地址M1
  - 然后到达路由器1后，路由器1一看，你想去地址12.0.0.2，属于12.0.0.0/24网段是吧，那我路由表里存了，想去这个网段，那得从路由器1的右口去路由器2的左口，所以
  - 第二个步骤是，从路由器1的右口MAC地址M2发送到路由器2的左口MAC地址M3
  - 然后到达路由器2后，路由器2一看，你想去地址12.0.0.2，数据12.0.0.0/24网段是吧，那我路由表里存了，想去这个网段，那得从路由器2的右口直接到达目标MAC，所以
  - 第三个步骤是，从路由器2的右口MAC地址M4发送到接收端电脑MAC地址MF

### 4.2TCP/IP数据链路层的交互过程

- 网络层到数据链层用mac地址作为通信目标，数据包到达网络等准备往数据链层发送的时候，会判断一下目标IP跟自己是否在同一网段。
  - 如果不在同一网段，那就发给网关，目标MAC填上网关的MAC，封装到MAC帧，发给网关，让网关去转发。
  - 如果在同一网段，那自己就能发过去了，不需要网关转发。首先会去自己的arp缓存表(存着ip-mac对应关系)去查找改目标ip的mac地址，如果查到了，就将目标ip的mac地址封装到链路层数据包的包头，封装带MAC帧里。如果缓存中没有找到，会发起一个arp广播：who is ip目标 tell ip 自己,所有收到的广播的机器看这个ip是不是自己的，如果是自己的，则以单播的形式将自己的mac地址回复给请求的机器。然后把MAC帧里的目标MAC填上目标IP的MAC地址，封装到MAC帧里，进行发送。
- **补充解释：**
- **数据发送的过程**
  - 假如A要给B发数据。
  - 计算机A怎么知道和计算机B在不在同一网段下呢，计算机A就用**A的子网掩码**，**跟A的IP地址**算一算，得到A所在的网段。计算机A用**A的子网掩码**（只能用A的子网掩码，因为B的你不知道）跟**B的IP地址**算一算，得到B所在的网段。然后比较这俩网段是不是一样的。
  - **假如A和B处于同一网段下（相当于俩计算机在一个局域网下，用交换机连的，根本不用过路由器）**：那计算机A就发arp广播包，询问局域网上所有机器，我需要知道目标（即计算机B）IP的MAC，然后目标电脑B接到这个指令，给它返回一个信息，告诉发送机A我的MAC是...然后A就可以封装以太网帧发送了
  - **假如A和B不在同一网段下（相当于俩计算机不在在一个局域网下，必须要用路由器来转发）**：那计算机A就发arp广播包，询问局域网上所有机器，询问网关（即路由器）你的MAC是多少，我需要你替我转达一个包，然后网关接到这个指令，给他返回一个信息，告诉计算机A，本网关的MAC是....然后A就可以封装以太网帧发送给网关了，靠路由器继续传送，最后抵达计算机B

### 4.3请你说说传递到IP层，怎么该区分该报文是UDP报文还是TCP报文

看网络层首部的协议字段

![image-20210112211549669](http://pichost.yangyadong.site/img/image-20210112211549669.png)

### 4.4 ARP（Address Resolution Protocol）地址解析协议

- 以太网帧发送时需要封装上目标MAC和源MAC

  - **电脑只知道源MAC（就是自己的网卡），那么发数据时的目标MAC怎么知道的呢？**
  - TCP/IP协议里有一个arp协议，当A计算机ping B计算机时，A计算机会在网上发一个广播帧，**广播帧的目标MAC是全F，即FF-FF-FF-FF-FF-FF**，48位的1。这个广播就是用于解析对方的MAC地址的。解析到以后就会缓存到本机上。
    - 不论哪台计算机，一旦收到一个目标MAC地址是FFFFFFFFFF的以太网帧时，都应该视为是给自己的。应当接收并处理。

- ARP协议是为IP协议提供服务的

  - 因为需要ARP包去解析目标主机的MAC地址。
  - 你要是不知道目标主机的MAC地址，这没法发过去的。数据链路层必须需要这个信息

- **ARP协议的作用，将以太网中的计算机的IP地址解析成MAC地址。**

  - **点到点链路使用PPP协议，不需要ARP协议。**（因为点到点的链路，不需要知道目标MAC地址，发给谁就是谁）

- ![image-20201223175026537](https://i.loli.net/2020/12/23/dt2VYXJM8EoqbGx.png)

- ARP帧格式

  - ![image-20201223170837589](https://i.loli.net/2020/12/23/9YaJxiHDjfvzlon.png)

- ARP举例

  - ![image-20201223165945374](https://i.loli.net/2020/12/23/KWtvLTRzfVuZciO.png)
  - 比如我ping林运检，发生了什么。我的ip是115.156.214.180。林运检IP是115.156.213.253。已知，我俩是交换机直连的。
  - 这时候还只知道林运检的IP地址，不知道他的MAC地址
  - 第一步
    - 杨亚东的PC机根据目标IP和自己的子网掩码一判断，目标主机跟我在同一网段，就不需要给网关了。直接给交换机上的所有主机发一个ARP广播，问，林运检（115.156.213.253）的MAC地址是多少
    - ![image-20201223171517672](https://i.loli.net/2020/12/23/eBGh9fFQR2l8wx5.png)
  - 第二步
    - 所有交换机上的主机都收到了杨亚东发送的广播包。但是只有林运检的主机一看，这个ARP是询问它自己的。因此**林运检的主机给杨亚东主机发送了arp回复**。交换机上其他主机一看不是问自己的，那就不回复。
    - ![image-20201223172630008](https://i.loli.net/2020/12/23/pDe29PSI3BVantg.png)
  - 第三步
    - 这时候杨亚东的主机收到arp回复了，知道林运检的MAC地址了。
    - 开始ICMP通信
    - ![image-20201223173843178](https://i.loli.net/2020/12/23/pivxJrLdfuSUYgM.png)

### 4.5Ping和TraceRoute实现原理

#### Ping原理

- ICMP协议是TCP/IP协议栈中的网络层的一个协议，**ICMP**是（Internet Control Message Protocol）**Internet控制报文协议**，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。
  - 也就是用来测试网络通还是不通的
  - 包括具体的数据报类型有：**ICMP请求、ICMP响应、ICMP差错报告**
  - 所以ICMP可以报告通还是不通，还可以报告出现了什么差错
- ICMP报文是在IP数据报内部被传输的，它封装在IP数据报内。ICMP报文通常被IP层或更层协议（TCP或UDP）使用。一些ICMP报文把差错报文返回给用户进程。
- ICMP依赖于网络层的IP协议。ICMP想传输，得在前边加上网络层首部

我ping 百度

- 我发送给百度服务器ICMP请求报文
- 百度服务器收到后，回复给我ICMP响应数据报
- 如果ping不通，中间某个路由器会发送给我ICMP差错报告

#### Tracert工作原理

- Ping命令并不能跟踪从源地址到目标地址沿途经过了哪些路由器， Windows操作系统中的tracert命令是路由跟踪实用程序，用于确定IP数据报访问目标地址路径，能够帮助我们发现到达目标网络到底是哪一条链路出现了故障。Tracert 命令就是ping命令的扩展，用 IP报文生存时间 （TTL）字段和 ICMP差错报告报文来确定沿途经过的路由器。
- TTL可以理解为，还可以跳几次。即该数据包还可以被路由器转发几次。
- Tracert工作原理如下图所示。
  - 即`ping www.baidu.com -i 1`。发送时，IP层首部的生存时间TTL设置为1。
    - 到第一个路由器，第一个路由器就会给我返回一个ICMP差错报告。因为TTL耗尽了
  - `ping www.baidu.com -i 2`
    - 到第二个路由器，第二个路由器就会给我返回一个ICMP差错报告。因为TTL耗尽了
  - `ping www.baidu.com -i 3`
    - 到第三个路由器，第三个路由器就会给我返回一个ICMP差错报告。因为TTL耗尽了
  - ....一个一个的发送这种TTL只有 1,2,3....的包。
- tracert其实可以完全像上边这样一个一个地使用ping来代替。tracert就仅仅是自动地发送 -i 1   -i 2 ....而已
- ![image-20201223155925182](https://i.loli.net/2020/12/23/ipkXoYMr8QBmzE2.png)
- pathping
  - Pathping是一个基于TCP/IP的命令行工具，该命令不但可以跟踪数据包从源主机到目标主机所经过的路径，还可以统计计算机网络延时以及丢包率，帮助我们解决网络问题，跟踪数据包路径的原理和tracert命令一样。

## 5.整体概念

### 5.1OSI七层模型和TCP/IP四层模型，每层列举2个协议

#### 概述

![image.png](https://i.loli.net/2020/10/12/au5Q6kJhKcHpoCY.png)

![image-20201221163749803](https://i.loli.net/2020/12/21/C4E3cFVaQyhbZvS.png)

#### OSI七层模型

- 应用层：根据互联网中需要通信的应用程序的功能，定义客户端和服务端程序通信的规范，应用层向表示层发出请求。有时候特指能够发起网络通信的应用程序。
  - 主要包括的协议为FTP HTTP，DNS DHCP
- 表示层：对数据进行编码、加密和压缩，主要包括的协议为JPEG压缩、ASCII编码、Unicode编码等等。
  - 压缩：QQ视频聊天，每一帧图像其实是很大的，QQ开发者采用了最先进的无损压缩算法。发送方在发送时先压缩了，等接收方收到数据到表示层时，再无损解压恢复出来，这样即节省了流量带宽，又保证了图像无损。
  - 加密：例如QQ聊天内容，传输时候聊天内容是加密的，传到接收方时，再解密出来。中间数据即使被黑客捕获了，黑客也无法得知俩人在聊什么，因为黑客不知道腾讯公司用的内容加密解密的秘钥。
  - 编码格式：文件在传的时候，要想正确显示文本（字符）内容，就得使用正确的编码格式，否则就是乱码。比如web服务器把网页，通过utf8字符集进行编码，编成二进制。客户端收到二进制，再通过utf8字符集，恢复成汉字、英文。
- 会话层：服务端和客户端建立会话，会话层连接面向用户，就一个。或者是SSL/TLS建立的会话。
  - 会话层连接面向用户，就一个。但是会话层可以使用多个传输层连接，或者一个传输层连接。
- 传输层：提供端到端的接口可靠报文传递和错误恢复，传输单位为报文,主要包括的协议为TCP UDP
  - 可靠传输、流量控制、拥塞控制：TCP。TCP需要建立连接。
  - 不可靠传输：UDP。UDP不建立连接。
  - 传输单位：数据段，或者说叫做分组。
- 网络层：负责为数据包选择路由，传输单位为数据包,主要包括的协议为ARP、IP、ICMP、IGMP
- 数据链路层：将数据包封装成能够在不同网络间传输的帧，传输单位为帧,主要包括的协议为CSMA/CD（以太网） 、PPP（点对点，ADSL拨号上网）
  - ![image-20210113211247169](http://pichost.yangyadong.site/img/image-20210113211247169.png)
- 物理层： 通过媒介传输比特,确定机械及电气规范,传输单位为bit，主要包括的协议为：IEE802.3 CLOCK RJ45

### 5.2打开baidu，会用到计算机网络中的什么层？每层是干什么的

#### 概览

- 1.浏览器中输入URL   https://www.baidu.com，敲回车
- 2.浏览器向DNS服务器请求解析www.baidu.com的IP地址
- 3.域名系统DNS解析出百度服务器的IP地址为182.61.200.7
- 4.浏览器与服务器建立TCP连接（在服务器端IP地址是182.61.200.7，端口是443）。
- 5.进行SSL握手。查验证书、协商加密算法、确定对称秘钥。
- 6.浏览器发出HTTP请求， GET...
- 7.服务器www.baidu.com，接受到这个请求后，根据路径参数，经过后台一些处理之后，把处理后的结果返回给浏览器，如果是百度首页，就可以把完整的 HTML 页面代码返回给浏览器。
- 8.浏览器拿到了百度首页的完整 HTML 页面代码，内核和 JS 引擎就会解析和渲染这个页面，里面的 JS，CSS，图片等静态资源也通过一个个 HTTP 请求进行加载。
- 9.浏览器根据拿到的资源对页面进行渲染，最终把完整的页面呈现给用户。
- 10.释放TCP连接

#### 细节

- 1.浏览器中输入URL
  - 浏览器要将URL解析为IP地址，解析域名就要用到DNS协议，首先主机会查询DNS的缓存，如果没有就给DNS服务器发送查询请求。
  - DNS查询分为两种方式，一种是递归查询，一种是迭代查询。
    - 递归查询（设置的DNS服务器是本地域名服务器，一般自动获取的就是这种。比如：华科本地域名服务器202.114.0.131）：这种DNS服务器一般离你的主机很近，一般不超过几个路由器的距离。如果主机所询问的本地域名服务器202.114.0.131不知道被查询域名的IP地址，那么本地域名服务器202.114.0.131就以DNS客户的身份，向其他根域名服务器继续发出查询请求报文。即本地域名服务器202.114.0.131替我去完成接下去的域名解析工作，我的主机只需要静静的等待结果。
    - 迭代查询（华科本地域名服务器202.114.0.131向根域名服务器的查询通常是采用迭代查询）：本地的DNS域名服务器202.114.0.131，向根域名服务器发送查询请求，根域名服务器告知该域名的一级域名服务器，然后本地服务器给该一级域名服务器发送查询请求，然后依次类推直到查询到该域名的IP地址。
  - 由于DNS是基于UDP协议的，因此还涉及到传输层UDP协议。
- 2.得到IP地址后，浏览器就要与服务器建立一个http连接。因此要用到http协议，http协议报文格式上面已经提到。http生成一个get请求报文，将该报文传给TCP层处理，所以还会用到TCP协议。如果采用https还会使用https协议先对http数据进行加密。
- 3.TCP层如果有需要先将HTTP数据包分段，分段大小最大是MSS。TCP的数据包然后会发送给IP层，用到IP协议。IP层通过路由选路，一跳一跳发送到目的地址。当然在一个网段内的寻址是通过以太网协议实现(也可以是其他物理层协议，比如PPP，帧中继)，以太网协议需要知道目的IP地址的物理地址，此时又需要网络层的ARP协议。

### 5.3server端监听端口，但还没有客户端连接进来，此时进程处于什么状态？

socket的开发

服务端：socket-bind-listen-accept
客户端：socket-connect

这个需要看服务端的编程模型，如果如上一个问题的回答描述的这样，则处于阻塞状态，如果使用了epoll,select等这样的io复用情况下，处于运行状态

### 5.4私网IP地址怎么上网？

#### NAT

- 静态NAT：一个私有IP固定映射一个公有IP地址，提供内网服务器的对外访问服务。一对一映射
- 动态NAT：私有IP映射地址池中的公有IP，映射关系是动态的，临时的。不过依然是一对一映射。
- 这两种方式是**仅仅转换IP地址，而不去动传输层的端口号**。这种方式只能做到，有n个公网IP，只能让n台内网机器上网。只有1个公网IP，那就只能让1台内网机器上网。即一对一映射。

#### 网络地址与端口号转换NAPT

- 私有IP地址+端口号与公网IP+端口进行映射。
- 这种方式可以做到1个公网IP，多台设备上网。即多对1映射。
- 路由器在执行NAPT这个工作。
- ![image-20210113152314358](http://pichost.yangyadong.site/img/image-20210113152314358.png)
- 所以一个公网IP最多可以支撑多少台电脑上网呢？
  - 这不一定，但是有一点可以确定的是，一个公网IP在同一时刻最多支持65536个TCP连接（或者说是65536个端口可用）。
  - 而一般来说，一台电脑某一时刻使用的TCP连接也就100来个。（大数据统计的）
  - 所以理论上，一个公网ip可以带600到900台这样的电脑同时上网，实际使用中不会所有主机同时上网，所以1个公网IP带1千多台是没问题的。
  - 当然，一个公网ip能带多少内部主机，不能一概而论，要根据内部主机的应用情况，只要同一时刻的总连接数小于一个公网ip的总连接数（65536）就可以了。
  - 换句话说，端口地址转换表，这个表同一时刻最多维系65536条映射数据。因为公网IP的端口就65536这么多。

### 5.5各种物理设备都工作在哪一层

- **计算机**工作在应用层、传输层和网络层，**计算机的网卡**工作在数据链路层和物理层。
  - 网卡工作在数据链路层和物理层。
  - 应用程序是应用层。
- 集线器（hub）这种设备工作在物理层。
- 交换机根据MAC地址转发帧，MAC地址属于数据链路层地址，所以所交换机工作在数据链路层。当然交换机的接口也有物理层功能。
- **路由器接口**工作在物理层和数据链路层，路由器根据IP首部转发数据包，所以说**路由器工作在网络层**。
  - 路由器接口跟路由器不一样，接口工作在物理层和数据链路层。但是路由器的主体功能是转发数据包，工作在网络层
- ![image-20210118115932281](http://pichost.yangyadong.site/img/image-20210118115932281.png)

### 5.6网卡的作用

#### 简洁

- 数据链路层的工作：所有的比如说以太网帧的封装解封、帧的差错校验、CSMA/CD里的检测网线碰撞等待重发等等，都是网卡完成的。
- 物理层的工作：比如说物理连接和数字信号同步、数据的编码和解码

#### 详细

![image.png](https://i.loli.net/2020/11/22/nyIlFDRzcw2pOYo.png)

**比如发信息出去：**

- 计算机的CPU将网络层的内容并行通信给网卡
- 网络层的内容，先存放在网卡的存储芯片里。
- 然后进行帧的封装，也就是加上目标MAC，源MAC，标记上网络层使用的协议，然后加上帧校验序列。
  - MAC其实就是数据链路层的地址
- 封好以后，还要检测要发的时候，网线上有没有冲突。如果冲突了就尝试第二次、第三次...发。也就是CAMA/CS就是在这里使用的
  - 以上都是数据链路层的工作
- 所有搞完以后，数字信号同步，数据进行编码（比如曼彻斯特编码）并串行发送到网线上
  - 只有这里是物理层工作

**接收信息**

- 串行接受网线上的信息，数字信号同步，并进行数据解码（比如解码曼彻斯特）
  - 只有这里是物理层工作，之下都是数据链路层的工作
- 先把接受到的内容，放在网卡存储芯片里
- 然后进行帧的拆封。
  - 到网卡这儿的时候，理论上应该已经可以没有MAC地址了，因为交换机现在是指谁发给谁，不会乱发。但是交换机对于没有见过的MAC，会往所有口全发一遍。所以实际上到网卡这儿还是有MAC的
  - **（即交换机比集线器好在，避免了很多不是自己的MAC地址的数据包传过来。但是没有完全避免，只是避免掉了大部分，对于交换机没有见过的MAC或者说第一次见时，要给所有的口转发一遍）**
- 拆封过程即，看看目标MAC是不是自己，不是自己的就扔掉。是自己的，就拆掉目标MAC和源MAC，然后开始帧的差错检验。一验，没有差错，那就留下。有差错，直接扔掉
- 然后把数据包解码，并行通信给计算机的CPU

## 6.网络安全相关

### 6.1 请你来说一下数字证书是什么，里面都包含那些内容

#### 牛客版参考

- 1）概念：
  - 数字证书是数字证书在一个身份和该身份的持有者所拥有的公/私钥对之间建立了一种联系，由认证中心（CA）或者认证中心的下级认证中心颁发的。根证书是认证中心与用户建立信任关系的基础。在用户（服务器）使用数字证书之前必须首先下载和安装。
  - 认证中心是一家能向用户签发数字证书以确认用户身份的管理机构。为了防止数字凭证的伪造，认证中心的公共密钥必须是可靠的，认证中心必须公布其公共密钥或由更高级别的认证中心提供一个电子凭证来证明其公共密钥的有效性，后一种方法导致了多级别认证中心的出现。
- 2）数字证书颁发过程：
  - 数字证书颁发过程如下：用户产生了自己的密钥对，并将公共密钥及部分个人身份信息传送给一家认证中心。认证中心在核实身份后，将执行一些必要的步骤，以确信请求确实由用户发送而来，然后，认证中心将发给用户一个数字证书，该证书内附了用户和他的密钥等信息，同时还附有对认证中心公共密钥加以确认的数字证书。当用户想证明其公开密钥的合法性时，就可以提供这一数字证书。
- 3）内容：
  - 数字证书的格式普遍采用的是X.509V3国际标准，一个标准的X.509数字证书包含以下一些内容：
    - 1、证书的版本信息；
    - 2、证书的序列号，每个证书都有一个唯一的证书序列号；
    - 3、证书所使用的签名算法；
    - 4、证书的发行机构名称，命名规则一般采用X.500格式；
    - 5、证书的有效期，通用的证书一般采用UTC时间格式；
    - 6、证书所有人的名称，命名规则一般采用X.500格式；
    - 7、证书所有人的公开密钥；
    - 8、证书发行者对证书的签名。
  - 前7项是证书明文，最后一项是CA对证书的数字签名。

#### 自己总结版

- 1.数字证书是什么

  - 网站在使用HTTPS前，需要向“**CA机构**”（certification authority认证中心）申请颁发一份**数字证书**，**数字证书里有证书持有者（域名）、证书持有者的公钥、证书过期时间、摘要算法、CA对证书的数字签名等信息**。服务器把证书传输给浏览器，浏览器从证书里取公钥就行了，证书就如身份证一样，可以证明“该公钥对应该网站”。
  - 简言之，数字证书=【证书明文+CA数字签名】
    - 证书明文   包括：【1、证书的版本信息；2、证书的序列号，每个证书都有一个唯一的证书序列号；3、证书所使用的签名（摘要）算法；4、证书的发行机构名称，命名规则一般采用X.500格式；5、证书的有效期，通用的证书一般采用UTC时间格式；6、证书所有人的名称，一般是域名，命名规则一般采用X.500格式；7、证书所有人的公开密钥；】
    - CA对证书的数字签名    （证书明文经过摘要hash算法压缩得到摘要（或者说叫签名)，然后摘要由CA机构的私钥C.pri加密，得到数字签名）

- 2.证书颁发过程（包含了CA对证书的数字签名的生成过程）

  - 1.网站自己生成一对非对称秘钥，公钥S.pub私钥S.pri
  - 2.CA肯定也有自己的非对称秘钥即CA公钥CA.pub和CA私钥CA.pri
  - 3.CA对证书明文信息【证书明文包括：证书持有者(域名)、证书持有者的公钥S.pub、证书过期时间、摘要hash算法等信息】进行hash
  - 4.对hash后的值用CA私钥CA.pri进行加密，就得到了CA证书数字签名
  - 5.将 【证书明文+CA证书数字签名】一起作为数字证书，颁发给网站。
  - 6.此时网站就有 一个数字证书(pem文件)和一个自己的私钥（S.pri即key文件）
    - 客服端发起请求时，网站不再是把公钥给客户端了，而是把数字证书给客户端。

- 3.证书的验证过程

  - ##### 浏览器验证过程：（浏览器对CA证书的验证过程）

    - 1.浏览器收到服务器传来的数字证书，可以分别拆解得到【证书明文+CA证书数字签名】
    - 2.用CA机构的公钥CA.pub对CA证书数字签名解密（由于是浏览器信任的机构，所以浏览器一定有CA公钥）。得到一个摘要（签名）
    - 3.用证书里说明的hash算法对证书明文进行hash得到另一个摘要（签名）。
    - 4.比较这两个摘要（签名）是否相等。
      - 相等，则证书可信。
      - 不相等，则可能是证书被篡改了。

- ![image-20210104212257805](https://i.loli.net/2021/01/04/pcgOLy9QIFlHY15.png)

### 6.2SYN洪水攻击（想发起这种攻击一台主机就可以做到，而DDos需要大量肉鸡）

#### SYN攻击

- SYN-Flood是一种利用TCP协议缺陷，发送大量伪造的TCP连接请求.
- 当攻击者向服务器发送大量SYN报文后，而不进行TCP第三次握手ACK包的应答。那么服务器在发出SYN+ACK应答报文后是无法收到客户端的ACK报文的，这种情况下服务器端将为了维护一个非常大的半连接列表而消耗非常多的资源无暇理睬客户的正常请求（毕竟客户端的正常请求比率非常之小），此时从正常客户的角度看来，服务器失去响应，这种情况我们称作：服务器端受到了SYN Flood攻击（SYN洪水攻击）。
- ![image-20210111213532458](http://pichost.yangyadong.site/img/image-20210111213532458.png)

#### 防范措施

- SYN Cookie
  -  SYN Cookie是专门用来防范SYN Flood攻击的一种手段。
  - 它的原理是，在TCP服务器收到TCP SYN包（第一次握手）并返回TCP SYN+ACK包（第二次握手）时，不分配一个专门的数据区，而是根据这个SYN包（第一次握手）计算出一个cookie值，这个cookie作为将要返回的SYN+ACK包的初始序号。在客户端返回一个ACK包（第三次握手）时，TCP服务器再根据ACK包头信息计算cookie，与返回的确认号(初始序列号 + 1)进行对比，如果相同，则是一个正常连接，然后，分配资源、数据区等，建立连接。
  - 简言之：
    - 要是正常的话，第二次握手完就得分配资源了。
    - 使用SYN Cookie策略时，第二次握手完，服务器根本就不分配资源。
    - 服务器根据第一次握手的信息算出一个SYN cookie，然后作为第二次握手的seq=y的y，发送第二次握手过去。
    - 如果客户端第三次握手返回来了ack=y+1，刚好是我的SYN cookie+1。那说明是个合法连接，才分配资源、数据区等，进行正常通信。
    - 如果是SYN攻击的话，是不会第三次握手的（因为第一次握手的IP都是伪造的，真实的IP主机根本不会理会服务器的第二次握手）。我的服务器也仅仅只是存了一个cookie而已，没有占用多少资源。因此，面对1000个伪造的SYN攻击，服务器也只是存了1000个cookie，根本不算皮毛，几乎占用不了我的服务器的资源。

### 6.3ARP欺骗（局域网才可以做到）

- ARP协议是建立在网络中各个主机互相信任的基础上的，计算机A发送ARP广播帧解析计算机C的MAC地址，同一个网段中的计算机都能够收到这个ARP请求消息，任何一个主机都可以给计算机A发送ARP应答消息，可以告诉计算机A一个错误的MAC地址，计算机A收到ARP应答报文时并不会检测该报文的真实性，就会将其记入本机ARP缓存，这就存在一个安全隐患--ARP欺骗。
- 网络执法官软件可以控制以太网中的计算机通信
  - ![image-20201223200535299](https://i.loli.net/2020/12/23/LnxQKHCl12k9NeE.png)
  - 比如计算机A想ping计算机C。那A就在局域网内发ARP广播，问计算机C（192.168.80.30）的MAC地址是多少。C收到广播了，肯定回复A计算机。正常情况下B计算机收到广播了，一看不是找自己的，那就不回复
    - 但是，ARP欺骗，就是计算机B收到广播了，一看A想问C的MAC地址。计算机B告诉计算机A了一个假的MAC地址。
    - 此时计算机A收到了C计算机回复了第一个MAC地址。没一会儿，又收到了一个号称是计算机C的MAC地址。计算机A以后来的为准。
    - 那么A跟C就通不了了。要是没有网络执法官来欺骗，是可以通的。网络执法官计算机B一欺骗，就不通了了。
  - 再比如不想让A访问internet，那就让A发ARP询问网关时，网络执法官（也就是计算机B）告诉计算机A一个错误的网关MAC。A就上不了网了。
- 总结：
  - 简言之，就是局域网内某个主机，发送了假的ARP回复。两头骗，骗网关和骗别人的主机，让别人的主机arp解析网关mac时解析成一个不存在的mac，那别人的主机就上不了网了

### 6.4 DDos攻击

-  dos攻击
  - 拒绝服务式攻击，即dos攻击（Denial of Service）。
  - 使用udp炸弹，给目标网站发送大量没用的数据包，目标网站主机带宽不够用，网站就卡了，没法给客服提供正常服务了。
-  DDos攻击
  - 黑客在网上，找到很多台有漏洞的主机（也叫肉鸡），这种有漏洞的主机也有公网IP，可以被黑客操纵。
  - 黑客操纵互联网上很多台主机，同时对一个网站进行数据包轰炸，对目标网站在较短的时间内发起大量请求，大规模消耗目标网站的主机资源，让它无法正常服务。这就叫做 分布式拒绝服务攻击 DDos。
    - 可能是ICMP Flood、UDP Flood、SYN Flood、DNS Query Flood等等。反正就是数据包轰炸，可能是各种类型的数据包。
  - 让你的网站带宽不够用，没法为客户提供服务，这就是拒绝服务式攻击。很多台主机一起发动攻击，这就是分布式攻击。所以合称分布式拒绝服务攻击DDos。
  - 这种攻击没法有效防范，因为带宽被吃没了，防火墙也无能为力，电脑关了都不行。唯一解决途径只能让网站租用特别高带宽的服务器，你再多主机攻击我带宽都够用，比如我的网站的服务器有10G带宽，你就算ddos有100台主机攻击我，你一个主机也就才10M，100台才1G，完全攻不摊我的服务器。
- 防范措施：
  - 1.使用高带宽服务器
    - 高防服务器主要是指能独立硬防御 50Gbps 以上的服务器，能够帮助网站拒绝服务攻击，定期扫描网络主节点等，这东西是不错，就是贵。
  - 2.CDN云分发
    - CDN ( Content Delivery Network )，即内容分发网络。**将网站内容分发至全网加速节点**，配合智能调度和边缘缓存，**使用户可就近获取所需内容**，解决网络拥塞问题，提高网站响应速度和可用性，降低源站压力。
    - CDN 服务将网站访问流量分配到了各个节点中，这样一方面隐藏网站的真实 IP，另一方面即使遭遇 DDoS 攻击，也可以将流量分散到各个节点中，防止源站崩溃。
    - CDN能隐藏真实服务器IP。把DDOS的攻击分流出去，增加攻击成本。
    - 说白了，就是租一堆服务器，让这些服务器同步我的主服务器内容，让它们替我的服务器分担流量。
  - 3.黑名单
    - 太频繁的IP就给它封掉。不过有时候真实客户也很频繁，也被封掉了。这个就是设置黑名单，此方法秉承的就是“错杀一千，也不放一百”的原则，有可能会封锁正常流量，影响到正常业务。

### 6.5CSRF攻击与防御

https://blog.csdn.net/stpeace/article/details/53512283

#### 原理

- CSRF跨站点请求伪造(Cross—Site Request Forgery)，跟XSS攻击一样，存在巨大的危害性，你可以这样来理解：
- 攻击者盗用了你的身份，以你的名义发送恶意请求，对服务器来说这个请求是完全合法的，但是却完成了攻击者所期望的一个操作，比如以你的名义发送邮件、发消息，盗取你的账号，添加系统管理员，甚至于购买商品、虚拟货币转账等。 

 **CSRF攻击攻击原理及过程如下：**

如下：其中Web A为存在CSRF漏洞的网站，Web B为攻击者构建的恶意网站，User C为Web A网站的合法用户。

- 1.用户C打开浏览器，访问受信任网站A，输入用户名和密码请求登录网站A；
- 2.在用户信息通过验证后，网站A产生Cookie信息并返回给浏览器，此时用户登录网站A成功，可以正常发送请求到网站A；
- 3.用户未退出网站A之前，在同一浏览器中，打开一个TAB页访问网站B；
- 4.网站B接收到用户请求后，返回一些攻击性代码，并发出一个请求要求访问第三方站点A；
- 5.浏览器在接收到这些攻击性代码后，根据网站B的请求，在用户不知情的情况下携带Cookie信息，向网站A发出请求。网站A并不知道该请求其实是由B发起的，所以会根据用户C的Cookie信息以C的权限处理该请求，导致来自网站B的恶意代码被执行。 

#### 实例

- 受害者 Bob 在银行有一笔存款，通过对银行的网站发送请求 http://bank.example/withdraw?account=bob&amount=1000000&for=bob2 可以使 Bob 把 1000000 的存款转到 bob2 的账号下。通常情况下，该请求发送到网站后，服务器会先验证该请求是否来自一个合法的 session，并且该 session 的用户 Bob 已经成功登陆。
- 黑客 Mallory 自己在该银行也有账户，他知道上文中的 URL 可以把钱进行转帐操作。Mallory 可以自己发送一个请求给银行：http://bank.example/withdraw?account=bob&amount=1000000&for=Mallory。但是这个请求来自 Mallory 而非 Bob，他不能通过安全认证，因此该请求不会起作用。
- 这时，Mallory 想到使用 CSRF 的攻击方式，他先自己做一个网站，在网站中放入如下代码： src=”http://bank.example/withdraw?account=bob&amount=1000000&for=Mallory ”，并且通过广告等诱使 Bob 来访问他的网站。当 Bob 访问该网站时，上述 url 就会从 Bob 的浏览器发向银行，而这个请求会附带 Bob 浏览器中的 cookie 一起发向银行服务器。大多数情况下，该请求会失败，因为他要求 Bob 的认证信息。但是，如果 Bob 当时恰巧刚访问他的银行后不久，他的浏览器与银行网站之间的 session 尚未过期，浏览器的 cookie 之中含有 Bob 的认证信息。这时，悲剧发生了，这个 url 请求就会得到响应，钱将从 Bob 的账号转移到 Mallory 的账号，而 Bob 当时毫不知情。等以后 Bob 发现账户钱少了，即使他去银行查询日志，他也只能发现确实有一个来自于他本人的合法请求转移了资金，没有任何被攻击的痕迹。而 Mallory 则可以拿到钱后逍遥法外。 

#### CSRF防御

- 1.验证 HTTP Referer 字段
- 2.在请求地址中添加 token 并验证
  -  CSRF 攻击之所以能够成功，是因为黑客可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 cookie 中，因此黑客可以在不知道这些验证信息的情况下直接利用用户自己的 cookie 来通过安全验证。要抵御 CSRF，关键在于在请求中放入黑客所不能伪造的信息，并且该信息不存在于 cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。
- 3.在 HTTP 头中自定义属性并验证